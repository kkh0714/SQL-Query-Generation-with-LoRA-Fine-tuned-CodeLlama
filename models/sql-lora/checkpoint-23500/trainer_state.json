{
  "best_global_step": 20500,
  "best_metric": 0.3402363955974579,
  "best_model_checkpoint": "./models/sql-lora\\checkpoint-20500",
  "epoch": 2.9906143616175114,
  "eval_steps": 500,
  "global_step": 23500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00012726289332187966,
      "grad_norm": 1.059227466583252,
      "learning_rate": 0.0,
      "loss": 2.1728,
      "step": 1
    },
    {
      "epoch": 0.0012726289332187968,
      "grad_norm": 0.7511335015296936,
      "learning_rate": 1.8e-05,
      "loss": 2.2625,
      "step": 10
    },
    {
      "epoch": 0.0025452578664375935,
      "grad_norm": 0.5990417003631592,
      "learning_rate": 3.8e-05,
      "loss": 2.1236,
      "step": 20
    },
    {
      "epoch": 0.00381788679965639,
      "grad_norm": 0.9447440505027771,
      "learning_rate": 5.8e-05,
      "loss": 1.8085,
      "step": 30
    },
    {
      "epoch": 0.005090515732875187,
      "grad_norm": 0.6914405226707458,
      "learning_rate": 7.800000000000001e-05,
      "loss": 1.209,
      "step": 40
    },
    {
      "epoch": 0.006363144666093984,
      "grad_norm": 0.9280157089233398,
      "learning_rate": 9.8e-05,
      "loss": 0.7729,
      "step": 50
    },
    {
      "epoch": 0.00763577359931278,
      "grad_norm": 0.397215336561203,
      "learning_rate": 0.000118,
      "loss": 0.6875,
      "step": 60
    },
    {
      "epoch": 0.008908402532531577,
      "grad_norm": 0.4037662446498871,
      "learning_rate": 0.000138,
      "loss": 0.6369,
      "step": 70
    },
    {
      "epoch": 0.010181031465750374,
      "grad_norm": 0.37055811285972595,
      "learning_rate": 0.00015800000000000002,
      "loss": 0.608,
      "step": 80
    },
    {
      "epoch": 0.011453660398969171,
      "grad_norm": 0.32679516077041626,
      "learning_rate": 0.00017800000000000002,
      "loss": 0.5832,
      "step": 90
    },
    {
      "epoch": 0.012726289332187968,
      "grad_norm": 0.37276265025138855,
      "learning_rate": 0.00019800000000000002,
      "loss": 0.5755,
      "step": 100
    },
    {
      "epoch": 0.013998918265406763,
      "grad_norm": 0.40921008586883545,
      "learning_rate": 0.00019999983608637713,
      "loss": 0.5141,
      "step": 110
    },
    {
      "epoch": 0.01527154719862556,
      "grad_norm": 0.3665948808193207,
      "learning_rate": 0.0001999992694720744,
      "loss": 0.511,
      "step": 120
    },
    {
      "epoch": 0.01654417613184436,
      "grad_norm": 0.4036601483821869,
      "learning_rate": 0.00019999829813575944,
      "loss": 0.5207,
      "step": 130
    },
    {
      "epoch": 0.017816805065063154,
      "grad_norm": 0.33048656582832336,
      "learning_rate": 0.00019999692208136355,
      "loss": 0.5213,
      "step": 140
    },
    {
      "epoch": 0.01908943399828195,
      "grad_norm": 0.3763377070426941,
      "learning_rate": 0.00019999514131445597,
      "loss": 0.4953,
      "step": 150
    },
    {
      "epoch": 0.02036206293150075,
      "grad_norm": 0.4006941318511963,
      "learning_rate": 0.0001999929558422439,
      "loss": 0.4632,
      "step": 160
    },
    {
      "epoch": 0.021634691864719544,
      "grad_norm": 0.3376578390598297,
      "learning_rate": 0.00019999036567357244,
      "loss": 0.5096,
      "step": 170
    },
    {
      "epoch": 0.022907320797938342,
      "grad_norm": 0.3127877116203308,
      "learning_rate": 0.00019998737081892474,
      "loss": 0.5014,
      "step": 180
    },
    {
      "epoch": 0.024179949731157137,
      "grad_norm": 0.2798115611076355,
      "learning_rate": 0.00019998397129042167,
      "loss": 0.4674,
      "step": 190
    },
    {
      "epoch": 0.025452578664375936,
      "grad_norm": 0.2624705135822296,
      "learning_rate": 0.00019998016710182196,
      "loss": 0.4672,
      "step": 200
    },
    {
      "epoch": 0.02672520759759473,
      "grad_norm": 0.27255743741989136,
      "learning_rate": 0.00019997595826852215,
      "loss": 0.4954,
      "step": 210
    },
    {
      "epoch": 0.027997836530813527,
      "grad_norm": 0.3000965714454651,
      "learning_rate": 0.0001999713448075564,
      "loss": 0.4572,
      "step": 220
    },
    {
      "epoch": 0.029270465464032325,
      "grad_norm": 0.311255544424057,
      "learning_rate": 0.00019996632673759658,
      "loss": 0.4665,
      "step": 230
    },
    {
      "epoch": 0.03054309439725112,
      "grad_norm": 0.3024809956550598,
      "learning_rate": 0.00019996090407895206,
      "loss": 0.4622,
      "step": 240
    },
    {
      "epoch": 0.03181572333046992,
      "grad_norm": 0.29154661297798157,
      "learning_rate": 0.00019995507685356966,
      "loss": 0.4564,
      "step": 250
    },
    {
      "epoch": 0.03308835226368872,
      "grad_norm": 0.2244841307401657,
      "learning_rate": 0.00019994884508503367,
      "loss": 0.4751,
      "step": 260
    },
    {
      "epoch": 0.03436098119690751,
      "grad_norm": 0.28219303488731384,
      "learning_rate": 0.00019994220879856553,
      "loss": 0.4954,
      "step": 270
    },
    {
      "epoch": 0.03563361013012631,
      "grad_norm": 0.3122469186782837,
      "learning_rate": 0.00019993516802102406,
      "loss": 0.4647,
      "step": 280
    },
    {
      "epoch": 0.03690623906334511,
      "grad_norm": 0.3144119679927826,
      "learning_rate": 0.00019992772278090498,
      "loss": 0.4588,
      "step": 290
    },
    {
      "epoch": 0.0381788679965639,
      "grad_norm": 0.3321373760700226,
      "learning_rate": 0.000199919873108341,
      "loss": 0.4509,
      "step": 300
    },
    {
      "epoch": 0.0394514969297827,
      "grad_norm": 0.2902957797050476,
      "learning_rate": 0.00019991161903510176,
      "loss": 0.4327,
      "step": 310
    },
    {
      "epoch": 0.0407241258630015,
      "grad_norm": 0.44116294384002686,
      "learning_rate": 0.00019990296059459357,
      "loss": 0.4582,
      "step": 320
    },
    {
      "epoch": 0.041996754796220295,
      "grad_norm": 0.35645315051078796,
      "learning_rate": 0.0001998938978218593,
      "loss": 0.4483,
      "step": 330
    },
    {
      "epoch": 0.04326938372943909,
      "grad_norm": 0.33013689517974854,
      "learning_rate": 0.00019988443075357815,
      "loss": 0.4433,
      "step": 340
    },
    {
      "epoch": 0.044542012662657886,
      "grad_norm": 0.25613951683044434,
      "learning_rate": 0.0001998745594280658,
      "loss": 0.4832,
      "step": 350
    },
    {
      "epoch": 0.045814641595876684,
      "grad_norm": 0.2826303541660309,
      "learning_rate": 0.000199864283885274,
      "loss": 0.4537,
      "step": 360
    },
    {
      "epoch": 0.047087270529095476,
      "grad_norm": 0.35812482237815857,
      "learning_rate": 0.00019985360416679038,
      "loss": 0.4485,
      "step": 370
    },
    {
      "epoch": 0.048359899462314275,
      "grad_norm": 0.2763531506061554,
      "learning_rate": 0.00019984252031583842,
      "loss": 0.4428,
      "step": 380
    },
    {
      "epoch": 0.049632528395533074,
      "grad_norm": 0.3039531111717224,
      "learning_rate": 0.00019983103237727727,
      "loss": 0.43,
      "step": 390
    },
    {
      "epoch": 0.05090515732875187,
      "grad_norm": 0.26911965012550354,
      "learning_rate": 0.00019981914039760148,
      "loss": 0.4514,
      "step": 400
    },
    {
      "epoch": 0.052177786261970664,
      "grad_norm": 0.33289840817451477,
      "learning_rate": 0.00019980684442494082,
      "loss": 0.4469,
      "step": 410
    },
    {
      "epoch": 0.05345041519518946,
      "grad_norm": 0.25282132625579834,
      "learning_rate": 0.0001997941445090602,
      "loss": 0.4394,
      "step": 420
    },
    {
      "epoch": 0.05472304412840826,
      "grad_norm": 0.26498690247535706,
      "learning_rate": 0.00019978104070135933,
      "loss": 0.4489,
      "step": 430
    },
    {
      "epoch": 0.05599567306162705,
      "grad_norm": 0.3393036425113678,
      "learning_rate": 0.00019976753305487262,
      "loss": 0.4584,
      "step": 440
    },
    {
      "epoch": 0.05726830199484585,
      "grad_norm": 0.25580060482025146,
      "learning_rate": 0.0001997536216242689,
      "loss": 0.4475,
      "step": 450
    },
    {
      "epoch": 0.05854093092806465,
      "grad_norm": 0.34103724360466003,
      "learning_rate": 0.00019973930646585112,
      "loss": 0.4333,
      "step": 460
    },
    {
      "epoch": 0.05981355986128345,
      "grad_norm": 0.2987314462661743,
      "learning_rate": 0.0001997245876375564,
      "loss": 0.4278,
      "step": 470
    },
    {
      "epoch": 0.06108618879450224,
      "grad_norm": 0.2496708631515503,
      "learning_rate": 0.00019970946519895546,
      "loss": 0.4608,
      "step": 480
    },
    {
      "epoch": 0.06235881772772104,
      "grad_norm": 0.2212415337562561,
      "learning_rate": 0.00019969393921125258,
      "loss": 0.4255,
      "step": 490
    },
    {
      "epoch": 0.06363144666093984,
      "grad_norm": 0.32847338914871216,
      "learning_rate": 0.00019967800973728531,
      "loss": 0.4355,
      "step": 500
    },
    {
      "epoch": 0.06363144666093984,
      "eval_loss": 0.43640944361686707,
      "eval_runtime": 749.7521,
      "eval_samples_per_second": 10.481,
      "eval_steps_per_second": 5.24,
      "step": 500
    },
    {
      "epoch": 0.06490407559415863,
      "grad_norm": 0.33382534980773926,
      "learning_rate": 0.00019966167684152425,
      "loss": 0.3909,
      "step": 510
    },
    {
      "epoch": 0.06617670452737744,
      "grad_norm": 0.24473857879638672,
      "learning_rate": 0.00019964494059007267,
      "loss": 0.4529,
      "step": 520
    },
    {
      "epoch": 0.06744933346059623,
      "grad_norm": 0.24855300784111023,
      "learning_rate": 0.00019962780105066633,
      "loss": 0.4582,
      "step": 530
    },
    {
      "epoch": 0.06872196239381502,
      "grad_norm": 0.24054820835590363,
      "learning_rate": 0.00019961025829267327,
      "loss": 0.4269,
      "step": 540
    },
    {
      "epoch": 0.06999459132703383,
      "grad_norm": 0.26057884097099304,
      "learning_rate": 0.00019959231238709344,
      "loss": 0.4388,
      "step": 550
    },
    {
      "epoch": 0.07126722026025262,
      "grad_norm": 0.25741925835609436,
      "learning_rate": 0.00019957396340655837,
      "loss": 0.4225,
      "step": 560
    },
    {
      "epoch": 0.07253984919347141,
      "grad_norm": 0.26043012738227844,
      "learning_rate": 0.0001995552114253309,
      "loss": 0.4064,
      "step": 570
    },
    {
      "epoch": 0.07381247812669021,
      "grad_norm": 0.2264043390750885,
      "learning_rate": 0.0001995360565193051,
      "loss": 0.4027,
      "step": 580
    },
    {
      "epoch": 0.075085107059909,
      "grad_norm": 0.3472518026828766,
      "learning_rate": 0.00019951649876600558,
      "loss": 0.4328,
      "step": 590
    },
    {
      "epoch": 0.0763577359931278,
      "grad_norm": 0.2739354074001312,
      "learning_rate": 0.00019949653824458748,
      "loss": 0.4178,
      "step": 600
    },
    {
      "epoch": 0.0776303649263466,
      "grad_norm": 0.27498915791511536,
      "learning_rate": 0.00019947617503583595,
      "loss": 0.4334,
      "step": 610
    },
    {
      "epoch": 0.0789029938595654,
      "grad_norm": 0.21079985797405243,
      "learning_rate": 0.00019945540922216608,
      "loss": 0.411,
      "step": 620
    },
    {
      "epoch": 0.08017562279278419,
      "grad_norm": 0.28130221366882324,
      "learning_rate": 0.00019943424088762223,
      "loss": 0.4306,
      "step": 630
    },
    {
      "epoch": 0.081448251726003,
      "grad_norm": 0.254841685295105,
      "learning_rate": 0.000199412670117878,
      "loss": 0.4258,
      "step": 640
    },
    {
      "epoch": 0.08272088065922178,
      "grad_norm": 0.3233833909034729,
      "learning_rate": 0.00019939069700023563,
      "loss": 0.4351,
      "step": 650
    },
    {
      "epoch": 0.08399350959244059,
      "grad_norm": 0.2459707111120224,
      "learning_rate": 0.0001993683216236258,
      "loss": 0.4059,
      "step": 660
    },
    {
      "epoch": 0.08526613852565938,
      "grad_norm": 0.27510133385658264,
      "learning_rate": 0.00019934554407860728,
      "loss": 0.4027,
      "step": 670
    },
    {
      "epoch": 0.08653876745887817,
      "grad_norm": 0.2929190993309021,
      "learning_rate": 0.00019932236445736648,
      "loss": 0.4205,
      "step": 680
    },
    {
      "epoch": 0.08781139639209698,
      "grad_norm": 0.25604844093322754,
      "learning_rate": 0.00019929878285371712,
      "loss": 0.424,
      "step": 690
    },
    {
      "epoch": 0.08908402532531577,
      "grad_norm": 0.2975817024707794,
      "learning_rate": 0.00019927479936309982,
      "loss": 0.4445,
      "step": 700
    },
    {
      "epoch": 0.09035665425853456,
      "grad_norm": 0.2291680872440338,
      "learning_rate": 0.00019925041408258177,
      "loss": 0.4379,
      "step": 710
    },
    {
      "epoch": 0.09162928319175337,
      "grad_norm": 0.22753196954727173,
      "learning_rate": 0.00019922562711085625,
      "loss": 0.4108,
      "step": 720
    },
    {
      "epoch": 0.09290191212497216,
      "grad_norm": 0.26376283168792725,
      "learning_rate": 0.00019920043854824236,
      "loss": 0.4231,
      "step": 730
    },
    {
      "epoch": 0.09417454105819095,
      "grad_norm": 0.22632098197937012,
      "learning_rate": 0.00019917484849668452,
      "loss": 0.4341,
      "step": 740
    },
    {
      "epoch": 0.09544716999140976,
      "grad_norm": 0.2265891134738922,
      "learning_rate": 0.00019914885705975204,
      "loss": 0.4149,
      "step": 750
    },
    {
      "epoch": 0.09671979892462855,
      "grad_norm": 0.2502087950706482,
      "learning_rate": 0.00019912246434263873,
      "loss": 0.4236,
      "step": 760
    },
    {
      "epoch": 0.09799242785784734,
      "grad_norm": 0.2513493597507477,
      "learning_rate": 0.0001990956704521625,
      "loss": 0.4358,
      "step": 770
    },
    {
      "epoch": 0.09926505679106615,
      "grad_norm": 0.22405105829238892,
      "learning_rate": 0.00019906847549676498,
      "loss": 0.434,
      "step": 780
    },
    {
      "epoch": 0.10053768572428494,
      "grad_norm": 0.22301359474658966,
      "learning_rate": 0.0001990408795865109,
      "loss": 0.4001,
      "step": 790
    },
    {
      "epoch": 0.10181031465750374,
      "grad_norm": 0.2707241475582123,
      "learning_rate": 0.00019901288283308781,
      "loss": 0.4342,
      "step": 800
    },
    {
      "epoch": 0.10308294359072254,
      "grad_norm": 0.23653069138526917,
      "learning_rate": 0.00019898448534980552,
      "loss": 0.4273,
      "step": 810
    },
    {
      "epoch": 0.10435557252394133,
      "grad_norm": 0.2570546865463257,
      "learning_rate": 0.0001989556872515958,
      "loss": 0.4254,
      "step": 820
    },
    {
      "epoch": 0.10562820145716013,
      "grad_norm": 0.2765389680862427,
      "learning_rate": 0.00019892648865501173,
      "loss": 0.4253,
      "step": 830
    },
    {
      "epoch": 0.10690083039037893,
      "grad_norm": 0.28100526332855225,
      "learning_rate": 0.00019889688967822728,
      "loss": 0.4068,
      "step": 840
    },
    {
      "epoch": 0.10817345932359772,
      "grad_norm": 0.2709536850452423,
      "learning_rate": 0.00019886689044103695,
      "loss": 0.4423,
      "step": 850
    },
    {
      "epoch": 0.10944608825681652,
      "grad_norm": 0.2565152049064636,
      "learning_rate": 0.00019883649106485507,
      "loss": 0.4299,
      "step": 860
    },
    {
      "epoch": 0.11071871719003532,
      "grad_norm": 0.20485669374465942,
      "learning_rate": 0.00019880569167271558,
      "loss": 0.4272,
      "step": 870
    },
    {
      "epoch": 0.1119913461232541,
      "grad_norm": 0.23217135667800903,
      "learning_rate": 0.00019877449238927131,
      "loss": 0.4197,
      "step": 880
    },
    {
      "epoch": 0.11326397505647291,
      "grad_norm": 0.326165109872818,
      "learning_rate": 0.0001987428933407935,
      "loss": 0.4322,
      "step": 890
    },
    {
      "epoch": 0.1145366039896917,
      "grad_norm": 0.2106117606163025,
      "learning_rate": 0.00019871089465517145,
      "loss": 0.4005,
      "step": 900
    },
    {
      "epoch": 0.1158092329229105,
      "grad_norm": 0.21343418955802917,
      "learning_rate": 0.00019867849646191177,
      "loss": 0.4253,
      "step": 910
    },
    {
      "epoch": 0.1170818618561293,
      "grad_norm": 0.24700887501239777,
      "learning_rate": 0.00019864569889213804,
      "loss": 0.428,
      "step": 920
    },
    {
      "epoch": 0.1183544907893481,
      "grad_norm": 0.24412640929222107,
      "learning_rate": 0.00019861250207859027,
      "loss": 0.4223,
      "step": 930
    },
    {
      "epoch": 0.1196271197225669,
      "grad_norm": 0.2223624736070633,
      "learning_rate": 0.0001985789061556242,
      "loss": 0.4339,
      "step": 940
    },
    {
      "epoch": 0.12089974865578569,
      "grad_norm": 0.24436765909194946,
      "learning_rate": 0.00019854491125921095,
      "loss": 0.4266,
      "step": 950
    },
    {
      "epoch": 0.12217237758900448,
      "grad_norm": 0.26049739122390747,
      "learning_rate": 0.00019851051752693634,
      "loss": 0.4269,
      "step": 960
    },
    {
      "epoch": 0.12344500652222329,
      "grad_norm": 0.2900514602661133,
      "learning_rate": 0.0001984757250980004,
      "loss": 0.4302,
      "step": 970
    },
    {
      "epoch": 0.12471763545544208,
      "grad_norm": 0.20771737396717072,
      "learning_rate": 0.00019844053411321674,
      "loss": 0.4073,
      "step": 980
    },
    {
      "epoch": 0.12599026438866087,
      "grad_norm": 0.3003405034542084,
      "learning_rate": 0.00019840494471501212,
      "loss": 0.4061,
      "step": 990
    },
    {
      "epoch": 0.12726289332187968,
      "grad_norm": 0.21513056755065918,
      "learning_rate": 0.00019836895704742572,
      "loss": 0.3848,
      "step": 1000
    },
    {
      "epoch": 0.12726289332187968,
      "eval_loss": 0.4144893288612366,
      "eval_runtime": 743.0689,
      "eval_samples_per_second": 10.575,
      "eval_steps_per_second": 5.288,
      "step": 1000
    },
    {
      "epoch": 0.12853552225509848,
      "grad_norm": 0.23211903870105743,
      "learning_rate": 0.00019833257125610856,
      "loss": 0.4149,
      "step": 1010
    },
    {
      "epoch": 0.12980815118831726,
      "grad_norm": 0.2532954812049866,
      "learning_rate": 0.00019829578748832306,
      "loss": 0.4395,
      "step": 1020
    },
    {
      "epoch": 0.13108078012153607,
      "grad_norm": 0.2609003782272339,
      "learning_rate": 0.00019825860589294228,
      "loss": 0.396,
      "step": 1030
    },
    {
      "epoch": 0.13235340905475487,
      "grad_norm": 0.2440241426229477,
      "learning_rate": 0.00019822102662044947,
      "loss": 0.4146,
      "step": 1040
    },
    {
      "epoch": 0.13362603798797365,
      "grad_norm": 0.2633926570415497,
      "learning_rate": 0.0001981830498229373,
      "loss": 0.398,
      "step": 1050
    },
    {
      "epoch": 0.13489866692119246,
      "grad_norm": 0.318979948759079,
      "learning_rate": 0.0001981446756541074,
      "loss": 0.3935,
      "step": 1060
    },
    {
      "epoch": 0.13617129585441126,
      "grad_norm": 0.2677208185195923,
      "learning_rate": 0.0001981059042692695,
      "loss": 0.4295,
      "step": 1070
    },
    {
      "epoch": 0.13744392478763004,
      "grad_norm": 0.26512250304222107,
      "learning_rate": 0.0001980667358253412,
      "loss": 0.4217,
      "step": 1080
    },
    {
      "epoch": 0.13871655372084885,
      "grad_norm": 0.2599424421787262,
      "learning_rate": 0.00019802717048084692,
      "loss": 0.42,
      "step": 1090
    },
    {
      "epoch": 0.13998918265406765,
      "grad_norm": 0.32032760977745056,
      "learning_rate": 0.00019798720839591744,
      "loss": 0.4275,
      "step": 1100
    },
    {
      "epoch": 0.14126181158728643,
      "grad_norm": 0.20141607522964478,
      "learning_rate": 0.0001979468497322894,
      "loss": 0.4135,
      "step": 1110
    },
    {
      "epoch": 0.14253444052050523,
      "grad_norm": 0.3143404424190521,
      "learning_rate": 0.00019790609465330426,
      "loss": 0.415,
      "step": 1120
    },
    {
      "epoch": 0.14380706945372404,
      "grad_norm": 0.20484526455402374,
      "learning_rate": 0.0001978649433239081,
      "loss": 0.4206,
      "step": 1130
    },
    {
      "epoch": 0.14507969838694282,
      "grad_norm": 0.2709077000617981,
      "learning_rate": 0.0001978233959106506,
      "loss": 0.3953,
      "step": 1140
    },
    {
      "epoch": 0.14635232732016162,
      "grad_norm": 0.21405300498008728,
      "learning_rate": 0.00019778145258168451,
      "loss": 0.396,
      "step": 1150
    },
    {
      "epoch": 0.14762495625338043,
      "grad_norm": 0.2626498341560364,
      "learning_rate": 0.000197739113506765,
      "loss": 0.4434,
      "step": 1160
    },
    {
      "epoch": 0.1488975851865992,
      "grad_norm": 0.2693157494068146,
      "learning_rate": 0.0001976963788572488,
      "loss": 0.4197,
      "step": 1170
    },
    {
      "epoch": 0.150170214119818,
      "grad_norm": 0.25565797090530396,
      "learning_rate": 0.00019765324880609373,
      "loss": 0.4225,
      "step": 1180
    },
    {
      "epoch": 0.15144284305303682,
      "grad_norm": 0.20845139026641846,
      "learning_rate": 0.00019760972352785792,
      "loss": 0.4046,
      "step": 1190
    },
    {
      "epoch": 0.1527154719862556,
      "grad_norm": 0.18222962319850922,
      "learning_rate": 0.00019756580319869898,
      "loss": 0.4152,
      "step": 1200
    },
    {
      "epoch": 0.1539881009194744,
      "grad_norm": 0.2450084388256073,
      "learning_rate": 0.00019752148799637346,
      "loss": 0.4189,
      "step": 1210
    },
    {
      "epoch": 0.1552607298526932,
      "grad_norm": 0.23591721057891846,
      "learning_rate": 0.00019747677810023608,
      "loss": 0.4125,
      "step": 1220
    },
    {
      "epoch": 0.15653335878591199,
      "grad_norm": 0.30602604150772095,
      "learning_rate": 0.00019743167369123894,
      "loss": 0.444,
      "step": 1230
    },
    {
      "epoch": 0.1578059877191308,
      "grad_norm": 0.254899799823761,
      "learning_rate": 0.00019738617495193084,
      "loss": 0.4213,
      "step": 1240
    },
    {
      "epoch": 0.1590786166523496,
      "grad_norm": 0.2705184519290924,
      "learning_rate": 0.00019734028206645654,
      "loss": 0.4016,
      "step": 1250
    },
    {
      "epoch": 0.16035124558556837,
      "grad_norm": 0.2539750337600708,
      "learning_rate": 0.00019729399522055603,
      "loss": 0.4048,
      "step": 1260
    },
    {
      "epoch": 0.16162387451878718,
      "grad_norm": 0.2675987184047699,
      "learning_rate": 0.0001972473146015637,
      "loss": 0.4174,
      "step": 1270
    },
    {
      "epoch": 0.162896503452006,
      "grad_norm": 0.20556168258190155,
      "learning_rate": 0.00019720024039840766,
      "loss": 0.4095,
      "step": 1280
    },
    {
      "epoch": 0.1641691323852248,
      "grad_norm": 0.19863826036453247,
      "learning_rate": 0.00019715277280160897,
      "loss": 0.3902,
      "step": 1290
    },
    {
      "epoch": 0.16544176131844357,
      "grad_norm": 0.25841501355171204,
      "learning_rate": 0.0001971049120032809,
      "loss": 0.4269,
      "step": 1300
    },
    {
      "epoch": 0.16671439025166238,
      "grad_norm": 0.22040435671806335,
      "learning_rate": 0.000197056658197128,
      "loss": 0.4289,
      "step": 1310
    },
    {
      "epoch": 0.16798701918488118,
      "grad_norm": 0.27355432510375977,
      "learning_rate": 0.00019700801157844549,
      "loss": 0.4003,
      "step": 1320
    },
    {
      "epoch": 0.16925964811809996,
      "grad_norm": 0.3163929283618927,
      "learning_rate": 0.00019695897234411834,
      "loss": 0.3957,
      "step": 1330
    },
    {
      "epoch": 0.17053227705131876,
      "grad_norm": 0.23528386652469635,
      "learning_rate": 0.00019690954069262066,
      "loss": 0.3732,
      "step": 1340
    },
    {
      "epoch": 0.17180490598453757,
      "grad_norm": 0.25503405928611755,
      "learning_rate": 0.00019685971682401464,
      "loss": 0.4005,
      "step": 1350
    },
    {
      "epoch": 0.17307753491775635,
      "grad_norm": 0.2553548216819763,
      "learning_rate": 0.00019680950093994986,
      "loss": 0.4146,
      "step": 1360
    },
    {
      "epoch": 0.17435016385097515,
      "grad_norm": 0.23394548892974854,
      "learning_rate": 0.00019675889324366263,
      "loss": 0.4434,
      "step": 1370
    },
    {
      "epoch": 0.17562279278419396,
      "grad_norm": 0.1981273889541626,
      "learning_rate": 0.0001967078939399749,
      "loss": 0.4156,
      "step": 1380
    },
    {
      "epoch": 0.17689542171741274,
      "grad_norm": 0.22939011454582214,
      "learning_rate": 0.0001966565032352936,
      "loss": 0.399,
      "step": 1390
    },
    {
      "epoch": 0.17816805065063154,
      "grad_norm": 0.24201159179210663,
      "learning_rate": 0.0001966047213376097,
      "loss": 0.4091,
      "step": 1400
    },
    {
      "epoch": 0.17944067958385035,
      "grad_norm": 0.17512787878513336,
      "learning_rate": 0.0001965525484564975,
      "loss": 0.3814,
      "step": 1410
    },
    {
      "epoch": 0.18071330851706913,
      "grad_norm": 0.22698163986206055,
      "learning_rate": 0.00019649998480311367,
      "loss": 0.4229,
      "step": 1420
    },
    {
      "epoch": 0.18198593745028793,
      "grad_norm": 0.20497988164424896,
      "learning_rate": 0.00019644703059019646,
      "loss": 0.3814,
      "step": 1430
    },
    {
      "epoch": 0.18325856638350674,
      "grad_norm": 0.24581177532672882,
      "learning_rate": 0.0001963936860320648,
      "loss": 0.3865,
      "step": 1440
    },
    {
      "epoch": 0.18453119531672552,
      "grad_norm": 0.22161301970481873,
      "learning_rate": 0.00019633995134461736,
      "loss": 0.4159,
      "step": 1450
    },
    {
      "epoch": 0.18580382424994432,
      "grad_norm": 0.26407507061958313,
      "learning_rate": 0.00019628582674533193,
      "loss": 0.4101,
      "step": 1460
    },
    {
      "epoch": 0.18707645318316313,
      "grad_norm": 0.22094939649105072,
      "learning_rate": 0.00019623131245326422,
      "loss": 0.3986,
      "step": 1470
    },
    {
      "epoch": 0.1883490821163819,
      "grad_norm": 0.21260716021060944,
      "learning_rate": 0.00019617640868904718,
      "loss": 0.3993,
      "step": 1480
    },
    {
      "epoch": 0.1896217110496007,
      "grad_norm": 0.2618875503540039,
      "learning_rate": 0.00019612111567489008,
      "loss": 0.3926,
      "step": 1490
    },
    {
      "epoch": 0.19089433998281952,
      "grad_norm": 0.22625286877155304,
      "learning_rate": 0.00019606543363457756,
      "loss": 0.4051,
      "step": 1500
    },
    {
      "epoch": 0.19089433998281952,
      "eval_loss": 0.4004307687282562,
      "eval_runtime": 742.9991,
      "eval_samples_per_second": 10.576,
      "eval_steps_per_second": 5.288,
      "step": 1500
    },
    {
      "epoch": 0.1921669689160383,
      "grad_norm": 0.23780208826065063,
      "learning_rate": 0.00019600936279346871,
      "loss": 0.3938,
      "step": 1510
    },
    {
      "epoch": 0.1934395978492571,
      "grad_norm": 0.37252360582351685,
      "learning_rate": 0.00019595290337849625,
      "loss": 0.3932,
      "step": 1520
    },
    {
      "epoch": 0.1947122267824759,
      "grad_norm": 0.18413083255290985,
      "learning_rate": 0.00019589605561816552,
      "loss": 0.4028,
      "step": 1530
    },
    {
      "epoch": 0.19598485571569468,
      "grad_norm": 0.21517173945903778,
      "learning_rate": 0.0001958388197425536,
      "loss": 0.3929,
      "step": 1540
    },
    {
      "epoch": 0.1972574846489135,
      "grad_norm": 0.29450708627700806,
      "learning_rate": 0.00019578119598330837,
      "loss": 0.4049,
      "step": 1550
    },
    {
      "epoch": 0.1985301135821323,
      "grad_norm": 0.20483534038066864,
      "learning_rate": 0.00019572318457364757,
      "loss": 0.409,
      "step": 1560
    },
    {
      "epoch": 0.19980274251535107,
      "grad_norm": 0.22029127180576324,
      "learning_rate": 0.00019566478574835786,
      "loss": 0.42,
      "step": 1570
    },
    {
      "epoch": 0.20107537144856988,
      "grad_norm": 0.23349401354789734,
      "learning_rate": 0.00019560599974379386,
      "loss": 0.4069,
      "step": 1580
    },
    {
      "epoch": 0.20234800038178868,
      "grad_norm": 0.21159088611602783,
      "learning_rate": 0.0001955468267978772,
      "loss": 0.3941,
      "step": 1590
    },
    {
      "epoch": 0.2036206293150075,
      "grad_norm": 0.22232356667518616,
      "learning_rate": 0.00019548726715009563,
      "loss": 0.3925,
      "step": 1600
    },
    {
      "epoch": 0.20489325824822627,
      "grad_norm": 0.21486036479473114,
      "learning_rate": 0.00019542732104150187,
      "loss": 0.426,
      "step": 1610
    },
    {
      "epoch": 0.20616588718144507,
      "grad_norm": 0.22724872827529907,
      "learning_rate": 0.00019536698871471274,
      "loss": 0.386,
      "step": 1620
    },
    {
      "epoch": 0.20743851611466388,
      "grad_norm": 0.2864999771118164,
      "learning_rate": 0.0001953062704139083,
      "loss": 0.3762,
      "step": 1630
    },
    {
      "epoch": 0.20871114504788266,
      "grad_norm": 0.20268234610557556,
      "learning_rate": 0.00019524516638483067,
      "loss": 0.4271,
      "step": 1640
    },
    {
      "epoch": 0.20998377398110146,
      "grad_norm": 0.22009678184986115,
      "learning_rate": 0.00019518367687478306,
      "loss": 0.4033,
      "step": 1650
    },
    {
      "epoch": 0.21125640291432027,
      "grad_norm": 0.19735677540302277,
      "learning_rate": 0.0001951218021326289,
      "loss": 0.3995,
      "step": 1660
    },
    {
      "epoch": 0.21252903184753905,
      "grad_norm": 0.22975341975688934,
      "learning_rate": 0.0001950595424087908,
      "loss": 0.3846,
      "step": 1670
    },
    {
      "epoch": 0.21380166078075785,
      "grad_norm": 0.2204420566558838,
      "learning_rate": 0.00019499689795524926,
      "loss": 0.4013,
      "step": 1680
    },
    {
      "epoch": 0.21507428971397666,
      "grad_norm": 0.26298826932907104,
      "learning_rate": 0.00019493386902554215,
      "loss": 0.4217,
      "step": 1690
    },
    {
      "epoch": 0.21634691864719544,
      "grad_norm": 0.22609908878803253,
      "learning_rate": 0.00019487045587476321,
      "loss": 0.4052,
      "step": 1700
    },
    {
      "epoch": 0.21761954758041424,
      "grad_norm": 0.21269550919532776,
      "learning_rate": 0.00019480665875956134,
      "loss": 0.3944,
      "step": 1710
    },
    {
      "epoch": 0.21889217651363305,
      "grad_norm": 0.23284192383289337,
      "learning_rate": 0.00019474247793813937,
      "loss": 0.3936,
      "step": 1720
    },
    {
      "epoch": 0.22016480544685182,
      "grad_norm": 0.18635646998882294,
      "learning_rate": 0.0001946779136702531,
      "loss": 0.4023,
      "step": 1730
    },
    {
      "epoch": 0.22143743438007063,
      "grad_norm": 0.20451916754245758,
      "learning_rate": 0.00019461296621721026,
      "loss": 0.4081,
      "step": 1740
    },
    {
      "epoch": 0.22271006331328944,
      "grad_norm": 0.24529501795768738,
      "learning_rate": 0.0001945476358418694,
      "loss": 0.3894,
      "step": 1750
    },
    {
      "epoch": 0.2239826922465082,
      "grad_norm": 0.21096381545066833,
      "learning_rate": 0.0001944819228086389,
      "loss": 0.4155,
      "step": 1760
    },
    {
      "epoch": 0.22525532117972702,
      "grad_norm": 0.24634596705436707,
      "learning_rate": 0.00019441582738347578,
      "loss": 0.4057,
      "step": 1770
    },
    {
      "epoch": 0.22652795011294583,
      "grad_norm": 0.24112476408481598,
      "learning_rate": 0.0001943493498338847,
      "loss": 0.4325,
      "step": 1780
    },
    {
      "epoch": 0.2278005790461646,
      "grad_norm": 0.24906212091445923,
      "learning_rate": 0.00019428249042891698,
      "loss": 0.4056,
      "step": 1790
    },
    {
      "epoch": 0.2290732079793834,
      "grad_norm": 0.2655482590198517,
      "learning_rate": 0.0001942152494391692,
      "loss": 0.3924,
      "step": 1800
    },
    {
      "epoch": 0.23034583691260221,
      "grad_norm": 0.23888714611530304,
      "learning_rate": 0.0001941476271367826,
      "loss": 0.3885,
      "step": 1810
    },
    {
      "epoch": 0.231618465845821,
      "grad_norm": 0.25552305579185486,
      "learning_rate": 0.00019407962379544138,
      "loss": 0.3943,
      "step": 1820
    },
    {
      "epoch": 0.2328910947790398,
      "grad_norm": 0.20003803074359894,
      "learning_rate": 0.0001940112396903721,
      "loss": 0.4191,
      "step": 1830
    },
    {
      "epoch": 0.2341637237122586,
      "grad_norm": 0.18830619752407074,
      "learning_rate": 0.00019394247509834235,
      "loss": 0.3997,
      "step": 1840
    },
    {
      "epoch": 0.23543635264547738,
      "grad_norm": 0.23910923302173615,
      "learning_rate": 0.0001938733302976595,
      "loss": 0.3963,
      "step": 1850
    },
    {
      "epoch": 0.2367089815786962,
      "grad_norm": 0.23272450268268585,
      "learning_rate": 0.0001938038055681699,
      "loss": 0.3942,
      "step": 1860
    },
    {
      "epoch": 0.237981610511915,
      "grad_norm": 0.24083124101161957,
      "learning_rate": 0.00019373390119125752,
      "loss": 0.3908,
      "step": 1870
    },
    {
      "epoch": 0.2392542394451338,
      "grad_norm": 0.2014201581478119,
      "learning_rate": 0.00019366361744984273,
      "loss": 0.3984,
      "step": 1880
    },
    {
      "epoch": 0.24052686837835258,
      "grad_norm": 0.23154722154140472,
      "learning_rate": 0.00019359295462838142,
      "loss": 0.3727,
      "step": 1890
    },
    {
      "epoch": 0.24179949731157138,
      "grad_norm": 0.28623339533805847,
      "learning_rate": 0.00019352191301286374,
      "loss": 0.4148,
      "step": 1900
    },
    {
      "epoch": 0.2430721262447902,
      "grad_norm": 0.24948176741600037,
      "learning_rate": 0.00019345049289081273,
      "loss": 0.416,
      "step": 1910
    },
    {
      "epoch": 0.24434475517800897,
      "grad_norm": 0.2029390037059784,
      "learning_rate": 0.00019337869455128353,
      "loss": 0.3707,
      "step": 1920
    },
    {
      "epoch": 0.24561738411122777,
      "grad_norm": 0.187034472823143,
      "learning_rate": 0.00019330651828486194,
      "loss": 0.4011,
      "step": 1930
    },
    {
      "epoch": 0.24689001304444658,
      "grad_norm": 0.2661944627761841,
      "learning_rate": 0.00019323396438366332,
      "loss": 0.381,
      "step": 1940
    },
    {
      "epoch": 0.24816264197766535,
      "grad_norm": 0.18501517176628113,
      "learning_rate": 0.00019316103314133144,
      "loss": 0.386,
      "step": 1950
    },
    {
      "epoch": 0.24943527091088416,
      "grad_norm": 0.2507719397544861,
      "learning_rate": 0.0001930877248530372,
      "loss": 0.4144,
      "step": 1960
    },
    {
      "epoch": 0.25070789984410297,
      "grad_norm": 0.20468640327453613,
      "learning_rate": 0.00019301403981547763,
      "loss": 0.4014,
      "step": 1970
    },
    {
      "epoch": 0.25198052877732174,
      "grad_norm": 0.23097506165504456,
      "learning_rate": 0.0001929399783268744,
      "loss": 0.4089,
      "step": 1980
    },
    {
      "epoch": 0.2532531577105405,
      "grad_norm": 0.20117299258708954,
      "learning_rate": 0.0001928655406869729,
      "loss": 0.3752,
      "step": 1990
    },
    {
      "epoch": 0.25452578664375936,
      "grad_norm": 0.21121786534786224,
      "learning_rate": 0.00019279072719704079,
      "loss": 0.4168,
      "step": 2000
    },
    {
      "epoch": 0.25452578664375936,
      "eval_loss": 0.39577823877334595,
      "eval_runtime": 742.571,
      "eval_samples_per_second": 10.582,
      "eval_steps_per_second": 5.291,
      "step": 2000
    },
    {
      "epoch": 0.25579841557697813,
      "grad_norm": 0.2693004608154297,
      "learning_rate": 0.00019271553815986697,
      "loss": 0.4182,
      "step": 2010
    },
    {
      "epoch": 0.25707104451019697,
      "grad_norm": 0.2316908985376358,
      "learning_rate": 0.00019263997387976027,
      "loss": 0.4058,
      "step": 2020
    },
    {
      "epoch": 0.25834367344341574,
      "grad_norm": 0.20321844518184662,
      "learning_rate": 0.00019256403466254816,
      "loss": 0.4202,
      "step": 2030
    },
    {
      "epoch": 0.2596163023766345,
      "grad_norm": 0.19937798380851746,
      "learning_rate": 0.00019248772081557566,
      "loss": 0.3958,
      "step": 2040
    },
    {
      "epoch": 0.26088893130985336,
      "grad_norm": 0.24149316549301147,
      "learning_rate": 0.00019241103264770396,
      "loss": 0.4001,
      "step": 2050
    },
    {
      "epoch": 0.26216156024307213,
      "grad_norm": 0.19260382652282715,
      "learning_rate": 0.00019233397046930915,
      "loss": 0.4193,
      "step": 2060
    },
    {
      "epoch": 0.2634341891762909,
      "grad_norm": 0.2526208460330963,
      "learning_rate": 0.00019225653459228114,
      "loss": 0.3866,
      "step": 2070
    },
    {
      "epoch": 0.26470681810950974,
      "grad_norm": 0.20545078814029694,
      "learning_rate": 0.00019217872533002232,
      "loss": 0.4033,
      "step": 2080
    },
    {
      "epoch": 0.2659794470427285,
      "grad_norm": 0.17184515297412872,
      "learning_rate": 0.00019210054299744614,
      "loss": 0.3858,
      "step": 2090
    },
    {
      "epoch": 0.2672520759759473,
      "grad_norm": 0.2523062527179718,
      "learning_rate": 0.00019202198791097604,
      "loss": 0.416,
      "step": 2100
    },
    {
      "epoch": 0.26852470490916613,
      "grad_norm": 0.22076529264450073,
      "learning_rate": 0.00019194306038854407,
      "loss": 0.3964,
      "step": 2110
    },
    {
      "epoch": 0.2697973338423849,
      "grad_norm": 0.2521530091762543,
      "learning_rate": 0.00019186376074958961,
      "loss": 0.4082,
      "step": 2120
    },
    {
      "epoch": 0.2710699627756037,
      "grad_norm": 0.2639363706111908,
      "learning_rate": 0.00019178408931505816,
      "loss": 0.3857,
      "step": 2130
    },
    {
      "epoch": 0.2723425917088225,
      "grad_norm": 0.20242290198802948,
      "learning_rate": 0.0001917040464073998,
      "loss": 0.4147,
      "step": 2140
    },
    {
      "epoch": 0.2736152206420413,
      "grad_norm": 0.19346176087856293,
      "learning_rate": 0.00019162363235056826,
      "loss": 0.3913,
      "step": 2150
    },
    {
      "epoch": 0.2748878495752601,
      "grad_norm": 0.23465828597545624,
      "learning_rate": 0.00019154284747001924,
      "loss": 0.4006,
      "step": 2160
    },
    {
      "epoch": 0.2761604785084789,
      "grad_norm": 0.19822093844413757,
      "learning_rate": 0.00019146169209270934,
      "loss": 0.3986,
      "step": 2170
    },
    {
      "epoch": 0.2774331074416977,
      "grad_norm": 0.19011831283569336,
      "learning_rate": 0.00019138016654709467,
      "loss": 0.3918,
      "step": 2180
    },
    {
      "epoch": 0.27870573637491647,
      "grad_norm": 0.23173391819000244,
      "learning_rate": 0.00019129827116312945,
      "loss": 0.4276,
      "step": 2190
    },
    {
      "epoch": 0.2799783653081353,
      "grad_norm": 0.1934816539287567,
      "learning_rate": 0.00019121600627226474,
      "loss": 0.408,
      "step": 2200
    },
    {
      "epoch": 0.2812509942413541,
      "grad_norm": 0.19138363003730774,
      "learning_rate": 0.00019113337220744703,
      "loss": 0.406,
      "step": 2210
    },
    {
      "epoch": 0.28252362317457286,
      "grad_norm": 0.27997294068336487,
      "learning_rate": 0.00019105036930311715,
      "loss": 0.3726,
      "step": 2220
    },
    {
      "epoch": 0.2837962521077917,
      "grad_norm": 0.26592203974723816,
      "learning_rate": 0.00019096699789520848,
      "loss": 0.3781,
      "step": 2230
    },
    {
      "epoch": 0.28506888104101047,
      "grad_norm": 0.24085761606693268,
      "learning_rate": 0.00019088325832114598,
      "loss": 0.4086,
      "step": 2240
    },
    {
      "epoch": 0.28634150997422925,
      "grad_norm": 0.41480886936187744,
      "learning_rate": 0.00019079915091984456,
      "loss": 0.3847,
      "step": 2250
    },
    {
      "epoch": 0.2876141389074481,
      "grad_norm": 0.22448310256004333,
      "learning_rate": 0.00019071467603170789,
      "loss": 0.4098,
      "step": 2260
    },
    {
      "epoch": 0.28888676784066686,
      "grad_norm": 0.2280968576669693,
      "learning_rate": 0.00019062983399862696,
      "loss": 0.3908,
      "step": 2270
    },
    {
      "epoch": 0.29015939677388564,
      "grad_norm": 0.2080506682395935,
      "learning_rate": 0.00019054462516397865,
      "loss": 0.3999,
      "step": 2280
    },
    {
      "epoch": 0.29143202570710447,
      "grad_norm": 0.21294312179088593,
      "learning_rate": 0.00019045904987262437,
      "loss": 0.4069,
      "step": 2290
    },
    {
      "epoch": 0.29270465464032325,
      "grad_norm": 0.22519196569919586,
      "learning_rate": 0.00019037310847090874,
      "loss": 0.3633,
      "step": 2300
    },
    {
      "epoch": 0.293977283573542,
      "grad_norm": 0.23349155485630035,
      "learning_rate": 0.000190286801306658,
      "loss": 0.3668,
      "step": 2310
    },
    {
      "epoch": 0.29524991250676086,
      "grad_norm": 0.24651911854743958,
      "learning_rate": 0.00019020012872917886,
      "loss": 0.3632,
      "step": 2320
    },
    {
      "epoch": 0.29652254143997964,
      "grad_norm": 0.22930724918842316,
      "learning_rate": 0.00019011309108925682,
      "loss": 0.3998,
      "step": 2330
    },
    {
      "epoch": 0.2977951703731984,
      "grad_norm": 0.23617568612098694,
      "learning_rate": 0.00019002568873915503,
      "loss": 0.3861,
      "step": 2340
    },
    {
      "epoch": 0.29906779930641725,
      "grad_norm": 0.2565435469150543,
      "learning_rate": 0.00018993792203261253,
      "loss": 0.3658,
      "step": 2350
    },
    {
      "epoch": 0.300340428239636,
      "grad_norm": 0.2211058884859085,
      "learning_rate": 0.00018984979132484315,
      "loss": 0.408,
      "step": 2360
    },
    {
      "epoch": 0.3016130571728548,
      "grad_norm": 0.19617897272109985,
      "learning_rate": 0.00018976129697253385,
      "loss": 0.4249,
      "step": 2370
    },
    {
      "epoch": 0.30288568610607364,
      "grad_norm": 0.22090435028076172,
      "learning_rate": 0.00018967243933384336,
      "loss": 0.3692,
      "step": 2380
    },
    {
      "epoch": 0.3041583150392924,
      "grad_norm": 0.24643154442310333,
      "learning_rate": 0.00018958321876840075,
      "loss": 0.3816,
      "step": 2390
    },
    {
      "epoch": 0.3054309439725112,
      "grad_norm": 0.22587965428829193,
      "learning_rate": 0.00018949363563730394,
      "loss": 0.3971,
      "step": 2400
    },
    {
      "epoch": 0.30670357290573,
      "grad_norm": 0.2417050302028656,
      "learning_rate": 0.0001894036903031182,
      "loss": 0.4156,
      "step": 2410
    },
    {
      "epoch": 0.3079762018389488,
      "grad_norm": 0.22342409193515778,
      "learning_rate": 0.00018931338312987473,
      "loss": 0.3765,
      "step": 2420
    },
    {
      "epoch": 0.3092488307721676,
      "grad_norm": 0.2543528974056244,
      "learning_rate": 0.0001892227144830693,
      "loss": 0.402,
      "step": 2430
    },
    {
      "epoch": 0.3105214597053864,
      "grad_norm": 0.21619848906993866,
      "learning_rate": 0.0001891316847296605,
      "loss": 0.3631,
      "step": 2440
    },
    {
      "epoch": 0.3117940886386052,
      "grad_norm": 0.24276484549045563,
      "learning_rate": 0.00018904029423806847,
      "loss": 0.422,
      "step": 2450
    },
    {
      "epoch": 0.31306671757182397,
      "grad_norm": 0.17257538437843323,
      "learning_rate": 0.00018894854337817333,
      "loss": 0.3604,
      "step": 2460
    },
    {
      "epoch": 0.3143393465050428,
      "grad_norm": 0.23601123690605164,
      "learning_rate": 0.00018885643252131376,
      "loss": 0.3843,
      "step": 2470
    },
    {
      "epoch": 0.3156119754382616,
      "grad_norm": 0.2392973154783249,
      "learning_rate": 0.0001887639620402854,
      "loss": 0.393,
      "step": 2480
    },
    {
      "epoch": 0.31688460437148036,
      "grad_norm": 0.23649254441261292,
      "learning_rate": 0.00018867113230933936,
      "loss": 0.4188,
      "step": 2490
    },
    {
      "epoch": 0.3181572333046992,
      "grad_norm": 0.20507389307022095,
      "learning_rate": 0.0001885779437041807,
      "loss": 0.3845,
      "step": 2500
    },
    {
      "epoch": 0.3181572333046992,
      "eval_loss": 0.3894585371017456,
      "eval_runtime": 769.7641,
      "eval_samples_per_second": 10.208,
      "eval_steps_per_second": 5.104,
      "step": 2500
    },
    {
      "epoch": 0.31942986223791797,
      "grad_norm": 0.24647781252861023,
      "learning_rate": 0.00018848439660196705,
      "loss": 0.3826,
      "step": 2510
    },
    {
      "epoch": 0.32070249117113675,
      "grad_norm": 0.2750057876110077,
      "learning_rate": 0.00018839049138130685,
      "loss": 0.3792,
      "step": 2520
    },
    {
      "epoch": 0.3219751201043556,
      "grad_norm": 0.21671578288078308,
      "learning_rate": 0.00018829622842225793,
      "loss": 0.3847,
      "step": 2530
    },
    {
      "epoch": 0.32324774903757436,
      "grad_norm": 0.1813986599445343,
      "learning_rate": 0.00018820160810632613,
      "loss": 0.3902,
      "step": 2540
    },
    {
      "epoch": 0.32452037797079314,
      "grad_norm": 0.2456510215997696,
      "learning_rate": 0.00018810663081646341,
      "loss": 0.4178,
      "step": 2550
    },
    {
      "epoch": 0.325793006904012,
      "grad_norm": 0.1839415282011032,
      "learning_rate": 0.0001880112969370666,
      "loss": 0.3797,
      "step": 2560
    },
    {
      "epoch": 0.32706563583723075,
      "grad_norm": 0.21284392476081848,
      "learning_rate": 0.00018791560685397566,
      "loss": 0.3679,
      "step": 2570
    },
    {
      "epoch": 0.3283382647704496,
      "grad_norm": 0.22662854194641113,
      "learning_rate": 0.00018781956095447234,
      "loss": 0.3612,
      "step": 2580
    },
    {
      "epoch": 0.32961089370366836,
      "grad_norm": 0.17697295546531677,
      "learning_rate": 0.00018772315962727837,
      "loss": 0.3909,
      "step": 2590
    },
    {
      "epoch": 0.33088352263688714,
      "grad_norm": 0.18970251083374023,
      "learning_rate": 0.00018762640326255392,
      "loss": 0.3953,
      "step": 2600
    },
    {
      "epoch": 0.332156151570106,
      "grad_norm": 0.23667512834072113,
      "learning_rate": 0.0001875292922518962,
      "loss": 0.3973,
      "step": 2610
    },
    {
      "epoch": 0.33342878050332475,
      "grad_norm": 0.2279874086380005,
      "learning_rate": 0.00018743182698833776,
      "loss": 0.4004,
      "step": 2620
    },
    {
      "epoch": 0.33470140943654353,
      "grad_norm": 0.19877280294895172,
      "learning_rate": 0.00018733400786634477,
      "loss": 0.4074,
      "step": 2630
    },
    {
      "epoch": 0.33597403836976236,
      "grad_norm": 0.24495546519756317,
      "learning_rate": 0.00018723583528181567,
      "loss": 0.3831,
      "step": 2640
    },
    {
      "epoch": 0.33724666730298114,
      "grad_norm": 0.17699521780014038,
      "learning_rate": 0.00018713730963207948,
      "loss": 0.3942,
      "step": 2650
    },
    {
      "epoch": 0.3385192962361999,
      "grad_norm": 0.222665935754776,
      "learning_rate": 0.00018703843131589402,
      "loss": 0.379,
      "step": 2660
    },
    {
      "epoch": 0.33979192516941875,
      "grad_norm": 0.19851481914520264,
      "learning_rate": 0.00018693920073344455,
      "loss": 0.3855,
      "step": 2670
    },
    {
      "epoch": 0.34106455410263753,
      "grad_norm": 0.20137353241443634,
      "learning_rate": 0.00018683961828634208,
      "loss": 0.3904,
      "step": 2680
    },
    {
      "epoch": 0.3423371830358563,
      "grad_norm": 0.5832889080047607,
      "learning_rate": 0.00018673968437762155,
      "loss": 0.403,
      "step": 2690
    },
    {
      "epoch": 0.34360981196907514,
      "grad_norm": 0.1948833465576172,
      "learning_rate": 0.0001866393994117405,
      "loss": 0.384,
      "step": 2700
    },
    {
      "epoch": 0.3448824409022939,
      "grad_norm": 0.30926358699798584,
      "learning_rate": 0.00018653876379457718,
      "loss": 0.3733,
      "step": 2710
    },
    {
      "epoch": 0.3461550698355127,
      "grad_norm": 0.1962960660457611,
      "learning_rate": 0.0001864377779334291,
      "loss": 0.4024,
      "step": 2720
    },
    {
      "epoch": 0.34742769876873153,
      "grad_norm": 0.24239233136177063,
      "learning_rate": 0.0001863364422370112,
      "loss": 0.3962,
      "step": 2730
    },
    {
      "epoch": 0.3487003277019503,
      "grad_norm": 0.22882845997810364,
      "learning_rate": 0.00018623475711545444,
      "loss": 0.4105,
      "step": 2740
    },
    {
      "epoch": 0.3499729566351691,
      "grad_norm": 0.21115782856941223,
      "learning_rate": 0.0001861327229803038,
      "loss": 0.3667,
      "step": 2750
    },
    {
      "epoch": 0.3512455855683879,
      "grad_norm": 0.24703431129455566,
      "learning_rate": 0.00018603034024451697,
      "loss": 0.4133,
      "step": 2760
    },
    {
      "epoch": 0.3525182145016067,
      "grad_norm": 0.2509574592113495,
      "learning_rate": 0.00018592760932246242,
      "loss": 0.3884,
      "step": 2770
    },
    {
      "epoch": 0.3537908434348255,
      "grad_norm": 0.2462671399116516,
      "learning_rate": 0.00018582453062991781,
      "loss": 0.398,
      "step": 2780
    },
    {
      "epoch": 0.3550634723680443,
      "grad_norm": 0.20986446738243103,
      "learning_rate": 0.00018572110458406842,
      "loss": 0.3652,
      "step": 2790
    },
    {
      "epoch": 0.3563361013012631,
      "grad_norm": 0.23729313910007477,
      "learning_rate": 0.00018561733160350522,
      "loss": 0.3802,
      "step": 2800
    },
    {
      "epoch": 0.35760873023448186,
      "grad_norm": 0.15870638191699982,
      "learning_rate": 0.0001855132121082234,
      "loss": 0.3579,
      "step": 2810
    },
    {
      "epoch": 0.3588813591677007,
      "grad_norm": 0.18477067351341248,
      "learning_rate": 0.0001854087465196205,
      "loss": 0.3836,
      "step": 2820
    },
    {
      "epoch": 0.3601539881009195,
      "grad_norm": 0.20734600722789764,
      "learning_rate": 0.00018530393526049492,
      "loss": 0.3965,
      "step": 2830
    },
    {
      "epoch": 0.36142661703413825,
      "grad_norm": 0.20221978425979614,
      "learning_rate": 0.00018519877875504398,
      "loss": 0.4107,
      "step": 2840
    },
    {
      "epoch": 0.3626992459673571,
      "grad_norm": 0.23505206406116486,
      "learning_rate": 0.0001850932774288623,
      "loss": 0.3722,
      "step": 2850
    },
    {
      "epoch": 0.36397187490057586,
      "grad_norm": 0.19897915422916412,
      "learning_rate": 0.00018498743170894006,
      "loss": 0.3995,
      "step": 2860
    },
    {
      "epoch": 0.36524450383379464,
      "grad_norm": 0.2650168836116791,
      "learning_rate": 0.00018488124202366136,
      "loss": 0.3878,
      "step": 2870
    },
    {
      "epoch": 0.3665171327670135,
      "grad_norm": 0.20339332520961761,
      "learning_rate": 0.00018477470880280233,
      "loss": 0.404,
      "step": 2880
    },
    {
      "epoch": 0.36778976170023225,
      "grad_norm": 0.2068691998720169,
      "learning_rate": 0.00018466783247752958,
      "loss": 0.387,
      "step": 2890
    },
    {
      "epoch": 0.36906239063345103,
      "grad_norm": 0.24014592170715332,
      "learning_rate": 0.0001845606134803982,
      "loss": 0.3917,
      "step": 2900
    },
    {
      "epoch": 0.37033501956666987,
      "grad_norm": 0.20035716891288757,
      "learning_rate": 0.0001844530522453503,
      "loss": 0.3756,
      "step": 2910
    },
    {
      "epoch": 0.37160764849988864,
      "grad_norm": 0.2427075058221817,
      "learning_rate": 0.00018434514920771306,
      "loss": 0.392,
      "step": 2920
    },
    {
      "epoch": 0.3728802774331074,
      "grad_norm": 0.4660325050354004,
      "learning_rate": 0.00018423690480419698,
      "loss": 0.4013,
      "step": 2930
    },
    {
      "epoch": 0.37415290636632625,
      "grad_norm": 0.23003028333187103,
      "learning_rate": 0.00018412831947289422,
      "loss": 0.3884,
      "step": 2940
    },
    {
      "epoch": 0.37542553529954503,
      "grad_norm": 0.2583659291267395,
      "learning_rate": 0.0001840193936532767,
      "loss": 0.3809,
      "step": 2950
    },
    {
      "epoch": 0.3766981642327638,
      "grad_norm": 0.22524872422218323,
      "learning_rate": 0.0001839101277861944,
      "loss": 0.3971,
      "step": 2960
    },
    {
      "epoch": 0.37797079316598264,
      "grad_norm": 0.26137861609458923,
      "learning_rate": 0.00018380052231387363,
      "loss": 0.3739,
      "step": 2970
    },
    {
      "epoch": 0.3792434220992014,
      "grad_norm": 0.18095643818378448,
      "learning_rate": 0.00018369057767991508,
      "loss": 0.3752,
      "step": 2980
    },
    {
      "epoch": 0.3805160510324202,
      "grad_norm": 0.17804598808288574,
      "learning_rate": 0.00018358029432929206,
      "loss": 0.3897,
      "step": 2990
    },
    {
      "epoch": 0.38178867996563903,
      "grad_norm": 0.20743094384670258,
      "learning_rate": 0.00018346967270834892,
      "loss": 0.3695,
      "step": 3000
    },
    {
      "epoch": 0.38178867996563903,
      "eval_loss": 0.38506466150283813,
      "eval_runtime": 760.3086,
      "eval_samples_per_second": 10.335,
      "eval_steps_per_second": 5.168,
      "step": 3000
    },
    {
      "epoch": 0.3830613088988578,
      "grad_norm": 0.23969925940036774,
      "learning_rate": 0.00018335871326479892,
      "loss": 0.3843,
      "step": 3010
    },
    {
      "epoch": 0.3843339378320766,
      "grad_norm": 0.19784630835056305,
      "learning_rate": 0.00018324741644772268,
      "loss": 0.3807,
      "step": 3020
    },
    {
      "epoch": 0.3856065667652954,
      "grad_norm": 0.25202497839927673,
      "learning_rate": 0.00018313578270756617,
      "loss": 0.394,
      "step": 3030
    },
    {
      "epoch": 0.3868791956985142,
      "grad_norm": 0.21774348616600037,
      "learning_rate": 0.000183023812496139,
      "loss": 0.3528,
      "step": 3040
    },
    {
      "epoch": 0.388151824631733,
      "grad_norm": 0.1903434842824936,
      "learning_rate": 0.00018291150626661268,
      "loss": 0.3787,
      "step": 3050
    },
    {
      "epoch": 0.3894244535649518,
      "grad_norm": 0.24000698328018188,
      "learning_rate": 0.00018279886447351845,
      "loss": 0.3962,
      "step": 3060
    },
    {
      "epoch": 0.3906970824981706,
      "grad_norm": 0.2130916863679886,
      "learning_rate": 0.00018268588757274577,
      "loss": 0.3743,
      "step": 3070
    },
    {
      "epoch": 0.39196971143138937,
      "grad_norm": 0.22332748770713806,
      "learning_rate": 0.00018257257602154043,
      "loss": 0.4076,
      "step": 3080
    },
    {
      "epoch": 0.3932423403646082,
      "grad_norm": 0.20550625026226044,
      "learning_rate": 0.00018245893027850254,
      "loss": 0.388,
      "step": 3090
    },
    {
      "epoch": 0.394514969297827,
      "grad_norm": 0.19417135417461395,
      "learning_rate": 0.0001823449508035848,
      "loss": 0.3896,
      "step": 3100
    },
    {
      "epoch": 0.39578759823104576,
      "grad_norm": 0.1819247007369995,
      "learning_rate": 0.0001822306380580906,
      "loss": 0.4013,
      "step": 3110
    },
    {
      "epoch": 0.3970602271642646,
      "grad_norm": 0.23271240293979645,
      "learning_rate": 0.00018211599250467217,
      "loss": 0.359,
      "step": 3120
    },
    {
      "epoch": 0.39833285609748337,
      "grad_norm": 0.2018502801656723,
      "learning_rate": 0.0001820010146073287,
      "loss": 0.3804,
      "step": 3130
    },
    {
      "epoch": 0.39960548503070215,
      "grad_norm": 0.40238621830940247,
      "learning_rate": 0.00018188570483140438,
      "loss": 0.3968,
      "step": 3140
    },
    {
      "epoch": 0.400878113963921,
      "grad_norm": 0.2140299528837204,
      "learning_rate": 0.00018177006364358678,
      "loss": 0.3877,
      "step": 3150
    },
    {
      "epoch": 0.40215074289713976,
      "grad_norm": 0.21526485681533813,
      "learning_rate": 0.0001816540915119046,
      "loss": 0.3842,
      "step": 3160
    },
    {
      "epoch": 0.4034233718303586,
      "grad_norm": 0.2873081564903259,
      "learning_rate": 0.00018153778890572596,
      "loss": 0.3741,
      "step": 3170
    },
    {
      "epoch": 0.40469600076357737,
      "grad_norm": 0.19644682109355927,
      "learning_rate": 0.00018142115629575666,
      "loss": 0.3925,
      "step": 3180
    },
    {
      "epoch": 0.40596862969679615,
      "grad_norm": 0.24827983975410461,
      "learning_rate": 0.00018130419415403792,
      "loss": 0.3851,
      "step": 3190
    },
    {
      "epoch": 0.407241258630015,
      "grad_norm": 0.17912434041500092,
      "learning_rate": 0.00018118690295394475,
      "loss": 0.3703,
      "step": 3200
    },
    {
      "epoch": 0.40851388756323376,
      "grad_norm": 0.22432121634483337,
      "learning_rate": 0.00018106928317018395,
      "loss": 0.3859,
      "step": 3210
    },
    {
      "epoch": 0.40978651649645254,
      "grad_norm": 0.24235861003398895,
      "learning_rate": 0.00018095133527879206,
      "loss": 0.3816,
      "step": 3220
    },
    {
      "epoch": 0.41105914542967137,
      "grad_norm": 0.30791303515434265,
      "learning_rate": 0.00018083305975713377,
      "loss": 0.3678,
      "step": 3230
    },
    {
      "epoch": 0.41233177436289015,
      "grad_norm": 0.21959301829338074,
      "learning_rate": 0.00018071445708389957,
      "loss": 0.3795,
      "step": 3240
    },
    {
      "epoch": 0.4136044032961089,
      "grad_norm": 0.22264376282691956,
      "learning_rate": 0.0001805955277391041,
      "loss": 0.3744,
      "step": 3250
    },
    {
      "epoch": 0.41487703222932776,
      "grad_norm": 0.16231146454811096,
      "learning_rate": 0.00018047627220408417,
      "loss": 0.3918,
      "step": 3260
    },
    {
      "epoch": 0.41614966116254654,
      "grad_norm": 0.20379520952701569,
      "learning_rate": 0.0001803566909614966,
      "loss": 0.3895,
      "step": 3270
    },
    {
      "epoch": 0.4174222900957653,
      "grad_norm": 0.30021801590919495,
      "learning_rate": 0.00018023678449531665,
      "loss": 0.3788,
      "step": 3280
    },
    {
      "epoch": 0.41869491902898415,
      "grad_norm": 0.20279823243618011,
      "learning_rate": 0.00018011655329083564,
      "loss": 0.3748,
      "step": 3290
    },
    {
      "epoch": 0.4199675479622029,
      "grad_norm": 0.23273596167564392,
      "learning_rate": 0.00017999599783465934,
      "loss": 0.3854,
      "step": 3300
    },
    {
      "epoch": 0.4212401768954217,
      "grad_norm": 0.17140251398086548,
      "learning_rate": 0.00017987511861470575,
      "loss": 0.3891,
      "step": 3310
    },
    {
      "epoch": 0.42251280582864054,
      "grad_norm": 0.18761231005191803,
      "learning_rate": 0.00017975391612020324,
      "loss": 0.3835,
      "step": 3320
    },
    {
      "epoch": 0.4237854347618593,
      "grad_norm": 0.2712923586368561,
      "learning_rate": 0.0001796323908416886,
      "loss": 0.3651,
      "step": 3330
    },
    {
      "epoch": 0.4250580636950781,
      "grad_norm": 0.21804848313331604,
      "learning_rate": 0.00017951054327100497,
      "loss": 0.3878,
      "step": 3340
    },
    {
      "epoch": 0.4263306926282969,
      "grad_norm": 0.25450944900512695,
      "learning_rate": 0.0001793883739012999,
      "loss": 0.3876,
      "step": 3350
    },
    {
      "epoch": 0.4276033215615157,
      "grad_norm": 0.21838313341140747,
      "learning_rate": 0.00017926588322702327,
      "loss": 0.3666,
      "step": 3360
    },
    {
      "epoch": 0.4288759504947345,
      "grad_norm": 0.18352927267551422,
      "learning_rate": 0.00017914307174392554,
      "loss": 0.3994,
      "step": 3370
    },
    {
      "epoch": 0.4301485794279533,
      "grad_norm": 0.175741508603096,
      "learning_rate": 0.0001790199399490553,
      "loss": 0.3862,
      "step": 3380
    },
    {
      "epoch": 0.4314212083611721,
      "grad_norm": 0.21561138331890106,
      "learning_rate": 0.00017889648834075778,
      "loss": 0.4118,
      "step": 3390
    },
    {
      "epoch": 0.43269383729439087,
      "grad_norm": 0.19962304830551147,
      "learning_rate": 0.00017877271741867246,
      "loss": 0.3953,
      "step": 3400
    },
    {
      "epoch": 0.4339664662276097,
      "grad_norm": 0.24710825085639954,
      "learning_rate": 0.0001786486276837311,
      "loss": 0.3893,
      "step": 3410
    },
    {
      "epoch": 0.4352390951608285,
      "grad_norm": 0.2212747037410736,
      "learning_rate": 0.00017852421963815592,
      "loss": 0.3795,
      "step": 3420
    },
    {
      "epoch": 0.43651172409404726,
      "grad_norm": 0.24682828783988953,
      "learning_rate": 0.00017839949378545725,
      "loss": 0.3708,
      "step": 3430
    },
    {
      "epoch": 0.4377843530272661,
      "grad_norm": 0.1947704255580902,
      "learning_rate": 0.00017827445063043186,
      "loss": 0.3739,
      "step": 3440
    },
    {
      "epoch": 0.43905698196048487,
      "grad_norm": 0.21031111478805542,
      "learning_rate": 0.00017814909067916056,
      "loss": 0.3747,
      "step": 3450
    },
    {
      "epoch": 0.44032961089370365,
      "grad_norm": 0.1867615282535553,
      "learning_rate": 0.00017802341443900636,
      "loss": 0.3919,
      "step": 3460
    },
    {
      "epoch": 0.4416022398269225,
      "grad_norm": 0.3112953007221222,
      "learning_rate": 0.0001778974224186124,
      "loss": 0.4108,
      "step": 3470
    },
    {
      "epoch": 0.44287486876014126,
      "grad_norm": 0.281484454870224,
      "learning_rate": 0.00017777111512789988,
      "loss": 0.3833,
      "step": 3480
    },
    {
      "epoch": 0.44414749769336004,
      "grad_norm": 0.17882467806339264,
      "learning_rate": 0.0001776444930780659,
      "loss": 0.3796,
      "step": 3490
    },
    {
      "epoch": 0.44542012662657887,
      "grad_norm": 0.17032252252101898,
      "learning_rate": 0.00017751755678158153,
      "loss": 0.3817,
      "step": 3500
    },
    {
      "epoch": 0.44542012662657887,
      "eval_loss": 0.38155239820480347,
      "eval_runtime": 753.018,
      "eval_samples_per_second": 10.435,
      "eval_steps_per_second": 5.218,
      "step": 3500
    },
    {
      "epoch": 0.44669275555979765,
      "grad_norm": 0.24431566894054413,
      "learning_rate": 0.00017739030675218963,
      "loss": 0.369,
      "step": 3510
    },
    {
      "epoch": 0.4479653844930164,
      "grad_norm": 0.18131214380264282,
      "learning_rate": 0.0001772627435049029,
      "loss": 0.3909,
      "step": 3520
    },
    {
      "epoch": 0.44923801342623526,
      "grad_norm": 0.25850602984428406,
      "learning_rate": 0.0001771348675560016,
      "loss": 0.4065,
      "step": 3530
    },
    {
      "epoch": 0.45051064235945404,
      "grad_norm": 0.19667208194732666,
      "learning_rate": 0.00017700667942303168,
      "loss": 0.3723,
      "step": 3540
    },
    {
      "epoch": 0.4517832712926728,
      "grad_norm": 0.20758533477783203,
      "learning_rate": 0.00017687817962480244,
      "loss": 0.3875,
      "step": 3550
    },
    {
      "epoch": 0.45305590022589165,
      "grad_norm": 0.19644862413406372,
      "learning_rate": 0.0001767493686813847,
      "loss": 0.3834,
      "step": 3560
    },
    {
      "epoch": 0.45432852915911043,
      "grad_norm": 0.19308310747146606,
      "learning_rate": 0.00017662024711410853,
      "loss": 0.3746,
      "step": 3570
    },
    {
      "epoch": 0.4556011580923292,
      "grad_norm": 0.23042963445186615,
      "learning_rate": 0.00017649081544556108,
      "loss": 0.3894,
      "step": 3580
    },
    {
      "epoch": 0.45687378702554804,
      "grad_norm": 0.18356165289878845,
      "learning_rate": 0.0001763610741995847,
      "loss": 0.3873,
      "step": 3590
    },
    {
      "epoch": 0.4581464159587668,
      "grad_norm": 0.266925185918808,
      "learning_rate": 0.0001762310239012746,
      "loss": 0.3873,
      "step": 3600
    },
    {
      "epoch": 0.4594190448919856,
      "grad_norm": 0.17228378355503082,
      "learning_rate": 0.00017610066507697675,
      "loss": 0.3781,
      "step": 3610
    },
    {
      "epoch": 0.46069167382520443,
      "grad_norm": 0.25054988265037537,
      "learning_rate": 0.00017596999825428595,
      "loss": 0.3845,
      "step": 3620
    },
    {
      "epoch": 0.4619643027584232,
      "grad_norm": 0.24068205058574677,
      "learning_rate": 0.00017583902396204338,
      "loss": 0.3752,
      "step": 3630
    },
    {
      "epoch": 0.463236931691642,
      "grad_norm": 0.2007785439491272,
      "learning_rate": 0.00017570774273033474,
      "loss": 0.3609,
      "step": 3640
    },
    {
      "epoch": 0.4645095606248608,
      "grad_norm": 0.19719383120536804,
      "learning_rate": 0.00017557615509048797,
      "loss": 0.3818,
      "step": 3650
    },
    {
      "epoch": 0.4657821895580796,
      "grad_norm": 0.2023475170135498,
      "learning_rate": 0.00017544426157507106,
      "loss": 0.3588,
      "step": 3660
    },
    {
      "epoch": 0.4670548184912984,
      "grad_norm": 0.20740288496017456,
      "learning_rate": 0.00017531206271789,
      "loss": 0.3876,
      "step": 3670
    },
    {
      "epoch": 0.4683274474245172,
      "grad_norm": 0.25285083055496216,
      "learning_rate": 0.00017517955905398664,
      "loss": 0.3818,
      "step": 3680
    },
    {
      "epoch": 0.469600076357736,
      "grad_norm": 0.22269509732723236,
      "learning_rate": 0.00017504675111963631,
      "loss": 0.3821,
      "step": 3690
    },
    {
      "epoch": 0.47087270529095476,
      "grad_norm": 0.18055453896522522,
      "learning_rate": 0.00017491363945234593,
      "loss": 0.4028,
      "step": 3700
    },
    {
      "epoch": 0.4721453342241736,
      "grad_norm": 0.19619052112102509,
      "learning_rate": 0.00017478022459085167,
      "loss": 0.3531,
      "step": 3710
    },
    {
      "epoch": 0.4734179631573924,
      "grad_norm": 0.1851343959569931,
      "learning_rate": 0.00017464650707511674,
      "loss": 0.3589,
      "step": 3720
    },
    {
      "epoch": 0.4746905920906112,
      "grad_norm": 0.2048233151435852,
      "learning_rate": 0.0001745124874463293,
      "loss": 0.3735,
      "step": 3730
    },
    {
      "epoch": 0.47596322102383,
      "grad_norm": 0.1963258981704712,
      "learning_rate": 0.00017437816624690032,
      "loss": 0.3894,
      "step": 3740
    },
    {
      "epoch": 0.47723584995704876,
      "grad_norm": 0.18115928769111633,
      "learning_rate": 0.0001742435440204612,
      "loss": 0.3667,
      "step": 3750
    },
    {
      "epoch": 0.4785084788902676,
      "grad_norm": 0.2147817313671112,
      "learning_rate": 0.00017410862131186168,
      "loss": 0.3981,
      "step": 3760
    },
    {
      "epoch": 0.4797811078234864,
      "grad_norm": 0.20713986456394196,
      "learning_rate": 0.00017397339866716767,
      "loss": 0.3964,
      "step": 3770
    },
    {
      "epoch": 0.48105373675670515,
      "grad_norm": 0.20480352640151978,
      "learning_rate": 0.00017383787663365898,
      "loss": 0.4013,
      "step": 3780
    },
    {
      "epoch": 0.482326365689924,
      "grad_norm": 0.21935442090034485,
      "learning_rate": 0.00017370205575982715,
      "loss": 0.3607,
      "step": 3790
    },
    {
      "epoch": 0.48359899462314276,
      "grad_norm": 0.20642127096652985,
      "learning_rate": 0.00017356593659537307,
      "loss": 0.3944,
      "step": 3800
    },
    {
      "epoch": 0.48487162355636154,
      "grad_norm": 0.22035925090312958,
      "learning_rate": 0.0001734295196912051,
      "loss": 0.3784,
      "step": 3810
    },
    {
      "epoch": 0.4861442524895804,
      "grad_norm": 0.24531851708889008,
      "learning_rate": 0.00017329280559943644,
      "loss": 0.381,
      "step": 3820
    },
    {
      "epoch": 0.48741688142279915,
      "grad_norm": 0.17115730047225952,
      "learning_rate": 0.00017315579487338316,
      "loss": 0.3858,
      "step": 3830
    },
    {
      "epoch": 0.48868951035601793,
      "grad_norm": 0.2249041050672531,
      "learning_rate": 0.00017301848806756194,
      "loss": 0.3715,
      "step": 3840
    },
    {
      "epoch": 0.48996213928923676,
      "grad_norm": 0.22486257553100586,
      "learning_rate": 0.00017288088573768763,
      "loss": 0.3754,
      "step": 3850
    },
    {
      "epoch": 0.49123476822245554,
      "grad_norm": 0.23398147523403168,
      "learning_rate": 0.00017274298844067128,
      "loss": 0.3851,
      "step": 3860
    },
    {
      "epoch": 0.4925073971556743,
      "grad_norm": 0.20500199496746063,
      "learning_rate": 0.00017260479673461763,
      "loss": 0.3667,
      "step": 3870
    },
    {
      "epoch": 0.49378002608889315,
      "grad_norm": 0.179521843791008,
      "learning_rate": 0.00017246631117882302,
      "loss": 0.3525,
      "step": 3880
    },
    {
      "epoch": 0.49505265502211193,
      "grad_norm": 0.21601291000843048,
      "learning_rate": 0.00017232753233377315,
      "loss": 0.3731,
      "step": 3890
    },
    {
      "epoch": 0.4963252839553307,
      "grad_norm": 0.2483818680047989,
      "learning_rate": 0.00017218846076114054,
      "loss": 0.4098,
      "step": 3900
    },
    {
      "epoch": 0.49759791288854954,
      "grad_norm": 0.20289571583271027,
      "learning_rate": 0.00017204909702378266,
      "loss": 0.4061,
      "step": 3910
    },
    {
      "epoch": 0.4988705418217683,
      "grad_norm": 0.19054432213306427,
      "learning_rate": 0.00017190944168573932,
      "loss": 0.3803,
      "step": 3920
    },
    {
      "epoch": 0.5001431707549872,
      "grad_norm": 0.25913387537002563,
      "learning_rate": 0.00017176949531223058,
      "loss": 0.3812,
      "step": 3930
    },
    {
      "epoch": 0.5014157996882059,
      "grad_norm": 0.2511399984359741,
      "learning_rate": 0.00017162925846965428,
      "loss": 0.3639,
      "step": 3940
    },
    {
      "epoch": 0.5026884286214247,
      "grad_norm": 0.22832521796226501,
      "learning_rate": 0.00017148873172558398,
      "loss": 0.3878,
      "step": 3950
    },
    {
      "epoch": 0.5039610575546435,
      "grad_norm": 0.23992812633514404,
      "learning_rate": 0.00017134791564876652,
      "loss": 0.3679,
      "step": 3960
    },
    {
      "epoch": 0.5052336864878623,
      "grad_norm": 0.26631245017051697,
      "learning_rate": 0.0001712068108091197,
      "loss": 0.3943,
      "step": 3970
    },
    {
      "epoch": 0.506506315421081,
      "grad_norm": 0.20602543652057648,
      "learning_rate": 0.00017106541777773003,
      "loss": 0.3551,
      "step": 3980
    },
    {
      "epoch": 0.5077789443542999,
      "grad_norm": 0.17400890588760376,
      "learning_rate": 0.00017092373712685043,
      "loss": 0.3729,
      "step": 3990
    },
    {
      "epoch": 0.5090515732875187,
      "grad_norm": 0.2492792010307312,
      "learning_rate": 0.00017078176942989786,
      "loss": 0.3883,
      "step": 4000
    },
    {
      "epoch": 0.5090515732875187,
      "eval_loss": 0.37659749388694763,
      "eval_runtime": 756.0742,
      "eval_samples_per_second": 10.393,
      "eval_steps_per_second": 5.197,
      "step": 4000
    },
    {
      "epoch": 0.5103242022207375,
      "grad_norm": 0.23218537867069244,
      "learning_rate": 0.00017063951526145106,
      "loss": 0.3818,
      "step": 4010
    },
    {
      "epoch": 0.5115968311539563,
      "grad_norm": 0.18294771015644073,
      "learning_rate": 0.00017049697519724814,
      "loss": 0.4037,
      "step": 4020
    },
    {
      "epoch": 0.512869460087175,
      "grad_norm": 0.2451658844947815,
      "learning_rate": 0.00017035414981418434,
      "loss": 0.3696,
      "step": 4030
    },
    {
      "epoch": 0.5141420890203939,
      "grad_norm": 0.22461465001106262,
      "learning_rate": 0.00017021103969030966,
      "loss": 0.3792,
      "step": 4040
    },
    {
      "epoch": 0.5154147179536127,
      "grad_norm": 0.20074908435344696,
      "learning_rate": 0.00017006764540482646,
      "loss": 0.3658,
      "step": 4050
    },
    {
      "epoch": 0.5166873468868315,
      "grad_norm": 0.21290361881256104,
      "learning_rate": 0.0001699239675380873,
      "loss": 0.3679,
      "step": 4060
    },
    {
      "epoch": 0.5179599758200503,
      "grad_norm": 0.2439873367547989,
      "learning_rate": 0.00016978000667159228,
      "loss": 0.3889,
      "step": 4070
    },
    {
      "epoch": 0.519232604753269,
      "grad_norm": 0.18213123083114624,
      "learning_rate": 0.00016963576338798706,
      "loss": 0.3753,
      "step": 4080
    },
    {
      "epoch": 0.5205052336864878,
      "grad_norm": 0.1632910668849945,
      "learning_rate": 0.00016949123827106018,
      "loss": 0.3696,
      "step": 4090
    },
    {
      "epoch": 0.5217778626197067,
      "grad_norm": 0.2115093320608139,
      "learning_rate": 0.00016934643190574087,
      "loss": 0.3918,
      "step": 4100
    },
    {
      "epoch": 0.5230504915529255,
      "grad_norm": 0.3363594114780426,
      "learning_rate": 0.00016920134487809666,
      "loss": 0.3616,
      "step": 4110
    },
    {
      "epoch": 0.5243231204861443,
      "grad_norm": 0.1820015162229538,
      "learning_rate": 0.00016905597777533098,
      "loss": 0.3706,
      "step": 4120
    },
    {
      "epoch": 0.525595749419363,
      "grad_norm": 0.1880275309085846,
      "learning_rate": 0.0001689103311857808,
      "loss": 0.3795,
      "step": 4130
    },
    {
      "epoch": 0.5268683783525818,
      "grad_norm": 0.20771847665309906,
      "learning_rate": 0.00016876440569891417,
      "loss": 0.3757,
      "step": 4140
    },
    {
      "epoch": 0.5281410072858006,
      "grad_norm": 0.20232202112674713,
      "learning_rate": 0.00016861820190532806,
      "loss": 0.387,
      "step": 4150
    },
    {
      "epoch": 0.5294136362190195,
      "grad_norm": 0.253665566444397,
      "learning_rate": 0.0001684717203967457,
      "loss": 0.3655,
      "step": 4160
    },
    {
      "epoch": 0.5306862651522383,
      "grad_norm": 0.22241438925266266,
      "learning_rate": 0.00016832496176601432,
      "loss": 0.3603,
      "step": 4170
    },
    {
      "epoch": 0.531958894085457,
      "grad_norm": 0.20423577725887299,
      "learning_rate": 0.00016817792660710272,
      "loss": 0.3444,
      "step": 4180
    },
    {
      "epoch": 0.5332315230186758,
      "grad_norm": 0.23929087817668915,
      "learning_rate": 0.00016803061551509896,
      "loss": 0.3739,
      "step": 4190
    },
    {
      "epoch": 0.5345041519518946,
      "grad_norm": 0.22925755381584167,
      "learning_rate": 0.00016788302908620774,
      "loss": 0.366,
      "step": 4200
    },
    {
      "epoch": 0.5357767808851134,
      "grad_norm": 0.23354722559452057,
      "learning_rate": 0.00016773516791774825,
      "loss": 0.3886,
      "step": 4210
    },
    {
      "epoch": 0.5370494098183323,
      "grad_norm": 0.21168950200080872,
      "learning_rate": 0.00016758703260815152,
      "loss": 0.3705,
      "step": 4220
    },
    {
      "epoch": 0.538322038751551,
      "grad_norm": 0.2067067176103592,
      "learning_rate": 0.00016743862375695815,
      "loss": 0.3873,
      "step": 4230
    },
    {
      "epoch": 0.5395946676847698,
      "grad_norm": 0.22793112695217133,
      "learning_rate": 0.0001672899419648158,
      "loss": 0.3923,
      "step": 4240
    },
    {
      "epoch": 0.5408672966179886,
      "grad_norm": 0.2370862513780594,
      "learning_rate": 0.00016714098783347683,
      "loss": 0.3866,
      "step": 4250
    },
    {
      "epoch": 0.5421399255512074,
      "grad_norm": 0.2871617376804352,
      "learning_rate": 0.00016699176196579578,
      "loss": 0.3749,
      "step": 4260
    },
    {
      "epoch": 0.5434125544844262,
      "grad_norm": 0.2052881121635437,
      "learning_rate": 0.00016684226496572704,
      "loss": 0.3818,
      "step": 4270
    },
    {
      "epoch": 0.544685183417645,
      "grad_norm": 0.17605938017368317,
      "learning_rate": 0.00016669249743832225,
      "loss": 0.3642,
      "step": 4280
    },
    {
      "epoch": 0.5459578123508638,
      "grad_norm": 0.21874938905239105,
      "learning_rate": 0.00016654245998972802,
      "loss": 0.3952,
      "step": 4290
    },
    {
      "epoch": 0.5472304412840826,
      "grad_norm": 0.20917847752571106,
      "learning_rate": 0.00016639215322718332,
      "loss": 0.3834,
      "step": 4300
    },
    {
      "epoch": 0.5485030702173014,
      "grad_norm": 0.22851748764514923,
      "learning_rate": 0.0001662415777590172,
      "loss": 0.3689,
      "step": 4310
    },
    {
      "epoch": 0.5497756991505202,
      "grad_norm": 0.23121052980422974,
      "learning_rate": 0.00016609073419464614,
      "loss": 0.3682,
      "step": 4320
    },
    {
      "epoch": 0.5510483280837389,
      "grad_norm": 0.19836902618408203,
      "learning_rate": 0.0001659396231445717,
      "loss": 0.3843,
      "step": 4330
    },
    {
      "epoch": 0.5523209570169578,
      "grad_norm": 0.2574593722820282,
      "learning_rate": 0.00016578824522037812,
      "loss": 0.3835,
      "step": 4340
    },
    {
      "epoch": 0.5535935859501766,
      "grad_norm": 0.19662289321422577,
      "learning_rate": 0.00016563660103472954,
      "loss": 0.3671,
      "step": 4350
    },
    {
      "epoch": 0.5548662148833954,
      "grad_norm": 0.1907922625541687,
      "learning_rate": 0.00016548469120136793,
      "loss": 0.3833,
      "step": 4360
    },
    {
      "epoch": 0.5561388438166142,
      "grad_norm": 0.22953307628631592,
      "learning_rate": 0.00016533251633511027,
      "loss": 0.3736,
      "step": 4370
    },
    {
      "epoch": 0.5574114727498329,
      "grad_norm": 0.22681862115859985,
      "learning_rate": 0.00016518007705184623,
      "loss": 0.3686,
      "step": 4380
    },
    {
      "epoch": 0.5586841016830517,
      "grad_norm": 0.19242379069328308,
      "learning_rate": 0.00016502737396853568,
      "loss": 0.3699,
      "step": 4390
    },
    {
      "epoch": 0.5599567306162706,
      "grad_norm": 0.20765669643878937,
      "learning_rate": 0.00016487440770320612,
      "loss": 0.3784,
      "step": 4400
    },
    {
      "epoch": 0.5612293595494894,
      "grad_norm": 0.17900581657886505,
      "learning_rate": 0.00016472117887495022,
      "loss": 0.3475,
      "step": 4410
    },
    {
      "epoch": 0.5625019884827082,
      "grad_norm": 0.20428335666656494,
      "learning_rate": 0.0001645676881039233,
      "loss": 0.411,
      "step": 4420
    },
    {
      "epoch": 0.5637746174159269,
      "grad_norm": 0.2554815411567688,
      "learning_rate": 0.00016441393601134086,
      "loss": 0.3923,
      "step": 4430
    },
    {
      "epoch": 0.5650472463491457,
      "grad_norm": 0.19997002184391022,
      "learning_rate": 0.00016425992321947598,
      "loss": 0.3905,
      "step": 4440
    },
    {
      "epoch": 0.5663198752823645,
      "grad_norm": 0.2590070366859436,
      "learning_rate": 0.0001641056503516569,
      "loss": 0.3839,
      "step": 4450
    },
    {
      "epoch": 0.5675925042155834,
      "grad_norm": 0.21575358510017395,
      "learning_rate": 0.00016395111803226443,
      "loss": 0.3712,
      "step": 4460
    },
    {
      "epoch": 0.5688651331488022,
      "grad_norm": 0.20771123468875885,
      "learning_rate": 0.00016379632688672942,
      "loss": 0.386,
      "step": 4470
    },
    {
      "epoch": 0.5701377620820209,
      "grad_norm": 0.21679162979125977,
      "learning_rate": 0.00016364127754153033,
      "loss": 0.3775,
      "step": 4480
    },
    {
      "epoch": 0.5714103910152397,
      "grad_norm": 0.28850165009498596,
      "learning_rate": 0.00016348597062419056,
      "loss": 0.3795,
      "step": 4490
    },
    {
      "epoch": 0.5726830199484585,
      "grad_norm": 0.27128008008003235,
      "learning_rate": 0.00016333040676327597,
      "loss": 0.3616,
      "step": 4500
    },
    {
      "epoch": 0.5726830199484585,
      "eval_loss": 0.3734498620033264,
      "eval_runtime": 757.5461,
      "eval_samples_per_second": 10.373,
      "eval_steps_per_second": 5.186,
      "step": 4500
    },
    {
      "epoch": 0.5739556488816773,
      "grad_norm": 0.19674964249134064,
      "learning_rate": 0.00016317458658839237,
      "loss": 0.3672,
      "step": 4510
    },
    {
      "epoch": 0.5752282778148962,
      "grad_norm": 0.19526803493499756,
      "learning_rate": 0.00016301851073018293,
      "loss": 0.3662,
      "step": 4520
    },
    {
      "epoch": 0.5765009067481149,
      "grad_norm": 0.2086932510137558,
      "learning_rate": 0.00016286217982032557,
      "loss": 0.382,
      "step": 4530
    },
    {
      "epoch": 0.5777735356813337,
      "grad_norm": 0.2643648386001587,
      "learning_rate": 0.00016270559449153054,
      "loss": 0.3724,
      "step": 4540
    },
    {
      "epoch": 0.5790461646145525,
      "grad_norm": 0.20466318726539612,
      "learning_rate": 0.00016254875537753777,
      "loss": 0.3689,
      "step": 4550
    },
    {
      "epoch": 0.5803187935477713,
      "grad_norm": 0.21608737111091614,
      "learning_rate": 0.0001623916631131143,
      "loss": 0.3701,
      "step": 4560
    },
    {
      "epoch": 0.58159142248099,
      "grad_norm": 0.24503962695598602,
      "learning_rate": 0.00016223431833405175,
      "loss": 0.3923,
      "step": 4570
    },
    {
      "epoch": 0.5828640514142089,
      "grad_norm": 0.20421543717384338,
      "learning_rate": 0.00016207672167716373,
      "loss": 0.3493,
      "step": 4580
    },
    {
      "epoch": 0.5841366803474277,
      "grad_norm": 0.19061747193336487,
      "learning_rate": 0.00016191887378028328,
      "loss": 0.3624,
      "step": 4590
    },
    {
      "epoch": 0.5854093092806465,
      "grad_norm": 0.17338848114013672,
      "learning_rate": 0.00016176077528226023,
      "loss": 0.3682,
      "step": 4600
    },
    {
      "epoch": 0.5866819382138653,
      "grad_norm": 0.26598888635635376,
      "learning_rate": 0.00016160242682295868,
      "loss": 0.3657,
      "step": 4610
    },
    {
      "epoch": 0.587954567147084,
      "grad_norm": 0.1878444105386734,
      "learning_rate": 0.0001614438290432544,
      "loss": 0.3711,
      "step": 4620
    },
    {
      "epoch": 0.5892271960803029,
      "grad_norm": 0.2806274890899658,
      "learning_rate": 0.00016128498258503215,
      "loss": 0.4062,
      "step": 4630
    },
    {
      "epoch": 0.5904998250135217,
      "grad_norm": 0.18684032559394836,
      "learning_rate": 0.00016112588809118328,
      "loss": 0.3725,
      "step": 4640
    },
    {
      "epoch": 0.5917724539467405,
      "grad_norm": 0.17239420115947723,
      "learning_rate": 0.0001609665462056029,
      "loss": 0.3657,
      "step": 4650
    },
    {
      "epoch": 0.5930450828799593,
      "grad_norm": 0.15960374474525452,
      "learning_rate": 0.00016080695757318737,
      "loss": 0.3516,
      "step": 4660
    },
    {
      "epoch": 0.594317711813178,
      "grad_norm": 0.22188995778560638,
      "learning_rate": 0.00016064712283983182,
      "loss": 0.3967,
      "step": 4670
    },
    {
      "epoch": 0.5955903407463968,
      "grad_norm": 0.17995131015777588,
      "learning_rate": 0.00016048704265242725,
      "loss": 0.3805,
      "step": 4680
    },
    {
      "epoch": 0.5968629696796157,
      "grad_norm": 0.18544511497020721,
      "learning_rate": 0.00016032671765885814,
      "loss": 0.3938,
      "step": 4690
    },
    {
      "epoch": 0.5981355986128345,
      "grad_norm": 0.18548153340816498,
      "learning_rate": 0.00016016614850799984,
      "loss": 0.3744,
      "step": 4700
    },
    {
      "epoch": 0.5994082275460533,
      "grad_norm": 0.19407716393470764,
      "learning_rate": 0.00016000533584971572,
      "loss": 0.3789,
      "step": 4710
    },
    {
      "epoch": 0.600680856479272,
      "grad_norm": 0.24818575382232666,
      "learning_rate": 0.00015984428033485485,
      "loss": 0.3771,
      "step": 4720
    },
    {
      "epoch": 0.6019534854124908,
      "grad_norm": 0.23186400532722473,
      "learning_rate": 0.000159682982615249,
      "loss": 0.3692,
      "step": 4730
    },
    {
      "epoch": 0.6032261143457096,
      "grad_norm": 0.25503861904144287,
      "learning_rate": 0.00015952144334371044,
      "loss": 0.3875,
      "step": 4740
    },
    {
      "epoch": 0.6044987432789285,
      "grad_norm": 0.2376078963279724,
      "learning_rate": 0.00015935966317402885,
      "loss": 0.3778,
      "step": 4750
    },
    {
      "epoch": 0.6057713722121473,
      "grad_norm": 0.19470569491386414,
      "learning_rate": 0.000159197642760969,
      "loss": 0.366,
      "step": 4760
    },
    {
      "epoch": 0.607044001145366,
      "grad_norm": 0.20413219928741455,
      "learning_rate": 0.00015903538276026792,
      "loss": 0.3696,
      "step": 4770
    },
    {
      "epoch": 0.6083166300785848,
      "grad_norm": 0.2570902705192566,
      "learning_rate": 0.00015887288382863238,
      "loss": 0.3816,
      "step": 4780
    },
    {
      "epoch": 0.6095892590118036,
      "grad_norm": 0.232659250497818,
      "learning_rate": 0.00015871014662373613,
      "loss": 0.3742,
      "step": 4790
    },
    {
      "epoch": 0.6108618879450224,
      "grad_norm": 0.23082619905471802,
      "learning_rate": 0.0001585471718042173,
      "loss": 0.3836,
      "step": 4800
    },
    {
      "epoch": 0.6121345168782413,
      "grad_norm": 0.2349472939968109,
      "learning_rate": 0.00015838396002967558,
      "loss": 0.3752,
      "step": 4810
    },
    {
      "epoch": 0.61340714581146,
      "grad_norm": 0.22491052746772766,
      "learning_rate": 0.0001582205119606699,
      "loss": 0.3657,
      "step": 4820
    },
    {
      "epoch": 0.6146797747446788,
      "grad_norm": 0.32426515221595764,
      "learning_rate": 0.00015805682825871534,
      "loss": 0.3729,
      "step": 4830
    },
    {
      "epoch": 0.6159524036778976,
      "grad_norm": 0.2212272733449936,
      "learning_rate": 0.00015789290958628072,
      "loss": 0.3519,
      "step": 4840
    },
    {
      "epoch": 0.6172250326111164,
      "grad_norm": 0.21693114936351776,
      "learning_rate": 0.00015772875660678581,
      "loss": 0.3688,
      "step": 4850
    },
    {
      "epoch": 0.6184976615443352,
      "grad_norm": 0.17163032293319702,
      "learning_rate": 0.00015756436998459874,
      "loss": 0.3597,
      "step": 4860
    },
    {
      "epoch": 0.619770290477554,
      "grad_norm": 0.22904251515865326,
      "learning_rate": 0.0001573997503850332,
      "loss": 0.3967,
      "step": 4870
    },
    {
      "epoch": 0.6210429194107728,
      "grad_norm": 0.20267266035079956,
      "learning_rate": 0.00015723489847434583,
      "loss": 0.3847,
      "step": 4880
    },
    {
      "epoch": 0.6223155483439916,
      "grad_norm": 0.1992737501859665,
      "learning_rate": 0.00015706981491973342,
      "loss": 0.3775,
      "step": 4890
    },
    {
      "epoch": 0.6235881772772104,
      "grad_norm": 0.18703290820121765,
      "learning_rate": 0.00015690450038933042,
      "loss": 0.3784,
      "step": 4900
    },
    {
      "epoch": 0.6248608062104292,
      "grad_norm": 0.18353059887886047,
      "learning_rate": 0.00015673895555220595,
      "loss": 0.3758,
      "step": 4910
    },
    {
      "epoch": 0.6261334351436479,
      "grad_norm": 0.18291208148002625,
      "learning_rate": 0.0001565731810783613,
      "loss": 0.3604,
      "step": 4920
    },
    {
      "epoch": 0.6274060640768668,
      "grad_norm": 0.23157046735286713,
      "learning_rate": 0.00015640717763872722,
      "loss": 0.3731,
      "step": 4930
    },
    {
      "epoch": 0.6286786930100856,
      "grad_norm": 0.2827458083629608,
      "learning_rate": 0.00015624094590516104,
      "loss": 0.3813,
      "step": 4940
    },
    {
      "epoch": 0.6299513219433044,
      "grad_norm": 0.20281031727790833,
      "learning_rate": 0.00015607448655044403,
      "loss": 0.3878,
      "step": 4950
    },
    {
      "epoch": 0.6312239508765232,
      "grad_norm": 0.2501719295978546,
      "learning_rate": 0.00015590780024827888,
      "loss": 0.3602,
      "step": 4960
    },
    {
      "epoch": 0.6324965798097419,
      "grad_norm": 0.18136541545391083,
      "learning_rate": 0.00015574088767328657,
      "loss": 0.3574,
      "step": 4970
    },
    {
      "epoch": 0.6337692087429607,
      "grad_norm": 0.19265298545360565,
      "learning_rate": 0.00015557374950100404,
      "loss": 0.3604,
      "step": 4980
    },
    {
      "epoch": 0.6350418376761796,
      "grad_norm": 0.3007219135761261,
      "learning_rate": 0.00015540638640788114,
      "loss": 0.3648,
      "step": 4990
    },
    {
      "epoch": 0.6363144666093984,
      "grad_norm": 0.24738313257694244,
      "learning_rate": 0.00015523879907127817,
      "loss": 0.3828,
      "step": 5000
    },
    {
      "epoch": 0.6363144666093984,
      "eval_loss": 0.37073999643325806,
      "eval_runtime": 764.6346,
      "eval_samples_per_second": 10.277,
      "eval_steps_per_second": 5.138,
      "step": 5000
    },
    {
      "epoch": 0.6375870955426172,
      "grad_norm": 0.227096289396286,
      "learning_rate": 0.00015507098816946283,
      "loss": 0.3746,
      "step": 5010
    },
    {
      "epoch": 0.6388597244758359,
      "grad_norm": 0.1781175285577774,
      "learning_rate": 0.00015490295438160784,
      "loss": 0.3599,
      "step": 5020
    },
    {
      "epoch": 0.6401323534090547,
      "grad_norm": 0.1947038769721985,
      "learning_rate": 0.00015473469838778788,
      "loss": 0.3595,
      "step": 5030
    },
    {
      "epoch": 0.6414049823422735,
      "grad_norm": 0.19020429253578186,
      "learning_rate": 0.00015456622086897689,
      "loss": 0.3516,
      "step": 5040
    },
    {
      "epoch": 0.6426776112754924,
      "grad_norm": 0.23230116069316864,
      "learning_rate": 0.00015439752250704554,
      "loss": 0.3698,
      "step": 5050
    },
    {
      "epoch": 0.6439502402087112,
      "grad_norm": 0.1956113576889038,
      "learning_rate": 0.00015422860398475816,
      "loss": 0.3753,
      "step": 5060
    },
    {
      "epoch": 0.6452228691419299,
      "grad_norm": 0.17663384974002838,
      "learning_rate": 0.00015405946598577024,
      "loss": 0.3799,
      "step": 5070
    },
    {
      "epoch": 0.6464954980751487,
      "grad_norm": 0.1763153076171875,
      "learning_rate": 0.0001538901091946255,
      "loss": 0.3965,
      "step": 5080
    },
    {
      "epoch": 0.6477681270083675,
      "grad_norm": 0.2606324255466461,
      "learning_rate": 0.00015372053429675307,
      "loss": 0.3721,
      "step": 5090
    },
    {
      "epoch": 0.6490407559415863,
      "grad_norm": 0.2612980306148529,
      "learning_rate": 0.000153550741978465,
      "loss": 0.3707,
      "step": 5100
    },
    {
      "epoch": 0.6503133848748052,
      "grad_norm": 0.20582841336727142,
      "learning_rate": 0.00015338073292695318,
      "loss": 0.3487,
      "step": 5110
    },
    {
      "epoch": 0.651586013808024,
      "grad_norm": 0.23422476649284363,
      "learning_rate": 0.00015321050783028662,
      "loss": 0.3899,
      "step": 5120
    },
    {
      "epoch": 0.6528586427412427,
      "grad_norm": 0.20744629204273224,
      "learning_rate": 0.00015304006737740887,
      "loss": 0.3349,
      "step": 5130
    },
    {
      "epoch": 0.6541312716744615,
      "grad_norm": 0.19206224381923676,
      "learning_rate": 0.00015286941225813494,
      "loss": 0.39,
      "step": 5140
    },
    {
      "epoch": 0.6554039006076803,
      "grad_norm": 0.18610087037086487,
      "learning_rate": 0.00015269854316314876,
      "loss": 0.3548,
      "step": 5150
    },
    {
      "epoch": 0.6566765295408992,
      "grad_norm": 0.2720935642719269,
      "learning_rate": 0.0001525274607840002,
      "loss": 0.3622,
      "step": 5160
    },
    {
      "epoch": 0.657949158474118,
      "grad_norm": 0.19084511697292328,
      "learning_rate": 0.00015235616581310235,
      "loss": 0.3649,
      "step": 5170
    },
    {
      "epoch": 0.6592217874073367,
      "grad_norm": 0.2320166379213333,
      "learning_rate": 0.00015218465894372877,
      "loss": 0.372,
      "step": 5180
    },
    {
      "epoch": 0.6604944163405555,
      "grad_norm": 0.2216753214597702,
      "learning_rate": 0.00015201294087001052,
      "loss": 0.3672,
      "step": 5190
    },
    {
      "epoch": 0.6617670452737743,
      "grad_norm": 0.20037546753883362,
      "learning_rate": 0.0001518410122869336,
      "loss": 0.3544,
      "step": 5200
    },
    {
      "epoch": 0.6630396742069931,
      "grad_norm": 0.20084919035434723,
      "learning_rate": 0.00015166887389033587,
      "loss": 0.3554,
      "step": 5210
    },
    {
      "epoch": 0.664312303140212,
      "grad_norm": 0.192629873752594,
      "learning_rate": 0.00015149652637690437,
      "loss": 0.3681,
      "step": 5220
    },
    {
      "epoch": 0.6655849320734307,
      "grad_norm": 0.19671761989593506,
      "learning_rate": 0.00015132397044417256,
      "loss": 0.3841,
      "step": 5230
    },
    {
      "epoch": 0.6668575610066495,
      "grad_norm": 0.17493034899234772,
      "learning_rate": 0.00015115120679051738,
      "loss": 0.3686,
      "step": 5240
    },
    {
      "epoch": 0.6681301899398683,
      "grad_norm": 0.26667389273643494,
      "learning_rate": 0.0001509782361151565,
      "loss": 0.3878,
      "step": 5250
    },
    {
      "epoch": 0.6694028188730871,
      "grad_norm": 0.23264718055725098,
      "learning_rate": 0.0001508050591181454,
      "loss": 0.3699,
      "step": 5260
    },
    {
      "epoch": 0.6706754478063058,
      "grad_norm": 0.21274729073047638,
      "learning_rate": 0.00015063167650037457,
      "loss": 0.375,
      "step": 5270
    },
    {
      "epoch": 0.6719480767395247,
      "grad_norm": 0.17448434233665466,
      "learning_rate": 0.00015045808896356686,
      "loss": 0.3457,
      "step": 5280
    },
    {
      "epoch": 0.6732207056727435,
      "grad_norm": 0.2549740970134735,
      "learning_rate": 0.00015028429721027434,
      "loss": 0.3676,
      "step": 5290
    },
    {
      "epoch": 0.6744933346059623,
      "grad_norm": 0.2439890056848526,
      "learning_rate": 0.00015011030194387562,
      "loss": 0.3846,
      "step": 5300
    },
    {
      "epoch": 0.6757659635391811,
      "grad_norm": 0.173786923289299,
      "learning_rate": 0.00014993610386857296,
      "loss": 0.3516,
      "step": 5310
    },
    {
      "epoch": 0.6770385924723998,
      "grad_norm": 0.24098634719848633,
      "learning_rate": 0.0001497617036893895,
      "loss": 0.3846,
      "step": 5320
    },
    {
      "epoch": 0.6783112214056186,
      "grad_norm": 0.20602190494537354,
      "learning_rate": 0.00014958710211216631,
      "loss": 0.3747,
      "step": 5330
    },
    {
      "epoch": 0.6795838503388375,
      "grad_norm": 0.22563223540782928,
      "learning_rate": 0.00014941229984355957,
      "loss": 0.3481,
      "step": 5340
    },
    {
      "epoch": 0.6808564792720563,
      "grad_norm": 0.24981573224067688,
      "learning_rate": 0.00014923729759103768,
      "loss": 0.4001,
      "step": 5350
    },
    {
      "epoch": 0.6821291082052751,
      "grad_norm": 0.2781941294670105,
      "learning_rate": 0.00014906209606287845,
      "loss": 0.4011,
      "step": 5360
    },
    {
      "epoch": 0.6834017371384938,
      "grad_norm": 0.23304763436317444,
      "learning_rate": 0.0001488866959681663,
      "loss": 0.3889,
      "step": 5370
    },
    {
      "epoch": 0.6846743660717126,
      "grad_norm": 0.26293709874153137,
      "learning_rate": 0.0001487110980167891,
      "loss": 0.3675,
      "step": 5380
    },
    {
      "epoch": 0.6859469950049314,
      "grad_norm": 0.211699977517128,
      "learning_rate": 0.00014853530291943564,
      "loss": 0.3669,
      "step": 5390
    },
    {
      "epoch": 0.6872196239381503,
      "grad_norm": 0.254812091588974,
      "learning_rate": 0.0001483593113875926,
      "loss": 0.3624,
      "step": 5400
    },
    {
      "epoch": 0.6884922528713691,
      "grad_norm": 0.214838445186615,
      "learning_rate": 0.0001481831241335416,
      "loss": 0.3626,
      "step": 5410
    },
    {
      "epoch": 0.6897648818045878,
      "grad_norm": 0.21809832751750946,
      "learning_rate": 0.00014800674187035652,
      "loss": 0.3695,
      "step": 5420
    },
    {
      "epoch": 0.6910375107378066,
      "grad_norm": 0.30367204546928406,
      "learning_rate": 0.00014783016531190034,
      "loss": 0.3521,
      "step": 5430
    },
    {
      "epoch": 0.6923101396710254,
      "grad_norm": 0.26925840973854065,
      "learning_rate": 0.00014765339517282256,
      "loss": 0.3454,
      "step": 5440
    },
    {
      "epoch": 0.6935827686042442,
      "grad_norm": 0.20498718321323395,
      "learning_rate": 0.00014747643216855597,
      "loss": 0.3507,
      "step": 5450
    },
    {
      "epoch": 0.6948553975374631,
      "grad_norm": 0.180291086435318,
      "learning_rate": 0.00014729927701531413,
      "loss": 0.3607,
      "step": 5460
    },
    {
      "epoch": 0.6961280264706818,
      "grad_norm": 0.22565940022468567,
      "learning_rate": 0.00014712193043008815,
      "loss": 0.3518,
      "step": 5470
    },
    {
      "epoch": 0.6974006554039006,
      "grad_norm": 0.21134810149669647,
      "learning_rate": 0.00014694439313064393,
      "loss": 0.3757,
      "step": 5480
    },
    {
      "epoch": 0.6986732843371194,
      "grad_norm": 0.40153050422668457,
      "learning_rate": 0.00014676666583551926,
      "loss": 0.3925,
      "step": 5490
    },
    {
      "epoch": 0.6999459132703382,
      "grad_norm": 0.24004080891609192,
      "learning_rate": 0.00014658874926402085,
      "loss": 0.3767,
      "step": 5500
    },
    {
      "epoch": 0.6999459132703382,
      "eval_loss": 0.36825913190841675,
      "eval_runtime": 797.1806,
      "eval_samples_per_second": 9.857,
      "eval_steps_per_second": 4.929,
      "step": 5500
    },
    {
      "epoch": 0.701218542203557,
      "grad_norm": 0.3018442392349243,
      "learning_rate": 0.00014641064413622155,
      "loss": 0.3958,
      "step": 5510
    },
    {
      "epoch": 0.7024911711367758,
      "grad_norm": 0.23482771217823029,
      "learning_rate": 0.0001462323511729572,
      "loss": 0.3603,
      "step": 5520
    },
    {
      "epoch": 0.7037638000699946,
      "grad_norm": 0.23410438001155853,
      "learning_rate": 0.000146053871095824,
      "loss": 0.3782,
      "step": 5530
    },
    {
      "epoch": 0.7050364290032134,
      "grad_norm": 0.20583826303482056,
      "learning_rate": 0.0001458752046271754,
      "loss": 0.37,
      "step": 5540
    },
    {
      "epoch": 0.7063090579364322,
      "grad_norm": 0.28167152404785156,
      "learning_rate": 0.00014569635249011916,
      "loss": 0.3975,
      "step": 5550
    },
    {
      "epoch": 0.707581686869651,
      "grad_norm": 0.19132085144519806,
      "learning_rate": 0.00014551731540851456,
      "loss": 0.3719,
      "step": 5560
    },
    {
      "epoch": 0.7088543158028697,
      "grad_norm": 0.19677896797657013,
      "learning_rate": 0.00014533809410696935,
      "loss": 0.3768,
      "step": 5570
    },
    {
      "epoch": 0.7101269447360886,
      "grad_norm": 0.23905810713768005,
      "learning_rate": 0.00014515868931083692,
      "loss": 0.3653,
      "step": 5580
    },
    {
      "epoch": 0.7113995736693074,
      "grad_norm": 0.2159186452627182,
      "learning_rate": 0.00014497910174621328,
      "loss": 0.3775,
      "step": 5590
    },
    {
      "epoch": 0.7126722026025262,
      "grad_norm": 0.15873178839683533,
      "learning_rate": 0.00014479933213993408,
      "loss": 0.3651,
      "step": 5600
    },
    {
      "epoch": 0.713944831535745,
      "grad_norm": 0.21046429872512817,
      "learning_rate": 0.0001446193812195719,
      "loss": 0.3811,
      "step": 5610
    },
    {
      "epoch": 0.7152174604689637,
      "grad_norm": 0.20076307654380798,
      "learning_rate": 0.00014443924971343296,
      "loss": 0.3738,
      "step": 5620
    },
    {
      "epoch": 0.7164900894021825,
      "grad_norm": 0.20749741792678833,
      "learning_rate": 0.0001442589383505545,
      "loss": 0.3948,
      "step": 5630
    },
    {
      "epoch": 0.7177627183354014,
      "grad_norm": 0.19524991512298584,
      "learning_rate": 0.0001440784478607016,
      "loss": 0.3622,
      "step": 5640
    },
    {
      "epoch": 0.7190353472686202,
      "grad_norm": 0.213662788271904,
      "learning_rate": 0.00014389777897436435,
      "loss": 0.4006,
      "step": 5650
    },
    {
      "epoch": 0.720307976201839,
      "grad_norm": 0.1974170058965683,
      "learning_rate": 0.00014371693242275484,
      "loss": 0.3604,
      "step": 5660
    },
    {
      "epoch": 0.7215806051350577,
      "grad_norm": 0.26314452290534973,
      "learning_rate": 0.0001435359089378042,
      "loss": 0.3793,
      "step": 5670
    },
    {
      "epoch": 0.7228532340682765,
      "grad_norm": 0.2502278983592987,
      "learning_rate": 0.0001433547092521597,
      "loss": 0.3705,
      "step": 5680
    },
    {
      "epoch": 0.7241258630014953,
      "grad_norm": 0.22776676714420319,
      "learning_rate": 0.00014317333409918172,
      "loss": 0.3911,
      "step": 5690
    },
    {
      "epoch": 0.7253984919347142,
      "grad_norm": 0.19667229056358337,
      "learning_rate": 0.00014299178421294073,
      "loss": 0.3826,
      "step": 5700
    },
    {
      "epoch": 0.726671120867933,
      "grad_norm": 0.18981845676898956,
      "learning_rate": 0.00014281006032821453,
      "loss": 0.3756,
      "step": 5710
    },
    {
      "epoch": 0.7279437498011517,
      "grad_norm": 0.24715378880500793,
      "learning_rate": 0.00014262816318048502,
      "loss": 0.3571,
      "step": 5720
    },
    {
      "epoch": 0.7292163787343705,
      "grad_norm": 0.2465544193983078,
      "learning_rate": 0.00014244609350593535,
      "loss": 0.3572,
      "step": 5730
    },
    {
      "epoch": 0.7304890076675893,
      "grad_norm": 0.18414311110973358,
      "learning_rate": 0.00014226385204144698,
      "loss": 0.361,
      "step": 5740
    },
    {
      "epoch": 0.7317616366008082,
      "grad_norm": 0.23428507149219513,
      "learning_rate": 0.00014208143952459663,
      "loss": 0.3719,
      "step": 5750
    },
    {
      "epoch": 0.733034265534027,
      "grad_norm": 0.20265544950962067,
      "learning_rate": 0.00014189885669365328,
      "loss": 0.3924,
      "step": 5760
    },
    {
      "epoch": 0.7343068944672457,
      "grad_norm": 0.21099326014518738,
      "learning_rate": 0.00014171610428757525,
      "loss": 0.3705,
      "step": 5770
    },
    {
      "epoch": 0.7355795234004645,
      "grad_norm": 0.17917032539844513,
      "learning_rate": 0.00014153318304600715,
      "loss": 0.3703,
      "step": 5780
    },
    {
      "epoch": 0.7368521523336833,
      "grad_norm": 0.24150651693344116,
      "learning_rate": 0.00014135009370927693,
      "loss": 0.3833,
      "step": 5790
    },
    {
      "epoch": 0.7381247812669021,
      "grad_norm": 0.20242059230804443,
      "learning_rate": 0.00014116683701839283,
      "loss": 0.3648,
      "step": 5800
    },
    {
      "epoch": 0.739397410200121,
      "grad_norm": 0.20288534462451935,
      "learning_rate": 0.00014098341371504046,
      "loss": 0.3755,
      "step": 5810
    },
    {
      "epoch": 0.7406700391333397,
      "grad_norm": 0.21972696483135223,
      "learning_rate": 0.00014079982454157973,
      "loss": 0.3716,
      "step": 5820
    },
    {
      "epoch": 0.7419426680665585,
      "grad_norm": 0.24599558115005493,
      "learning_rate": 0.0001406160702410418,
      "loss": 0.3738,
      "step": 5830
    },
    {
      "epoch": 0.7432152969997773,
      "grad_norm": 0.2337218075990677,
      "learning_rate": 0.0001404321515571263,
      "loss": 0.3681,
      "step": 5840
    },
    {
      "epoch": 0.7444879259329961,
      "grad_norm": 0.20103484392166138,
      "learning_rate": 0.00014024806923419798,
      "loss": 0.3605,
      "step": 5850
    },
    {
      "epoch": 0.7457605548662148,
      "grad_norm": 0.27654770016670227,
      "learning_rate": 0.00014006382401728404,
      "loss": 0.3971,
      "step": 5860
    },
    {
      "epoch": 0.7470331837994337,
      "grad_norm": 0.24416115880012512,
      "learning_rate": 0.00013987941665207084,
      "loss": 0.3718,
      "step": 5870
    },
    {
      "epoch": 0.7483058127326525,
      "grad_norm": 0.17320065200328827,
      "learning_rate": 0.000139694847884901,
      "loss": 0.4123,
      "step": 5880
    },
    {
      "epoch": 0.7495784416658713,
      "grad_norm": 0.17669285833835602,
      "learning_rate": 0.00013951011846277046,
      "loss": 0.3826,
      "step": 5890
    },
    {
      "epoch": 0.7508510705990901,
      "grad_norm": 0.2649834156036377,
      "learning_rate": 0.0001393252291333253,
      "loss": 0.4021,
      "step": 5900
    },
    {
      "epoch": 0.7521236995323088,
      "grad_norm": 0.28356030583381653,
      "learning_rate": 0.0001391401806448588,
      "loss": 0.3522,
      "step": 5910
    },
    {
      "epoch": 0.7533963284655276,
      "grad_norm": 0.1639363020658493,
      "learning_rate": 0.0001389549737463084,
      "loss": 0.338,
      "step": 5920
    },
    {
      "epoch": 0.7546689573987465,
      "grad_norm": 0.2249743491411209,
      "learning_rate": 0.00013876960918725263,
      "loss": 0.3766,
      "step": 5930
    },
    {
      "epoch": 0.7559415863319653,
      "grad_norm": 0.1770409643650055,
      "learning_rate": 0.0001385840877179082,
      "loss": 0.3866,
      "step": 5940
    },
    {
      "epoch": 0.7572142152651841,
      "grad_norm": 0.24146825075149536,
      "learning_rate": 0.00013839841008912674,
      "loss": 0.3759,
      "step": 5950
    },
    {
      "epoch": 0.7584868441984028,
      "grad_norm": 0.2595473527908325,
      "learning_rate": 0.00013821257705239206,
      "loss": 0.3724,
      "step": 5960
    },
    {
      "epoch": 0.7597594731316216,
      "grad_norm": 0.2809872627258301,
      "learning_rate": 0.00013802658935981683,
      "loss": 0.373,
      "step": 5970
    },
    {
      "epoch": 0.7610321020648404,
      "grad_norm": 0.21205872297286987,
      "learning_rate": 0.00013784044776413964,
      "loss": 0.35,
      "step": 5980
    },
    {
      "epoch": 0.7623047309980593,
      "grad_norm": 0.25038132071495056,
      "learning_rate": 0.0001376541530187221,
      "loss": 0.3933,
      "step": 5990
    },
    {
      "epoch": 0.7635773599312781,
      "grad_norm": 0.21244096755981445,
      "learning_rate": 0.00013746770587754544,
      "loss": 0.3724,
      "step": 6000
    },
    {
      "epoch": 0.7635773599312781,
      "eval_loss": 0.36493751406669617,
      "eval_runtime": 750.9103,
      "eval_samples_per_second": 10.465,
      "eval_steps_per_second": 5.232,
      "step": 6000
    },
    {
      "epoch": 0.7648499888644968,
      "grad_norm": 0.24046450853347778,
      "learning_rate": 0.00013728110709520784,
      "loss": 0.383,
      "step": 6010
    },
    {
      "epoch": 0.7661226177977156,
      "grad_norm": 0.20186170935630798,
      "learning_rate": 0.00013709435742692122,
      "loss": 0.3778,
      "step": 6020
    },
    {
      "epoch": 0.7673952467309344,
      "grad_norm": 0.24164848029613495,
      "learning_rate": 0.00013690745762850808,
      "loss": 0.3743,
      "step": 6030
    },
    {
      "epoch": 0.7686678756641532,
      "grad_norm": 0.4292798936367035,
      "learning_rate": 0.00013672040845639857,
      "loss": 0.3791,
      "step": 6040
    },
    {
      "epoch": 0.7699405045973721,
      "grad_norm": 0.2156647890806198,
      "learning_rate": 0.00013653321066762732,
      "loss": 0.3692,
      "step": 6050
    },
    {
      "epoch": 0.7712131335305908,
      "grad_norm": 0.20248840749263763,
      "learning_rate": 0.00013634586501983065,
      "loss": 0.3564,
      "step": 6060
    },
    {
      "epoch": 0.7724857624638096,
      "grad_norm": 0.20453856885433197,
      "learning_rate": 0.0001361583722712431,
      "loss": 0.3985,
      "step": 6070
    },
    {
      "epoch": 0.7737583913970284,
      "grad_norm": 0.17480814456939697,
      "learning_rate": 0.00013597073318069464,
      "loss": 0.3718,
      "step": 6080
    },
    {
      "epoch": 0.7750310203302472,
      "grad_norm": 0.20554445683956146,
      "learning_rate": 0.00013578294850760756,
      "loss": 0.3626,
      "step": 6090
    },
    {
      "epoch": 0.776303649263466,
      "grad_norm": 0.3559362590312958,
      "learning_rate": 0.00013559501901199328,
      "loss": 0.3805,
      "step": 6100
    },
    {
      "epoch": 0.7775762781966848,
      "grad_norm": 0.24314668774604797,
      "learning_rate": 0.0001354069454544494,
      "loss": 0.3653,
      "step": 6110
    },
    {
      "epoch": 0.7788489071299036,
      "grad_norm": 0.2661728262901306,
      "learning_rate": 0.0001352187285961566,
      "loss": 0.3798,
      "step": 6120
    },
    {
      "epoch": 0.7801215360631224,
      "grad_norm": 0.29006731510162354,
      "learning_rate": 0.00013503036919887545,
      "loss": 0.3749,
      "step": 6130
    },
    {
      "epoch": 0.7813941649963412,
      "grad_norm": 0.21642446517944336,
      "learning_rate": 0.00013484186802494345,
      "loss": 0.3646,
      "step": 6140
    },
    {
      "epoch": 0.78266679392956,
      "grad_norm": 0.22969354689121246,
      "learning_rate": 0.000134653225837272,
      "loss": 0.392,
      "step": 6150
    },
    {
      "epoch": 0.7839394228627787,
      "grad_norm": 0.23153066635131836,
      "learning_rate": 0.00013446444339934309,
      "loss": 0.3597,
      "step": 6160
    },
    {
      "epoch": 0.7852120517959976,
      "grad_norm": 0.20648406445980072,
      "learning_rate": 0.00013427552147520636,
      "loss": 0.3696,
      "step": 6170
    },
    {
      "epoch": 0.7864846807292164,
      "grad_norm": 0.2291058897972107,
      "learning_rate": 0.00013408646082947604,
      "loss": 0.3509,
      "step": 6180
    },
    {
      "epoch": 0.7877573096624352,
      "grad_norm": 0.20643417537212372,
      "learning_rate": 0.00013389726222732778,
      "loss": 0.3333,
      "step": 6190
    },
    {
      "epoch": 0.789029938595654,
      "grad_norm": 0.23330651223659515,
      "learning_rate": 0.00013370792643449552,
      "loss": 0.3719,
      "step": 6200
    },
    {
      "epoch": 0.7903025675288727,
      "grad_norm": 0.2042660415172577,
      "learning_rate": 0.00013351845421726848,
      "loss": 0.377,
      "step": 6210
    },
    {
      "epoch": 0.7915751964620915,
      "grad_norm": 0.20804250240325928,
      "learning_rate": 0.0001333288463424881,
      "loss": 0.3699,
      "step": 6220
    },
    {
      "epoch": 0.7928478253953104,
      "grad_norm": 0.1889469474554062,
      "learning_rate": 0.0001331391035775448,
      "loss": 0.362,
      "step": 6230
    },
    {
      "epoch": 0.7941204543285292,
      "grad_norm": 0.27416300773620605,
      "learning_rate": 0.00013294922669037482,
      "loss": 0.3545,
      "step": 6240
    },
    {
      "epoch": 0.795393083261748,
      "grad_norm": 0.1923321634531021,
      "learning_rate": 0.0001327592164494574,
      "loss": 0.3368,
      "step": 6250
    },
    {
      "epoch": 0.7966657121949667,
      "grad_norm": 0.2188410460948944,
      "learning_rate": 0.00013256907362381144,
      "loss": 0.3507,
      "step": 6260
    },
    {
      "epoch": 0.7979383411281855,
      "grad_norm": 0.2549818754196167,
      "learning_rate": 0.00013237879898299242,
      "loss": 0.3538,
      "step": 6270
    },
    {
      "epoch": 0.7992109700614043,
      "grad_norm": 0.23275160789489746,
      "learning_rate": 0.00013218839329708928,
      "loss": 0.3793,
      "step": 6280
    },
    {
      "epoch": 0.8004835989946232,
      "grad_norm": 0.19438298046588898,
      "learning_rate": 0.00013199785733672146,
      "loss": 0.3546,
      "step": 6290
    },
    {
      "epoch": 0.801756227927842,
      "grad_norm": 0.24728138744831085,
      "learning_rate": 0.00013180719187303548,
      "loss": 0.3686,
      "step": 6300
    },
    {
      "epoch": 0.8030288568610607,
      "grad_norm": 0.21291188895702362,
      "learning_rate": 0.0001316163976777021,
      "loss": 0.3852,
      "step": 6310
    },
    {
      "epoch": 0.8043014857942795,
      "grad_norm": 0.3199424743652344,
      "learning_rate": 0.0001314254755229131,
      "loss": 0.3563,
      "step": 6320
    },
    {
      "epoch": 0.8055741147274983,
      "grad_norm": 0.2564390003681183,
      "learning_rate": 0.00013123442618137812,
      "loss": 0.3562,
      "step": 6330
    },
    {
      "epoch": 0.8068467436607172,
      "grad_norm": 0.2615058422088623,
      "learning_rate": 0.00013104325042632146,
      "loss": 0.3533,
      "step": 6340
    },
    {
      "epoch": 0.808119372593936,
      "grad_norm": 0.20054496824741364,
      "learning_rate": 0.00013085194903147924,
      "loss": 0.3448,
      "step": 6350
    },
    {
      "epoch": 0.8093920015271547,
      "grad_norm": 0.20528393983840942,
      "learning_rate": 0.0001306605227710959,
      "loss": 0.3643,
      "step": 6360
    },
    {
      "epoch": 0.8106646304603735,
      "grad_norm": 0.18899673223495483,
      "learning_rate": 0.00013046897241992134,
      "loss": 0.3885,
      "step": 6370
    },
    {
      "epoch": 0.8119372593935923,
      "grad_norm": 0.20311447978019714,
      "learning_rate": 0.00013027729875320768,
      "loss": 0.3987,
      "step": 6380
    },
    {
      "epoch": 0.8132098883268111,
      "grad_norm": 0.1969757080078125,
      "learning_rate": 0.00013008550254670607,
      "loss": 0.3595,
      "step": 6390
    },
    {
      "epoch": 0.81448251726003,
      "grad_norm": 0.21847078204154968,
      "learning_rate": 0.00012989358457666364,
      "loss": 0.3701,
      "step": 6400
    },
    {
      "epoch": 0.8157551461932487,
      "grad_norm": 0.23095139861106873,
      "learning_rate": 0.00012970154561982037,
      "loss": 0.3764,
      "step": 6410
    },
    {
      "epoch": 0.8170277751264675,
      "grad_norm": 0.22449220716953278,
      "learning_rate": 0.00012950938645340588,
      "loss": 0.3695,
      "step": 6420
    },
    {
      "epoch": 0.8183004040596863,
      "grad_norm": 0.20064710080623627,
      "learning_rate": 0.00012931710785513625,
      "loss": 0.3584,
      "step": 6430
    },
    {
      "epoch": 0.8195730329929051,
      "grad_norm": 0.22981877624988556,
      "learning_rate": 0.00012912471060321098,
      "loss": 0.366,
      "step": 6440
    },
    {
      "epoch": 0.8208456619261238,
      "grad_norm": 0.21860527992248535,
      "learning_rate": 0.00012893219547630984,
      "loss": 0.3512,
      "step": 6450
    },
    {
      "epoch": 0.8221182908593427,
      "grad_norm": 0.16366587579250336,
      "learning_rate": 0.00012873956325358955,
      "loss": 0.3616,
      "step": 6460
    },
    {
      "epoch": 0.8233909197925615,
      "grad_norm": 0.23395690321922302,
      "learning_rate": 0.0001285468147146809,
      "loss": 0.3493,
      "step": 6470
    },
    {
      "epoch": 0.8246635487257803,
      "grad_norm": 0.27464359998703003,
      "learning_rate": 0.00012835395063968524,
      "loss": 0.3457,
      "step": 6480
    },
    {
      "epoch": 0.8259361776589991,
      "grad_norm": 0.218461275100708,
      "learning_rate": 0.0001281609718091717,
      "loss": 0.3683,
      "step": 6490
    },
    {
      "epoch": 0.8272088065922178,
      "grad_norm": 0.21863533556461334,
      "learning_rate": 0.00012796787900417383,
      "loss": 0.3726,
      "step": 6500
    },
    {
      "epoch": 0.8272088065922178,
      "eval_loss": 0.3632776141166687,
      "eval_runtime": 759.6148,
      "eval_samples_per_second": 10.345,
      "eval_steps_per_second": 5.172,
      "step": 6500
    },
    {
      "epoch": 0.8284814355254366,
      "grad_norm": 0.24344174563884735,
      "learning_rate": 0.00012777467300618636,
      "loss": 0.3871,
      "step": 6510
    },
    {
      "epoch": 0.8297540644586555,
      "grad_norm": 0.1919211596250534,
      "learning_rate": 0.00012758135459716222,
      "loss": 0.3713,
      "step": 6520
    },
    {
      "epoch": 0.8310266933918743,
      "grad_norm": 0.23005874454975128,
      "learning_rate": 0.0001273879245595093,
      "loss": 0.3507,
      "step": 6530
    },
    {
      "epoch": 0.8322993223250931,
      "grad_norm": 0.23416242003440857,
      "learning_rate": 0.00012719438367608725,
      "loss": 0.3669,
      "step": 6540
    },
    {
      "epoch": 0.8335719512583118,
      "grad_norm": 0.18266308307647705,
      "learning_rate": 0.00012700073273020434,
      "loss": 0.3679,
      "step": 6550
    },
    {
      "epoch": 0.8348445801915306,
      "grad_norm": 0.2205212116241455,
      "learning_rate": 0.00012680697250561432,
      "loss": 0.3482,
      "step": 6560
    },
    {
      "epoch": 0.8361172091247494,
      "grad_norm": 0.19787678122520447,
      "learning_rate": 0.00012661310378651316,
      "loss": 0.3753,
      "step": 6570
    },
    {
      "epoch": 0.8373898380579683,
      "grad_norm": 0.23430103063583374,
      "learning_rate": 0.00012641912735753604,
      "loss": 0.381,
      "step": 6580
    },
    {
      "epoch": 0.8386624669911871,
      "grad_norm": 0.1880687177181244,
      "learning_rate": 0.00012622504400375395,
      "loss": 0.3474,
      "step": 6590
    },
    {
      "epoch": 0.8399350959244059,
      "grad_norm": 0.220291405916214,
      "learning_rate": 0.0001260308545106707,
      "loss": 0.3745,
      "step": 6600
    },
    {
      "epoch": 0.8412077248576246,
      "grad_norm": 0.2024318277835846,
      "learning_rate": 0.00012583655966421964,
      "loss": 0.3506,
      "step": 6610
    },
    {
      "epoch": 0.8424803537908434,
      "grad_norm": 0.2618573307991028,
      "learning_rate": 0.00012564216025076052,
      "loss": 0.352,
      "step": 6620
    },
    {
      "epoch": 0.8437529827240622,
      "grad_norm": 0.22505280375480652,
      "learning_rate": 0.00012544765705707636,
      "loss": 0.3853,
      "step": 6630
    },
    {
      "epoch": 0.8450256116572811,
      "grad_norm": 0.2172926515340805,
      "learning_rate": 0.00012525305087037007,
      "loss": 0.3392,
      "step": 6640
    },
    {
      "epoch": 0.8462982405904999,
      "grad_norm": 0.227550208568573,
      "learning_rate": 0.00012505834247826156,
      "loss": 0.3819,
      "step": 6650
    },
    {
      "epoch": 0.8475708695237186,
      "grad_norm": 0.22064369916915894,
      "learning_rate": 0.00012486353266878428,
      "loss": 0.3907,
      "step": 6660
    },
    {
      "epoch": 0.8488434984569374,
      "grad_norm": 0.2683287560939789,
      "learning_rate": 0.0001246686222303821,
      "loss": 0.3898,
      "step": 6670
    },
    {
      "epoch": 0.8501161273901562,
      "grad_norm": 0.19466553628444672,
      "learning_rate": 0.00012447361195190636,
      "loss": 0.3629,
      "step": 6680
    },
    {
      "epoch": 0.851388756323375,
      "grad_norm": 0.21588052809238434,
      "learning_rate": 0.00012427850262261222,
      "loss": 0.3632,
      "step": 6690
    },
    {
      "epoch": 0.8526613852565939,
      "grad_norm": 0.22188498079776764,
      "learning_rate": 0.00012408329503215597,
      "loss": 0.3542,
      "step": 6700
    },
    {
      "epoch": 0.8539340141898126,
      "grad_norm": 0.22277764976024628,
      "learning_rate": 0.00012388798997059139,
      "loss": 0.3884,
      "step": 6710
    },
    {
      "epoch": 0.8552066431230314,
      "grad_norm": 0.2920931875705719,
      "learning_rate": 0.00012369258822836685,
      "loss": 0.3442,
      "step": 6720
    },
    {
      "epoch": 0.8564792720562502,
      "grad_norm": 0.23665891587734222,
      "learning_rate": 0.000123497090596322,
      "loss": 0.3727,
      "step": 6730
    },
    {
      "epoch": 0.857751900989469,
      "grad_norm": 0.23798462748527527,
      "learning_rate": 0.00012330149786568456,
      "loss": 0.3717,
      "step": 6740
    },
    {
      "epoch": 0.8590245299226877,
      "grad_norm": 0.21869242191314697,
      "learning_rate": 0.00012310581082806713,
      "loss": 0.3817,
      "step": 6750
    },
    {
      "epoch": 0.8602971588559066,
      "grad_norm": 0.20879210531711578,
      "learning_rate": 0.00012291003027546405,
      "loss": 0.33,
      "step": 6760
    },
    {
      "epoch": 0.8615697877891254,
      "grad_norm": 0.2897946834564209,
      "learning_rate": 0.0001227141570002481,
      "loss": 0.3881,
      "step": 6770
    },
    {
      "epoch": 0.8628424167223442,
      "grad_norm": 0.2560538649559021,
      "learning_rate": 0.00012251819179516727,
      "loss": 0.3819,
      "step": 6780
    },
    {
      "epoch": 0.864115045655563,
      "grad_norm": 0.23532098531723022,
      "learning_rate": 0.00012232213545334175,
      "loss": 0.37,
      "step": 6790
    },
    {
      "epoch": 0.8653876745887817,
      "grad_norm": 0.27170294523239136,
      "learning_rate": 0.00012212598876826047,
      "loss": 0.3722,
      "step": 6800
    },
    {
      "epoch": 0.8666603035220005,
      "grad_norm": 0.18637558817863464,
      "learning_rate": 0.00012192975253377805,
      "loss": 0.3504,
      "step": 6810
    },
    {
      "epoch": 0.8679329324552194,
      "grad_norm": 0.24689140915870667,
      "learning_rate": 0.00012173342754411155,
      "loss": 0.3638,
      "step": 6820
    },
    {
      "epoch": 0.8692055613884382,
      "grad_norm": 0.19877567887306213,
      "learning_rate": 0.00012153701459383718,
      "loss": 0.3707,
      "step": 6830
    },
    {
      "epoch": 0.870478190321657,
      "grad_norm": 0.2621847093105316,
      "learning_rate": 0.00012134051447788721,
      "loss": 0.3671,
      "step": 6840
    },
    {
      "epoch": 0.8717508192548757,
      "grad_norm": 0.2269444316625595,
      "learning_rate": 0.00012114392799154669,
      "loss": 0.3576,
      "step": 6850
    },
    {
      "epoch": 0.8730234481880945,
      "grad_norm": 0.2169962227344513,
      "learning_rate": 0.00012094725593045018,
      "loss": 0.3684,
      "step": 6860
    },
    {
      "epoch": 0.8742960771213133,
      "grad_norm": 0.1901581585407257,
      "learning_rate": 0.00012075049909057865,
      "loss": 0.3717,
      "step": 6870
    },
    {
      "epoch": 0.8755687060545322,
      "grad_norm": 0.24532932043075562,
      "learning_rate": 0.00012055365826825616,
      "loss": 0.3752,
      "step": 6880
    },
    {
      "epoch": 0.876841334987751,
      "grad_norm": 0.1831309199333191,
      "learning_rate": 0.00012035673426014662,
      "loss": 0.3626,
      "step": 6890
    },
    {
      "epoch": 0.8781139639209697,
      "grad_norm": 0.2048492729663849,
      "learning_rate": 0.00012015972786325074,
      "loss": 0.3576,
      "step": 6900
    },
    {
      "epoch": 0.8793865928541885,
      "grad_norm": 0.18880508840084076,
      "learning_rate": 0.00011996263987490252,
      "loss": 0.3595,
      "step": 6910
    },
    {
      "epoch": 0.8806592217874073,
      "grad_norm": 0.22867046296596527,
      "learning_rate": 0.00011976547109276631,
      "loss": 0.3521,
      "step": 6920
    },
    {
      "epoch": 0.8819318507206262,
      "grad_norm": 0.1982397437095642,
      "learning_rate": 0.00011956822231483338,
      "loss": 0.3698,
      "step": 6930
    },
    {
      "epoch": 0.883204479653845,
      "grad_norm": 0.2352265566587448,
      "learning_rate": 0.00011937089433941881,
      "loss": 0.3566,
      "step": 6940
    },
    {
      "epoch": 0.8844771085870637,
      "grad_norm": 0.252990186214447,
      "learning_rate": 0.00011917348796515813,
      "loss": 0.3656,
      "step": 6950
    },
    {
      "epoch": 0.8857497375202825,
      "grad_norm": 0.20498068630695343,
      "learning_rate": 0.00011897600399100428,
      "loss": 0.3592,
      "step": 6960
    },
    {
      "epoch": 0.8870223664535013,
      "grad_norm": 0.2135986089706421,
      "learning_rate": 0.00011877844321622417,
      "loss": 0.3572,
      "step": 6970
    },
    {
      "epoch": 0.8882949953867201,
      "grad_norm": 0.19242005050182343,
      "learning_rate": 0.00011858080644039567,
      "loss": 0.3662,
      "step": 6980
    },
    {
      "epoch": 0.889567624319939,
      "grad_norm": 0.36278876662254333,
      "learning_rate": 0.00011838309446340408,
      "loss": 0.365,
      "step": 6990
    },
    {
      "epoch": 0.8908402532531577,
      "grad_norm": 0.23556026816368103,
      "learning_rate": 0.00011818530808543911,
      "loss": 0.3743,
      "step": 7000
    },
    {
      "epoch": 0.8908402532531577,
      "eval_loss": 0.36050716042518616,
      "eval_runtime": 736.8774,
      "eval_samples_per_second": 10.664,
      "eval_steps_per_second": 5.332,
      "step": 7000
    },
    {
      "epoch": 0.8921128821863765,
      "grad_norm": 0.23027437925338745,
      "learning_rate": 0.00011798744810699172,
      "loss": 0.3747,
      "step": 7010
    },
    {
      "epoch": 0.8933855111195953,
      "grad_norm": 0.1934041976928711,
      "learning_rate": 0.00011778951532885054,
      "loss": 0.3564,
      "step": 7020
    },
    {
      "epoch": 0.8946581400528141,
      "grad_norm": 0.23010362684726715,
      "learning_rate": 0.00011759151055209903,
      "loss": 0.3836,
      "step": 7030
    },
    {
      "epoch": 0.8959307689860329,
      "grad_norm": 0.21454490721225739,
      "learning_rate": 0.00011739343457811192,
      "loss": 0.3482,
      "step": 7040
    },
    {
      "epoch": 0.8972033979192517,
      "grad_norm": 0.31548744440078735,
      "learning_rate": 0.00011719528820855212,
      "loss": 0.3754,
      "step": 7050
    },
    {
      "epoch": 0.8984760268524705,
      "grad_norm": 0.2033730149269104,
      "learning_rate": 0.00011699707224536749,
      "loss": 0.3478,
      "step": 7060
    },
    {
      "epoch": 0.8997486557856893,
      "grad_norm": 0.22619619965553284,
      "learning_rate": 0.00011679878749078752,
      "loss": 0.3733,
      "step": 7070
    },
    {
      "epoch": 0.9010212847189081,
      "grad_norm": 0.1954258233308792,
      "learning_rate": 0.00011660043474732012,
      "loss": 0.3555,
      "step": 7080
    },
    {
      "epoch": 0.9022939136521269,
      "grad_norm": 0.27478528022766113,
      "learning_rate": 0.00011640201481774838,
      "loss": 0.3802,
      "step": 7090
    },
    {
      "epoch": 0.9035665425853456,
      "grad_norm": 0.2439286708831787,
      "learning_rate": 0.00011620352850512723,
      "loss": 0.3588,
      "step": 7100
    },
    {
      "epoch": 0.9048391715185645,
      "grad_norm": 0.27026402950286865,
      "learning_rate": 0.00011600497661278044,
      "loss": 0.3618,
      "step": 7110
    },
    {
      "epoch": 0.9061118004517833,
      "grad_norm": 0.20071102678775787,
      "learning_rate": 0.00011580635994429703,
      "loss": 0.3561,
      "step": 7120
    },
    {
      "epoch": 0.9073844293850021,
      "grad_norm": 0.2071961909532547,
      "learning_rate": 0.0001156076793035283,
      "loss": 0.3601,
      "step": 7130
    },
    {
      "epoch": 0.9086570583182209,
      "grad_norm": 0.19979754090309143,
      "learning_rate": 0.00011540893549458433,
      "loss": 0.3453,
      "step": 7140
    },
    {
      "epoch": 0.9099296872514396,
      "grad_norm": 0.23921194672584534,
      "learning_rate": 0.000115210129321831,
      "loss": 0.3519,
      "step": 7150
    },
    {
      "epoch": 0.9112023161846584,
      "grad_norm": 0.16881299018859863,
      "learning_rate": 0.00011501126158988653,
      "loss": 0.3714,
      "step": 7160
    },
    {
      "epoch": 0.9124749451178773,
      "grad_norm": 0.2075909972190857,
      "learning_rate": 0.00011481233310361825,
      "loss": 0.3553,
      "step": 7170
    },
    {
      "epoch": 0.9137475740510961,
      "grad_norm": 0.22676944732666016,
      "learning_rate": 0.00011461334466813944,
      "loss": 0.3775,
      "step": 7180
    },
    {
      "epoch": 0.9150202029843149,
      "grad_norm": 0.148894265294075,
      "learning_rate": 0.00011441429708880602,
      "loss": 0.365,
      "step": 7190
    },
    {
      "epoch": 0.9162928319175336,
      "grad_norm": 0.2398858517408371,
      "learning_rate": 0.00011421519117121315,
      "loss": 0.3427,
      "step": 7200
    },
    {
      "epoch": 0.9175654608507524,
      "grad_norm": 0.19390930235385895,
      "learning_rate": 0.00011401602772119229,
      "loss": 0.3427,
      "step": 7210
    },
    {
      "epoch": 0.9188380897839712,
      "grad_norm": 0.23127609491348267,
      "learning_rate": 0.00011381680754480756,
      "loss": 0.3561,
      "step": 7220
    },
    {
      "epoch": 0.9201107187171901,
      "grad_norm": 0.22504013776779175,
      "learning_rate": 0.00011361753144835283,
      "loss": 0.3591,
      "step": 7230
    },
    {
      "epoch": 0.9213833476504089,
      "grad_norm": 0.2390899360179901,
      "learning_rate": 0.00011341820023834819,
      "loss": 0.3618,
      "step": 7240
    },
    {
      "epoch": 0.9226559765836276,
      "grad_norm": 0.22557511925697327,
      "learning_rate": 0.00011321881472153682,
      "loss": 0.3568,
      "step": 7250
    },
    {
      "epoch": 0.9239286055168464,
      "grad_norm": 0.16617654263973236,
      "learning_rate": 0.0001130193757048817,
      "loss": 0.365,
      "step": 7260
    },
    {
      "epoch": 0.9252012344500652,
      "grad_norm": 0.24062912166118622,
      "learning_rate": 0.00011281988399556232,
      "loss": 0.3517,
      "step": 7270
    },
    {
      "epoch": 0.926473863383284,
      "grad_norm": 0.18292871117591858,
      "learning_rate": 0.00011262034040097142,
      "loss": 0.3251,
      "step": 7280
    },
    {
      "epoch": 0.9277464923165029,
      "grad_norm": 0.18963691592216492,
      "learning_rate": 0.0001124207457287118,
      "loss": 0.3643,
      "step": 7290
    },
    {
      "epoch": 0.9290191212497216,
      "grad_norm": 0.22133979201316833,
      "learning_rate": 0.00011222110078659285,
      "loss": 0.3731,
      "step": 7300
    },
    {
      "epoch": 0.9302917501829404,
      "grad_norm": 0.1875661462545395,
      "learning_rate": 0.00011202140638262759,
      "loss": 0.3634,
      "step": 7310
    },
    {
      "epoch": 0.9315643791161592,
      "grad_norm": 0.22763769328594208,
      "learning_rate": 0.0001118216633250291,
      "loss": 0.3639,
      "step": 7320
    },
    {
      "epoch": 0.932837008049378,
      "grad_norm": 0.23210401833057404,
      "learning_rate": 0.00011162187242220739,
      "loss": 0.3466,
      "step": 7330
    },
    {
      "epoch": 0.9341096369825967,
      "grad_norm": 0.2607424855232239,
      "learning_rate": 0.00011142203448276616,
      "loss": 0.3546,
      "step": 7340
    },
    {
      "epoch": 0.9353822659158156,
      "grad_norm": 0.21639031171798706,
      "learning_rate": 0.0001112221503154994,
      "loss": 0.3614,
      "step": 7350
    },
    {
      "epoch": 0.9366548948490344,
      "grad_norm": 0.2169739007949829,
      "learning_rate": 0.00011102222072938832,
      "loss": 0.3785,
      "step": 7360
    },
    {
      "epoch": 0.9379275237822532,
      "grad_norm": 0.24327148497104645,
      "learning_rate": 0.00011082224653359783,
      "loss": 0.3545,
      "step": 7370
    },
    {
      "epoch": 0.939200152715472,
      "grad_norm": 0.21812450885772705,
      "learning_rate": 0.0001106222285374734,
      "loss": 0.3434,
      "step": 7380
    },
    {
      "epoch": 0.9404727816486907,
      "grad_norm": 0.25485605001449585,
      "learning_rate": 0.00011042216755053785,
      "loss": 0.3584,
      "step": 7390
    },
    {
      "epoch": 0.9417454105819095,
      "grad_norm": 0.19871872663497925,
      "learning_rate": 0.00011022206438248792,
      "loss": 0.3587,
      "step": 7400
    },
    {
      "epoch": 0.9430180395151284,
      "grad_norm": 0.3731781542301178,
      "learning_rate": 0.00011002191984319113,
      "loss": 0.362,
      "step": 7410
    },
    {
      "epoch": 0.9442906684483472,
      "grad_norm": 0.2100808322429657,
      "learning_rate": 0.00010982173474268236,
      "loss": 0.3479,
      "step": 7420
    },
    {
      "epoch": 0.945563297381566,
      "grad_norm": 0.19932962954044342,
      "learning_rate": 0.0001096215098911607,
      "loss": 0.3515,
      "step": 7430
    },
    {
      "epoch": 0.9468359263147847,
      "grad_norm": 0.25290435552597046,
      "learning_rate": 0.00010942124609898617,
      "loss": 0.3757,
      "step": 7440
    },
    {
      "epoch": 0.9481085552480035,
      "grad_norm": 0.25227218866348267,
      "learning_rate": 0.00010922094417667627,
      "loss": 0.3661,
      "step": 7450
    },
    {
      "epoch": 0.9493811841812224,
      "grad_norm": 0.18592019379138947,
      "learning_rate": 0.00010902060493490296,
      "loss": 0.3504,
      "step": 7460
    },
    {
      "epoch": 0.9506538131144412,
      "grad_norm": 0.19399793446063995,
      "learning_rate": 0.00010882022918448913,
      "loss": 0.3587,
      "step": 7470
    },
    {
      "epoch": 0.95192644204766,
      "grad_norm": 0.2024637758731842,
      "learning_rate": 0.00010861981773640548,
      "loss": 0.3459,
      "step": 7480
    },
    {
      "epoch": 0.9531990709808787,
      "grad_norm": 0.24334070086479187,
      "learning_rate": 0.00010841937140176716,
      "loss": 0.365,
      "step": 7490
    },
    {
      "epoch": 0.9544716999140975,
      "grad_norm": 0.20380844175815582,
      "learning_rate": 0.00010821889099183061,
      "loss": 0.363,
      "step": 7500
    },
    {
      "epoch": 0.9544716999140975,
      "eval_loss": 0.3584687113761902,
      "eval_runtime": 737.0714,
      "eval_samples_per_second": 10.661,
      "eval_steps_per_second": 5.331,
      "step": 7500
    },
    {
      "epoch": 0.9557443288473163,
      "grad_norm": 0.20537865161895752,
      "learning_rate": 0.00010801837731799003,
      "loss": 0.3533,
      "step": 7510
    },
    {
      "epoch": 0.9570169577805352,
      "grad_norm": 0.24753212928771973,
      "learning_rate": 0.00010781783119177436,
      "loss": 0.3676,
      "step": 7520
    },
    {
      "epoch": 0.958289586713754,
      "grad_norm": 0.18498533964157104,
      "learning_rate": 0.00010761725342484384,
      "loss": 0.3631,
      "step": 7530
    },
    {
      "epoch": 0.9595622156469727,
      "grad_norm": 0.19725443422794342,
      "learning_rate": 0.00010741664482898675,
      "loss": 0.3358,
      "step": 7540
    },
    {
      "epoch": 0.9608348445801915,
      "grad_norm": 0.23846648633480072,
      "learning_rate": 0.0001072160062161162,
      "loss": 0.3866,
      "step": 7550
    },
    {
      "epoch": 0.9621074735134103,
      "grad_norm": 0.22702769935131073,
      "learning_rate": 0.00010701533839826674,
      "loss": 0.3715,
      "step": 7560
    },
    {
      "epoch": 0.9633801024466291,
      "grad_norm": 0.24441230297088623,
      "learning_rate": 0.00010681464218759116,
      "loss": 0.3727,
      "step": 7570
    },
    {
      "epoch": 0.964652731379848,
      "grad_norm": 0.1842740774154663,
      "learning_rate": 0.00010661391839635708,
      "loss": 0.3333,
      "step": 7580
    },
    {
      "epoch": 0.9659253603130667,
      "grad_norm": 0.22790148854255676,
      "learning_rate": 0.00010641316783694385,
      "loss": 0.3733,
      "step": 7590
    },
    {
      "epoch": 0.9671979892462855,
      "grad_norm": 0.24052435159683228,
      "learning_rate": 0.00010621239132183909,
      "loss": 0.3712,
      "step": 7600
    },
    {
      "epoch": 0.9684706181795043,
      "grad_norm": 0.21842651069164276,
      "learning_rate": 0.00010601158966363549,
      "loss": 0.3867,
      "step": 7610
    },
    {
      "epoch": 0.9697432471127231,
      "grad_norm": 0.2476186454296112,
      "learning_rate": 0.00010581076367502749,
      "loss": 0.3724,
      "step": 7620
    },
    {
      "epoch": 0.9710158760459419,
      "grad_norm": 0.20767971873283386,
      "learning_rate": 0.000105609914168808,
      "loss": 0.3528,
      "step": 7630
    },
    {
      "epoch": 0.9722885049791608,
      "grad_norm": 0.22790779173374176,
      "learning_rate": 0.00010540904195786521,
      "loss": 0.3572,
      "step": 7640
    },
    {
      "epoch": 0.9735611339123795,
      "grad_norm": 0.2069920152425766,
      "learning_rate": 0.000105208147855179,
      "loss": 0.3466,
      "step": 7650
    },
    {
      "epoch": 0.9748337628455983,
      "grad_norm": 0.2580191195011139,
      "learning_rate": 0.00010500723267381798,
      "loss": 0.3432,
      "step": 7660
    },
    {
      "epoch": 0.9761063917788171,
      "grad_norm": 0.22470463812351227,
      "learning_rate": 0.00010480629722693614,
      "loss": 0.3855,
      "step": 7670
    },
    {
      "epoch": 0.9773790207120359,
      "grad_norm": 0.22707898914813995,
      "learning_rate": 0.00010460534232776929,
      "loss": 0.3625,
      "step": 7680
    },
    {
      "epoch": 0.9786516496452546,
      "grad_norm": 0.23037223517894745,
      "learning_rate": 0.00010440436878963217,
      "loss": 0.3545,
      "step": 7690
    },
    {
      "epoch": 0.9799242785784735,
      "grad_norm": 0.24983076751232147,
      "learning_rate": 0.00010420337742591487,
      "loss": 0.3513,
      "step": 7700
    },
    {
      "epoch": 0.9811969075116923,
      "grad_norm": 0.18835309147834778,
      "learning_rate": 0.00010400236905007954,
      "loss": 0.3325,
      "step": 7710
    },
    {
      "epoch": 0.9824695364449111,
      "grad_norm": 0.21282251179218292,
      "learning_rate": 0.00010380134447565734,
      "loss": 0.3866,
      "step": 7720
    },
    {
      "epoch": 0.9837421653781299,
      "grad_norm": 0.28080248832702637,
      "learning_rate": 0.0001036003045162449,
      "loss": 0.3862,
      "step": 7730
    },
    {
      "epoch": 0.9850147943113486,
      "grad_norm": 0.20284518599510193,
      "learning_rate": 0.00010339924998550112,
      "loss": 0.3781,
      "step": 7740
    },
    {
      "epoch": 0.9862874232445674,
      "grad_norm": 0.16810981929302216,
      "learning_rate": 0.00010319818169714393,
      "loss": 0.3526,
      "step": 7750
    },
    {
      "epoch": 0.9875600521777863,
      "grad_norm": 0.22093597054481506,
      "learning_rate": 0.00010299710046494682,
      "loss": 0.3391,
      "step": 7760
    },
    {
      "epoch": 0.9888326811110051,
      "grad_norm": 0.24768371880054474,
      "learning_rate": 0.00010279600710273581,
      "loss": 0.3757,
      "step": 7770
    },
    {
      "epoch": 0.9901053100442239,
      "grad_norm": 0.21269327402114868,
      "learning_rate": 0.0001025949024243859,
      "loss": 0.3695,
      "step": 7780
    },
    {
      "epoch": 0.9913779389774426,
      "grad_norm": 0.25447532534599304,
      "learning_rate": 0.00010239378724381801,
      "loss": 0.3839,
      "step": 7790
    },
    {
      "epoch": 0.9926505679106614,
      "grad_norm": 0.26521599292755127,
      "learning_rate": 0.0001021926623749954,
      "loss": 0.3655,
      "step": 7800
    },
    {
      "epoch": 0.9939231968438802,
      "grad_norm": 0.21922965347766876,
      "learning_rate": 0.0001019915286319207,
      "loss": 0.3653,
      "step": 7810
    },
    {
      "epoch": 0.9951958257770991,
      "grad_norm": 0.21862728893756866,
      "learning_rate": 0.00010179038682863237,
      "loss": 0.3665,
      "step": 7820
    },
    {
      "epoch": 0.9964684547103179,
      "grad_norm": 0.25378361344337463,
      "learning_rate": 0.00010158923777920151,
      "loss": 0.3537,
      "step": 7830
    },
    {
      "epoch": 0.9977410836435366,
      "grad_norm": 0.22143536806106567,
      "learning_rate": 0.00010138808229772851,
      "loss": 0.3448,
      "step": 7840
    },
    {
      "epoch": 0.9990137125767554,
      "grad_norm": 0.2566254436969757,
      "learning_rate": 0.0001011869211983399,
      "loss": 0.3427,
      "step": 7850
    },
    {
      "epoch": 1.0002545257866438,
      "grad_norm": 0.1951414942741394,
      "learning_rate": 0.00010098575529518482,
      "loss": 0.355,
      "step": 7860
    },
    {
      "epoch": 1.0015271547198625,
      "grad_norm": 0.19621381163597107,
      "learning_rate": 0.00010078458540243192,
      "loss": 0.3441,
      "step": 7870
    },
    {
      "epoch": 1.0027997836530813,
      "grad_norm": 0.20071032643318176,
      "learning_rate": 0.00010058341233426602,
      "loss": 0.3426,
      "step": 7880
    },
    {
      "epoch": 1.0040724125863,
      "grad_norm": 0.20974516868591309,
      "learning_rate": 0.00010038223690488471,
      "loss": 0.3328,
      "step": 7890
    },
    {
      "epoch": 1.0053450415195189,
      "grad_norm": 0.23683008551597595,
      "learning_rate": 0.00010018105992849523,
      "loss": 0.3343,
      "step": 7900
    },
    {
      "epoch": 1.0066176704527376,
      "grad_norm": 0.19824840128421783,
      "learning_rate": 9.997988221931098e-05,
      "loss": 0.3175,
      "step": 7910
    },
    {
      "epoch": 1.0078902993859566,
      "grad_norm": 0.2043451964855194,
      "learning_rate": 9.977870459154843e-05,
      "loss": 0.3462,
      "step": 7920
    },
    {
      "epoch": 1.0091629283191754,
      "grad_norm": 0.21038702130317688,
      "learning_rate": 9.957752785942366e-05,
      "loss": 0.351,
      "step": 7930
    },
    {
      "epoch": 1.0104355572523942,
      "grad_norm": 0.21187201142311096,
      "learning_rate": 9.937635283714914e-05,
      "loss": 0.3192,
      "step": 7940
    },
    {
      "epoch": 1.011708186185613,
      "grad_norm": 0.22820158302783966,
      "learning_rate": 9.917518033893034e-05,
      "loss": 0.3426,
      "step": 7950
    },
    {
      "epoch": 1.0129808151188318,
      "grad_norm": 0.18901021778583527,
      "learning_rate": 9.897401117896271e-05,
      "loss": 0.3266,
      "step": 7960
    },
    {
      "epoch": 1.0142534440520505,
      "grad_norm": 0.23531650006771088,
      "learning_rate": 9.877284617142802e-05,
      "loss": 0.3287,
      "step": 7970
    },
    {
      "epoch": 1.0155260729852693,
      "grad_norm": 0.19738832116127014,
      "learning_rate": 9.857168613049128e-05,
      "loss": 0.3322,
      "step": 7980
    },
    {
      "epoch": 1.016798701918488,
      "grad_norm": 0.27529582381248474,
      "learning_rate": 9.83705318702974e-05,
      "loss": 0.3514,
      "step": 7990
    },
    {
      "epoch": 1.0180713308517069,
      "grad_norm": 0.20934079587459564,
      "learning_rate": 9.816938420496785e-05,
      "loss": 0.3283,
      "step": 8000
    },
    {
      "epoch": 1.0180713308517069,
      "eval_loss": 0.3571886718273163,
      "eval_runtime": 759.1719,
      "eval_samples_per_second": 10.351,
      "eval_steps_per_second": 5.175,
      "step": 8000
    },
    {
      "epoch": 1.0193439597849256,
      "grad_norm": 0.2376367449760437,
      "learning_rate": 9.796824394859756e-05,
      "loss": 0.3395,
      "step": 8010
    },
    {
      "epoch": 1.0206165887181444,
      "grad_norm": 0.24392855167388916,
      "learning_rate": 9.77671119152513e-05,
      "loss": 0.3395,
      "step": 8020
    },
    {
      "epoch": 1.0218892176513632,
      "grad_norm": 0.17656071484088898,
      "learning_rate": 9.756598891896066e-05,
      "loss": 0.3311,
      "step": 8030
    },
    {
      "epoch": 1.0231618465845822,
      "grad_norm": 0.20507854223251343,
      "learning_rate": 9.73648757737206e-05,
      "loss": 0.3406,
      "step": 8040
    },
    {
      "epoch": 1.024434475517801,
      "grad_norm": 0.24060803651809692,
      "learning_rate": 9.71637732934862e-05,
      "loss": 0.3259,
      "step": 8050
    },
    {
      "epoch": 1.0257071044510198,
      "grad_norm": 0.24888327717781067,
      "learning_rate": 9.696268229216951e-05,
      "loss": 0.3417,
      "step": 8060
    },
    {
      "epoch": 1.0269797333842385,
      "grad_norm": 0.21758408844470978,
      "learning_rate": 9.676160358363596e-05,
      "loss": 0.3278,
      "step": 8070
    },
    {
      "epoch": 1.0282523623174573,
      "grad_norm": 0.21953977644443512,
      "learning_rate": 9.656053798170129e-05,
      "loss": 0.3254,
      "step": 8080
    },
    {
      "epoch": 1.029524991250676,
      "grad_norm": 0.23336628079414368,
      "learning_rate": 9.635948630012817e-05,
      "loss": 0.3231,
      "step": 8090
    },
    {
      "epoch": 1.0307976201838949,
      "grad_norm": 0.22685055434703827,
      "learning_rate": 9.615844935262299e-05,
      "loss": 0.341,
      "step": 8100
    },
    {
      "epoch": 1.0320702491171136,
      "grad_norm": 0.3170505464076996,
      "learning_rate": 9.59574279528325e-05,
      "loss": 0.3419,
      "step": 8110
    },
    {
      "epoch": 1.0333428780503324,
      "grad_norm": 0.24626627564430237,
      "learning_rate": 9.575642291434047e-05,
      "loss": 0.3204,
      "step": 8120
    },
    {
      "epoch": 1.0346155069835512,
      "grad_norm": 0.29209116101264954,
      "learning_rate": 9.555543505066447e-05,
      "loss": 0.3253,
      "step": 8130
    },
    {
      "epoch": 1.03588813591677,
      "grad_norm": 0.21843388676643372,
      "learning_rate": 9.535446517525255e-05,
      "loss": 0.3408,
      "step": 8140
    },
    {
      "epoch": 1.0371607648499888,
      "grad_norm": 0.2555292546749115,
      "learning_rate": 9.515351410148002e-05,
      "loss": 0.3532,
      "step": 8150
    },
    {
      "epoch": 1.0384333937832078,
      "grad_norm": 0.19754023849964142,
      "learning_rate": 9.495258264264603e-05,
      "loss": 0.3237,
      "step": 8160
    },
    {
      "epoch": 1.0397060227164265,
      "grad_norm": 0.2195679396390915,
      "learning_rate": 9.475167161197037e-05,
      "loss": 0.3597,
      "step": 8170
    },
    {
      "epoch": 1.0409786516496453,
      "grad_norm": 0.21435309946537018,
      "learning_rate": 9.455078182259011e-05,
      "loss": 0.3349,
      "step": 8180
    },
    {
      "epoch": 1.042251280582864,
      "grad_norm": 0.23673228919506073,
      "learning_rate": 9.434991408755646e-05,
      "loss": 0.3482,
      "step": 8190
    },
    {
      "epoch": 1.0435239095160829,
      "grad_norm": 0.272311806678772,
      "learning_rate": 9.414906921983124e-05,
      "loss": 0.3416,
      "step": 8200
    },
    {
      "epoch": 1.0447965384493016,
      "grad_norm": 0.16197986900806427,
      "learning_rate": 9.394824803228379e-05,
      "loss": 0.3402,
      "step": 8210
    },
    {
      "epoch": 1.0460691673825204,
      "grad_norm": 0.2721675634384155,
      "learning_rate": 9.374745133768761e-05,
      "loss": 0.3454,
      "step": 8220
    },
    {
      "epoch": 1.0473417963157392,
      "grad_norm": 0.21302758157253265,
      "learning_rate": 9.354667994871706e-05,
      "loss": 0.3477,
      "step": 8230
    },
    {
      "epoch": 1.048614425248958,
      "grad_norm": 0.24618226289749146,
      "learning_rate": 9.334593467794407e-05,
      "loss": 0.3396,
      "step": 8240
    },
    {
      "epoch": 1.0498870541821768,
      "grad_norm": 0.22572503983974457,
      "learning_rate": 9.314521633783486e-05,
      "loss": 0.3232,
      "step": 8250
    },
    {
      "epoch": 1.0511596831153955,
      "grad_norm": 0.2235393226146698,
      "learning_rate": 9.294452574074672e-05,
      "loss": 0.3404,
      "step": 8260
    },
    {
      "epoch": 1.0524323120486145,
      "grad_norm": 0.2555708587169647,
      "learning_rate": 9.274386369892454e-05,
      "loss": 0.3345,
      "step": 8270
    },
    {
      "epoch": 1.0537049409818333,
      "grad_norm": 0.24907317757606506,
      "learning_rate": 9.254323102449778e-05,
      "loss": 0.3599,
      "step": 8280
    },
    {
      "epoch": 1.054977569915052,
      "grad_norm": 0.2510485351085663,
      "learning_rate": 9.234262852947692e-05,
      "loss": 0.3465,
      "step": 8290
    },
    {
      "epoch": 1.0562501988482709,
      "grad_norm": 0.21919284760951996,
      "learning_rate": 9.214205702575036e-05,
      "loss": 0.3197,
      "step": 8300
    },
    {
      "epoch": 1.0575228277814896,
      "grad_norm": 0.2136908620595932,
      "learning_rate": 9.1941517325081e-05,
      "loss": 0.3446,
      "step": 8310
    },
    {
      "epoch": 1.0587954567147084,
      "grad_norm": 0.2982677221298218,
      "learning_rate": 9.174101023910319e-05,
      "loss": 0.3597,
      "step": 8320
    },
    {
      "epoch": 1.0600680856479272,
      "grad_norm": 0.3058708608150482,
      "learning_rate": 9.15405365793191e-05,
      "loss": 0.3235,
      "step": 8330
    },
    {
      "epoch": 1.061340714581146,
      "grad_norm": 0.24277080595493317,
      "learning_rate": 9.13400971570957e-05,
      "loss": 0.3453,
      "step": 8340
    },
    {
      "epoch": 1.0626133435143648,
      "grad_norm": 0.20666015148162842,
      "learning_rate": 9.11396927836614e-05,
      "loss": 0.3209,
      "step": 8350
    },
    {
      "epoch": 1.0638859724475835,
      "grad_norm": 0.22842544317245483,
      "learning_rate": 9.093932427010265e-05,
      "loss": 0.3575,
      "step": 8360
    },
    {
      "epoch": 1.0651586013808023,
      "grad_norm": 0.2815300524234772,
      "learning_rate": 9.073899242736098e-05,
      "loss": 0.3258,
      "step": 8370
    },
    {
      "epoch": 1.066431230314021,
      "grad_norm": 0.24458613991737366,
      "learning_rate": 9.053869806622933e-05,
      "loss": 0.3303,
      "step": 8380
    },
    {
      "epoch": 1.0677038592472399,
      "grad_norm": 0.21305173635482788,
      "learning_rate": 9.033844199734896e-05,
      "loss": 0.3456,
      "step": 8390
    },
    {
      "epoch": 1.0689764881804589,
      "grad_norm": 0.20521949231624603,
      "learning_rate": 9.01382250312062e-05,
      "loss": 0.3319,
      "step": 8400
    },
    {
      "epoch": 1.0702491171136777,
      "grad_norm": 0.21193280816078186,
      "learning_rate": 8.993804797812907e-05,
      "loss": 0.319,
      "step": 8410
    },
    {
      "epoch": 1.0715217460468964,
      "grad_norm": 0.27018386125564575,
      "learning_rate": 8.973791164828416e-05,
      "loss": 0.3207,
      "step": 8420
    },
    {
      "epoch": 1.0727943749801152,
      "grad_norm": 0.2347859889268875,
      "learning_rate": 8.953781685167316e-05,
      "loss": 0.3273,
      "step": 8430
    },
    {
      "epoch": 1.074067003913334,
      "grad_norm": 0.2275753915309906,
      "learning_rate": 8.933776439812961e-05,
      "loss": 0.3346,
      "step": 8440
    },
    {
      "epoch": 1.0753396328465528,
      "grad_norm": 0.24461352825164795,
      "learning_rate": 8.91377550973158e-05,
      "loss": 0.3404,
      "step": 8450
    },
    {
      "epoch": 1.0766122617797715,
      "grad_norm": 0.26793304085731506,
      "learning_rate": 8.893778975871922e-05,
      "loss": 0.3456,
      "step": 8460
    },
    {
      "epoch": 1.0778848907129903,
      "grad_norm": 0.27843227982521057,
      "learning_rate": 8.873786919164963e-05,
      "loss": 0.3326,
      "step": 8470
    },
    {
      "epoch": 1.079157519646209,
      "grad_norm": 0.18955042958259583,
      "learning_rate": 8.853799420523545e-05,
      "loss": 0.332,
      "step": 8480
    },
    {
      "epoch": 1.0804301485794279,
      "grad_norm": 0.24182389676570892,
      "learning_rate": 8.833816560842065e-05,
      "loss": 0.3309,
      "step": 8490
    },
    {
      "epoch": 1.0817027775126467,
      "grad_norm": 0.27507737278938293,
      "learning_rate": 8.813838420996146e-05,
      "loss": 0.3513,
      "step": 8500
    },
    {
      "epoch": 1.0817027775126467,
      "eval_loss": 0.35580840706825256,
      "eval_runtime": 938.2122,
      "eval_samples_per_second": 8.376,
      "eval_steps_per_second": 4.188,
      "step": 8500
    },
    {
      "epoch": 1.0829754064458657,
      "grad_norm": 0.23276287317276,
      "learning_rate": 8.793865081842302e-05,
      "loss": 0.3438,
      "step": 8510
    },
    {
      "epoch": 1.0842480353790844,
      "grad_norm": 0.2824460566043854,
      "learning_rate": 8.773896624217635e-05,
      "loss": 0.3569,
      "step": 8520
    },
    {
      "epoch": 1.0855206643123032,
      "grad_norm": 0.23059982061386108,
      "learning_rate": 8.753933128939472e-05,
      "loss": 0.3379,
      "step": 8530
    },
    {
      "epoch": 1.086793293245522,
      "grad_norm": 0.2591283321380615,
      "learning_rate": 8.733974676805065e-05,
      "loss": 0.3401,
      "step": 8540
    },
    {
      "epoch": 1.0880659221787408,
      "grad_norm": 0.23304666578769684,
      "learning_rate": 8.714021348591251e-05,
      "loss": 0.3569,
      "step": 8550
    },
    {
      "epoch": 1.0893385511119595,
      "grad_norm": 0.18124650418758392,
      "learning_rate": 8.694073225054131e-05,
      "loss": 0.3123,
      "step": 8560
    },
    {
      "epoch": 1.0906111800451783,
      "grad_norm": 0.25139182806015015,
      "learning_rate": 8.674130386928745e-05,
      "loss": 0.3274,
      "step": 8570
    },
    {
      "epoch": 1.091883808978397,
      "grad_norm": 0.2181069403886795,
      "learning_rate": 8.654192914928739e-05,
      "loss": 0.3386,
      "step": 8580
    },
    {
      "epoch": 1.0931564379116159,
      "grad_norm": 0.26133212447166443,
      "learning_rate": 8.634260889746037e-05,
      "loss": 0.3387,
      "step": 8590
    },
    {
      "epoch": 1.0944290668448347,
      "grad_norm": 0.20808742940425873,
      "learning_rate": 8.614334392050525e-05,
      "loss": 0.3428,
      "step": 8600
    },
    {
      "epoch": 1.0957016957780534,
      "grad_norm": 0.2769017815589905,
      "learning_rate": 8.594413502489707e-05,
      "loss": 0.325,
      "step": 8610
    },
    {
      "epoch": 1.0969743247112722,
      "grad_norm": 0.2104777991771698,
      "learning_rate": 8.574498301688408e-05,
      "loss": 0.331,
      "step": 8620
    },
    {
      "epoch": 1.0982469536444912,
      "grad_norm": 0.30818411707878113,
      "learning_rate": 8.554588870248412e-05,
      "loss": 0.3437,
      "step": 8630
    },
    {
      "epoch": 1.09951958257771,
      "grad_norm": 0.2133590430021286,
      "learning_rate": 8.534685288748159e-05,
      "loss": 0.3424,
      "step": 8640
    },
    {
      "epoch": 1.1007922115109288,
      "grad_norm": 0.25293365120887756,
      "learning_rate": 8.514787637742415e-05,
      "loss": 0.3538,
      "step": 8650
    },
    {
      "epoch": 1.1020648404441475,
      "grad_norm": 0.2787363827228546,
      "learning_rate": 8.494895997761936e-05,
      "loss": 0.3334,
      "step": 8660
    },
    {
      "epoch": 1.1033374693773663,
      "grad_norm": 0.20417428016662598,
      "learning_rate": 8.475010449313165e-05,
      "loss": 0.3227,
      "step": 8670
    },
    {
      "epoch": 1.104610098310585,
      "grad_norm": 0.2108258157968521,
      "learning_rate": 8.455131072877879e-05,
      "loss": 0.3457,
      "step": 8680
    },
    {
      "epoch": 1.1058827272438039,
      "grad_norm": 0.22652651369571686,
      "learning_rate": 8.435257948912876e-05,
      "loss": 0.339,
      "step": 8690
    },
    {
      "epoch": 1.1071553561770227,
      "grad_norm": 0.25278240442276,
      "learning_rate": 8.41539115784965e-05,
      "loss": 0.3547,
      "step": 8700
    },
    {
      "epoch": 1.1084279851102414,
      "grad_norm": 0.25854960083961487,
      "learning_rate": 8.395530780094062e-05,
      "loss": 0.3462,
      "step": 8710
    },
    {
      "epoch": 1.1097006140434602,
      "grad_norm": 0.2673235237598419,
      "learning_rate": 8.37567689602603e-05,
      "loss": 0.3411,
      "step": 8720
    },
    {
      "epoch": 1.110973242976679,
      "grad_norm": 0.24451950192451477,
      "learning_rate": 8.355829585999171e-05,
      "loss": 0.3403,
      "step": 8730
    },
    {
      "epoch": 1.1122458719098978,
      "grad_norm": 0.282997727394104,
      "learning_rate": 8.335988930340509e-05,
      "loss": 0.3266,
      "step": 8740
    },
    {
      "epoch": 1.1135185008431168,
      "grad_norm": 0.22564734518527985,
      "learning_rate": 8.31615500935013e-05,
      "loss": 0.3162,
      "step": 8750
    },
    {
      "epoch": 1.1147911297763355,
      "grad_norm": 0.2557711899280548,
      "learning_rate": 8.296327903300858e-05,
      "loss": 0.3385,
      "step": 8760
    },
    {
      "epoch": 1.1160637587095543,
      "grad_norm": 0.21239058673381805,
      "learning_rate": 8.276507692437954e-05,
      "loss": 0.3108,
      "step": 8770
    },
    {
      "epoch": 1.117336387642773,
      "grad_norm": 0.31949934363365173,
      "learning_rate": 8.256694456978753e-05,
      "loss": 0.3381,
      "step": 8780
    },
    {
      "epoch": 1.1186090165759919,
      "grad_norm": 0.2067975252866745,
      "learning_rate": 8.236888277112369e-05,
      "loss": 0.3114,
      "step": 8790
    },
    {
      "epoch": 1.1198816455092107,
      "grad_norm": 0.28111717104911804,
      "learning_rate": 8.217089232999353e-05,
      "loss": 0.3489,
      "step": 8800
    },
    {
      "epoch": 1.1211542744424294,
      "grad_norm": 0.23840267956256866,
      "learning_rate": 8.197297404771382e-05,
      "loss": 0.3406,
      "step": 8810
    },
    {
      "epoch": 1.1224269033756482,
      "grad_norm": 0.26257771253585815,
      "learning_rate": 8.17751287253093e-05,
      "loss": 0.334,
      "step": 8820
    },
    {
      "epoch": 1.123699532308867,
      "grad_norm": 0.24831408262252808,
      "learning_rate": 8.157735716350935e-05,
      "loss": 0.3242,
      "step": 8830
    },
    {
      "epoch": 1.1249721612420858,
      "grad_norm": 0.21757815778255463,
      "learning_rate": 8.137966016274489e-05,
      "loss": 0.3058,
      "step": 8840
    },
    {
      "epoch": 1.1262447901753045,
      "grad_norm": 0.31710243225097656,
      "learning_rate": 8.118203852314498e-05,
      "loss": 0.3413,
      "step": 8850
    },
    {
      "epoch": 1.1275174191085235,
      "grad_norm": 0.2456531524658203,
      "learning_rate": 8.098449304453381e-05,
      "loss": 0.3446,
      "step": 8860
    },
    {
      "epoch": 1.1287900480417423,
      "grad_norm": 0.24682988226413727,
      "learning_rate": 8.078702452642726e-05,
      "loss": 0.3362,
      "step": 8870
    },
    {
      "epoch": 1.130062676974961,
      "grad_norm": 0.24206803739070892,
      "learning_rate": 8.05896337680297e-05,
      "loss": 0.3538,
      "step": 8880
    },
    {
      "epoch": 1.1313353059081799,
      "grad_norm": 0.21377751231193542,
      "learning_rate": 8.039232156823078e-05,
      "loss": 0.3315,
      "step": 8890
    },
    {
      "epoch": 1.1326079348413987,
      "grad_norm": 0.2158677577972412,
      "learning_rate": 8.019508872560232e-05,
      "loss": 0.3195,
      "step": 8900
    },
    {
      "epoch": 1.1338805637746174,
      "grad_norm": 0.2542739510536194,
      "learning_rate": 7.999793603839482e-05,
      "loss": 0.3372,
      "step": 8910
    },
    {
      "epoch": 1.1351531927078362,
      "grad_norm": 0.17928127944469452,
      "learning_rate": 7.980086430453444e-05,
      "loss": 0.3209,
      "step": 8920
    },
    {
      "epoch": 1.136425821641055,
      "grad_norm": 0.21578428149223328,
      "learning_rate": 7.96038743216197e-05,
      "loss": 0.3153,
      "step": 8930
    },
    {
      "epoch": 1.1376984505742738,
      "grad_norm": 0.24002233147621155,
      "learning_rate": 7.940696688691827e-05,
      "loss": 0.3243,
      "step": 8940
    },
    {
      "epoch": 1.1389710795074925,
      "grad_norm": 0.22335755825042725,
      "learning_rate": 7.921014279736369e-05,
      "loss": 0.3265,
      "step": 8950
    },
    {
      "epoch": 1.1402437084407113,
      "grad_norm": 0.24255593121051788,
      "learning_rate": 7.901340284955219e-05,
      "loss": 0.3198,
      "step": 8960
    },
    {
      "epoch": 1.14151633737393,
      "grad_norm": 0.2857009172439575,
      "learning_rate": 7.881674783973943e-05,
      "loss": 0.3549,
      "step": 8970
    },
    {
      "epoch": 1.1427889663071489,
      "grad_norm": 0.2061537206172943,
      "learning_rate": 7.862017856383737e-05,
      "loss": 0.3394,
      "step": 8980
    },
    {
      "epoch": 1.1440615952403679,
      "grad_norm": 0.2144133299589157,
      "learning_rate": 7.842369581741098e-05,
      "loss": 0.3192,
      "step": 8990
    },
    {
      "epoch": 1.1453342241735867,
      "grad_norm": 0.2743724584579468,
      "learning_rate": 7.822730039567496e-05,
      "loss": 0.327,
      "step": 9000
    },
    {
      "epoch": 1.1453342241735867,
      "eval_loss": 0.3545679748058319,
      "eval_runtime": 777.4206,
      "eval_samples_per_second": 10.108,
      "eval_steps_per_second": 5.054,
      "step": 9000
    },
    {
      "epoch": 1.1466068531068054,
      "grad_norm": 0.21841228008270264,
      "learning_rate": 7.803099309349062e-05,
      "loss": 0.3455,
      "step": 9010
    },
    {
      "epoch": 1.1478794820400242,
      "grad_norm": 0.20182016491889954,
      "learning_rate": 7.783477470536259e-05,
      "loss": 0.3263,
      "step": 9020
    },
    {
      "epoch": 1.149152110973243,
      "grad_norm": 0.32818546891212463,
      "learning_rate": 7.763864602543576e-05,
      "loss": 0.3473,
      "step": 9030
    },
    {
      "epoch": 1.1504247399064618,
      "grad_norm": 0.23195454478263855,
      "learning_rate": 7.744260784749183e-05,
      "loss": 0.3345,
      "step": 9040
    },
    {
      "epoch": 1.1516973688396805,
      "grad_norm": 0.2158662974834442,
      "learning_rate": 7.724666096494627e-05,
      "loss": 0.3247,
      "step": 9050
    },
    {
      "epoch": 1.1529699977728993,
      "grad_norm": 0.23151731491088867,
      "learning_rate": 7.7050806170845e-05,
      "loss": 0.3323,
      "step": 9060
    },
    {
      "epoch": 1.154242626706118,
      "grad_norm": 0.22403086721897125,
      "learning_rate": 7.685504425786125e-05,
      "loss": 0.3496,
      "step": 9070
    },
    {
      "epoch": 1.1555152556393369,
      "grad_norm": 0.21950708329677582,
      "learning_rate": 7.665937601829247e-05,
      "loss": 0.3328,
      "step": 9080
    },
    {
      "epoch": 1.1567878845725557,
      "grad_norm": 0.2598375976085663,
      "learning_rate": 7.64638022440568e-05,
      "loss": 0.3364,
      "step": 9090
    },
    {
      "epoch": 1.1580605135057747,
      "grad_norm": 0.24133962392807007,
      "learning_rate": 7.626832372669017e-05,
      "loss": 0.3441,
      "step": 9100
    },
    {
      "epoch": 1.1593331424389934,
      "grad_norm": 0.27416908740997314,
      "learning_rate": 7.607294125734294e-05,
      "loss": 0.3325,
      "step": 9110
    },
    {
      "epoch": 1.1606057713722122,
      "grad_norm": 0.2519339621067047,
      "learning_rate": 7.587765562677668e-05,
      "loss": 0.3338,
      "step": 9120
    },
    {
      "epoch": 1.161878400305431,
      "grad_norm": 0.2944711446762085,
      "learning_rate": 7.568246762536123e-05,
      "loss": 0.3448,
      "step": 9130
    },
    {
      "epoch": 1.1631510292386498,
      "grad_norm": 0.24611568450927734,
      "learning_rate": 7.54873780430711e-05,
      "loss": 0.3293,
      "step": 9140
    },
    {
      "epoch": 1.1644236581718685,
      "grad_norm": 0.2046009749174118,
      "learning_rate": 7.529238766948252e-05,
      "loss": 0.3404,
      "step": 9150
    },
    {
      "epoch": 1.1656962871050873,
      "grad_norm": 0.24574284255504608,
      "learning_rate": 7.509749729377025e-05,
      "loss": 0.3344,
      "step": 9160
    },
    {
      "epoch": 1.166968916038306,
      "grad_norm": 0.27075132727622986,
      "learning_rate": 7.490270770470423e-05,
      "loss": 0.3504,
      "step": 9170
    },
    {
      "epoch": 1.1682415449715249,
      "grad_norm": 0.2304145097732544,
      "learning_rate": 7.470801969064669e-05,
      "loss": 0.3276,
      "step": 9180
    },
    {
      "epoch": 1.1695141739047437,
      "grad_norm": 0.20058682560920715,
      "learning_rate": 7.451343403954856e-05,
      "loss": 0.335,
      "step": 9190
    },
    {
      "epoch": 1.1707868028379624,
      "grad_norm": 0.24594399333000183,
      "learning_rate": 7.431895153894654e-05,
      "loss": 0.3339,
      "step": 9200
    },
    {
      "epoch": 1.1720594317711814,
      "grad_norm": 0.26358872652053833,
      "learning_rate": 7.412457297595994e-05,
      "loss": 0.3444,
      "step": 9210
    },
    {
      "epoch": 1.1733320607044,
      "grad_norm": 0.22118957340717316,
      "learning_rate": 7.393029913728721e-05,
      "loss": 0.3243,
      "step": 9220
    },
    {
      "epoch": 1.174604689637619,
      "grad_norm": 0.26930296421051025,
      "learning_rate": 7.373613080920323e-05,
      "loss": 0.3363,
      "step": 9230
    },
    {
      "epoch": 1.1758773185708378,
      "grad_norm": 0.32602354884147644,
      "learning_rate": 7.354206877755563e-05,
      "loss": 0.3365,
      "step": 9240
    },
    {
      "epoch": 1.1771499475040565,
      "grad_norm": 0.23665153980255127,
      "learning_rate": 7.334811382776192e-05,
      "loss": 0.3413,
      "step": 9250
    },
    {
      "epoch": 1.1784225764372753,
      "grad_norm": 0.2507941722869873,
      "learning_rate": 7.315426674480623e-05,
      "loss": 0.3376,
      "step": 9260
    },
    {
      "epoch": 1.179695205370494,
      "grad_norm": 0.24279531836509705,
      "learning_rate": 7.2960528313236e-05,
      "loss": 0.3316,
      "step": 9270
    },
    {
      "epoch": 1.1809678343037129,
      "grad_norm": 0.2500077486038208,
      "learning_rate": 7.276689931715918e-05,
      "loss": 0.3302,
      "step": 9280
    },
    {
      "epoch": 1.1822404632369317,
      "grad_norm": 0.26013368368148804,
      "learning_rate": 7.257338054024063e-05,
      "loss": 0.3297,
      "step": 9290
    },
    {
      "epoch": 1.1835130921701504,
      "grad_norm": 0.2395409643650055,
      "learning_rate": 7.237997276569911e-05,
      "loss": 0.3411,
      "step": 9300
    },
    {
      "epoch": 1.1847857211033692,
      "grad_norm": 0.2811245620250702,
      "learning_rate": 7.218667677630419e-05,
      "loss": 0.3554,
      "step": 9310
    },
    {
      "epoch": 1.186058350036588,
      "grad_norm": 0.30220168828964233,
      "learning_rate": 7.199349335437299e-05,
      "loss": 0.346,
      "step": 9320
    },
    {
      "epoch": 1.1873309789698068,
      "grad_norm": 0.2699691951274872,
      "learning_rate": 7.180042328176711e-05,
      "loss": 0.3397,
      "step": 9330
    },
    {
      "epoch": 1.1886036079030258,
      "grad_norm": 0.21779686212539673,
      "learning_rate": 7.160746733988932e-05,
      "loss": 0.3165,
      "step": 9340
    },
    {
      "epoch": 1.1898762368362445,
      "grad_norm": 0.25077348947525024,
      "learning_rate": 7.141462630968046e-05,
      "loss": 0.3511,
      "step": 9350
    },
    {
      "epoch": 1.1911488657694633,
      "grad_norm": 0.22843927145004272,
      "learning_rate": 7.122190097161637e-05,
      "loss": 0.3244,
      "step": 9360
    },
    {
      "epoch": 1.192421494702682,
      "grad_norm": 0.24882128834724426,
      "learning_rate": 7.102929210570455e-05,
      "loss": 0.3226,
      "step": 9370
    },
    {
      "epoch": 1.1936941236359009,
      "grad_norm": 0.23791788518428802,
      "learning_rate": 7.083680049148126e-05,
      "loss": 0.3321,
      "step": 9380
    },
    {
      "epoch": 1.1949667525691197,
      "grad_norm": 0.2519265115261078,
      "learning_rate": 7.064442690800807e-05,
      "loss": 0.343,
      "step": 9390
    },
    {
      "epoch": 1.1962393815023384,
      "grad_norm": 0.2528795897960663,
      "learning_rate": 7.045217213386895e-05,
      "loss": 0.3472,
      "step": 9400
    },
    {
      "epoch": 1.1975120104355572,
      "grad_norm": 0.208982452750206,
      "learning_rate": 7.026003694716693e-05,
      "loss": 0.3351,
      "step": 9410
    },
    {
      "epoch": 1.198784639368776,
      "grad_norm": 0.21242405474185944,
      "learning_rate": 7.006802212552105e-05,
      "loss": 0.3427,
      "step": 9420
    },
    {
      "epoch": 1.2000572683019948,
      "grad_norm": 0.2114800214767456,
      "learning_rate": 6.987612844606335e-05,
      "loss": 0.3332,
      "step": 9430
    },
    {
      "epoch": 1.2013298972352136,
      "grad_norm": 0.2610507607460022,
      "learning_rate": 6.968435668543538e-05,
      "loss": 0.345,
      "step": 9440
    },
    {
      "epoch": 1.2026025261684326,
      "grad_norm": 0.2518205940723419,
      "learning_rate": 6.949270761978536e-05,
      "loss": 0.3247,
      "step": 9450
    },
    {
      "epoch": 1.2038751551016513,
      "grad_norm": 0.2297665774822235,
      "learning_rate": 6.930118202476492e-05,
      "loss": 0.334,
      "step": 9460
    },
    {
      "epoch": 1.20514778403487,
      "grad_norm": 0.2943696081638336,
      "learning_rate": 6.910978067552591e-05,
      "loss": 0.3306,
      "step": 9470
    },
    {
      "epoch": 1.2064204129680889,
      "grad_norm": 0.2276790291070938,
      "learning_rate": 6.891850434671747e-05,
      "loss": 0.3404,
      "step": 9480
    },
    {
      "epoch": 1.2076930419013077,
      "grad_norm": 0.25828078389167786,
      "learning_rate": 6.872735381248262e-05,
      "loss": 0.3392,
      "step": 9490
    },
    {
      "epoch": 1.2089656708345264,
      "grad_norm": 0.2455635666847229,
      "learning_rate": 6.853632984645531e-05,
      "loss": 0.3064,
      "step": 9500
    },
    {
      "epoch": 1.2089656708345264,
      "eval_loss": 0.35318905115127563,
      "eval_runtime": 750.5597,
      "eval_samples_per_second": 10.47,
      "eval_steps_per_second": 5.235,
      "step": 9500
    },
    {
      "epoch": 1.2102382997677452,
      "grad_norm": 0.2740643620491028,
      "learning_rate": 0.00013065466728160252,
      "loss": 0.3322,
      "step": 9510
    },
    {
      "epoch": 1.211510928700964,
      "grad_norm": 0.2353079915046692,
      "learning_rate": 0.0001305272503014542,
      "loss": 0.3121,
      "step": 9520
    },
    {
      "epoch": 1.2127835576341828,
      "grad_norm": 0.28257760405540466,
      "learning_rate": 0.00013039977864323708,
      "loss": 0.3298,
      "step": 9530
    },
    {
      "epoch": 1.2140561865674016,
      "grad_norm": 0.23038563132286072,
      "learning_rate": 0.00013027225253526846,
      "loss": 0.3273,
      "step": 9540
    },
    {
      "epoch": 1.2153288155006203,
      "grad_norm": 0.2708836495876312,
      "learning_rate": 0.00013014467220596348,
      "loss": 0.3528,
      "step": 9550
    },
    {
      "epoch": 1.216601444433839,
      "grad_norm": 0.22897560894489288,
      "learning_rate": 0.00013001703788383413,
      "loss": 0.3298,
      "step": 9560
    },
    {
      "epoch": 1.2178740733670579,
      "grad_norm": 0.20656529068946838,
      "learning_rate": 0.0001298893497974893,
      "loss": 0.337,
      "step": 9570
    },
    {
      "epoch": 1.2191467023002769,
      "grad_norm": 0.289668470621109,
      "learning_rate": 0.00012976160817563395,
      "loss": 0.3195,
      "step": 9580
    },
    {
      "epoch": 1.2204193312334957,
      "grad_norm": 0.2685324549674988,
      "learning_rate": 0.00012963381324706925,
      "loss": 0.3246,
      "step": 9590
    },
    {
      "epoch": 1.2216919601667144,
      "grad_norm": 0.2458927184343338,
      "learning_rate": 0.00012950596524069158,
      "loss": 0.3398,
      "step": 9600
    },
    {
      "epoch": 1.2229645890999332,
      "grad_norm": 0.2146037518978119,
      "learning_rate": 0.00012937806438549247,
      "loss": 0.331,
      "step": 9610
    },
    {
      "epoch": 1.224237218033152,
      "grad_norm": 0.26990726590156555,
      "learning_rate": 0.00012925011091055816,
      "loss": 0.343,
      "step": 9620
    },
    {
      "epoch": 1.2255098469663708,
      "grad_norm": 0.30691957473754883,
      "learning_rate": 0.0001291221050450691,
      "loss": 0.3572,
      "step": 9630
    },
    {
      "epoch": 1.2267824758995896,
      "grad_norm": 0.24201162159442902,
      "learning_rate": 0.00012899404701829952,
      "loss": 0.345,
      "step": 9640
    },
    {
      "epoch": 1.2280551048328083,
      "grad_norm": 0.23696847259998322,
      "learning_rate": 0.0001288659370596172,
      "loss": 0.3481,
      "step": 9650
    },
    {
      "epoch": 1.229327733766027,
      "grad_norm": 0.24345481395721436,
      "learning_rate": 0.00012873777539848283,
      "loss": 0.3254,
      "step": 9660
    },
    {
      "epoch": 1.2306003626992459,
      "grad_norm": 0.28496965765953064,
      "learning_rate": 0.00012860956226444975,
      "loss": 0.3372,
      "step": 9670
    },
    {
      "epoch": 1.2318729916324647,
      "grad_norm": 0.25761693716049194,
      "learning_rate": 0.00012848129788716354,
      "loss": 0.3268,
      "step": 9680
    },
    {
      "epoch": 1.2331456205656837,
      "grad_norm": 0.1812032163143158,
      "learning_rate": 0.0001283529824963614,
      "loss": 0.3356,
      "step": 9690
    },
    {
      "epoch": 1.2344182494989024,
      "grad_norm": 0.23453189432621002,
      "learning_rate": 0.00012822461632187214,
      "loss": 0.3469,
      "step": 9700
    },
    {
      "epoch": 1.2356908784321212,
      "grad_norm": 0.2574700117111206,
      "learning_rate": 0.00012809619959361533,
      "loss": 0.3365,
      "step": 9710
    },
    {
      "epoch": 1.23696350736534,
      "grad_norm": 0.2501879036426544,
      "learning_rate": 0.00012796773254160118,
      "loss": 0.3232,
      "step": 9720
    },
    {
      "epoch": 1.2382361362985588,
      "grad_norm": 0.2301279604434967,
      "learning_rate": 0.00012783921539593005,
      "loss": 0.3346,
      "step": 9730
    },
    {
      "epoch": 1.2395087652317776,
      "grad_norm": 0.205980122089386,
      "learning_rate": 0.00012771064838679194,
      "loss": 0.3159,
      "step": 9740
    },
    {
      "epoch": 1.2407813941649963,
      "grad_norm": 0.2546384036540985,
      "learning_rate": 0.00012758203174446624,
      "loss": 0.3196,
      "step": 9750
    },
    {
      "epoch": 1.242054023098215,
      "grad_norm": 0.31881874799728394,
      "learning_rate": 0.0001274533656993212,
      "loss": 0.3606,
      "step": 9760
    },
    {
      "epoch": 1.2433266520314339,
      "grad_norm": 0.2062113881111145,
      "learning_rate": 0.00012732465048181363,
      "loss": 0.3366,
      "step": 9770
    },
    {
      "epoch": 1.2445992809646527,
      "grad_norm": 0.2321619689464569,
      "learning_rate": 0.00012719588632248823,
      "loss": 0.3183,
      "step": 9780
    },
    {
      "epoch": 1.2458719098978714,
      "grad_norm": 0.20802071690559387,
      "learning_rate": 0.00012706707345197757,
      "loss": 0.3389,
      "step": 9790
    },
    {
      "epoch": 1.2471445388310904,
      "grad_norm": 0.27879244089126587,
      "learning_rate": 0.0001269382121010014,
      "loss": 0.3242,
      "step": 9800
    },
    {
      "epoch": 1.248417167764309,
      "grad_norm": 0.22252419590950012,
      "learning_rate": 0.00012680930250036623,
      "loss": 0.3341,
      "step": 9810
    },
    {
      "epoch": 1.249689796697528,
      "grad_norm": 0.26085004210472107,
      "learning_rate": 0.00012668034488096507,
      "loss": 0.3353,
      "step": 9820
    },
    {
      "epoch": 1.2509624256307468,
      "grad_norm": 0.2332713007926941,
      "learning_rate": 0.00012655133947377692,
      "loss": 0.3269,
      "step": 9830
    },
    {
      "epoch": 1.2522350545639656,
      "grad_norm": 0.21288618445396423,
      "learning_rate": 0.00012642228650986637,
      "loss": 0.3492,
      "step": 9840
    },
    {
      "epoch": 1.2535076834971843,
      "grad_norm": 0.2125503420829773,
      "learning_rate": 0.0001262931862203832,
      "loss": 0.3206,
      "step": 9850
    },
    {
      "epoch": 1.254780312430403,
      "grad_norm": 0.2567022740840912,
      "learning_rate": 0.0001261640388365619,
      "loss": 0.3341,
      "step": 9860
    },
    {
      "epoch": 1.2560529413636219,
      "grad_norm": 0.290033221244812,
      "learning_rate": 0.00012603484458972142,
      "loss": 0.3625,
      "step": 9870
    },
    {
      "epoch": 1.2573255702968407,
      "grad_norm": 0.21565495431423187,
      "learning_rate": 0.00012590560371126451,
      "loss": 0.3311,
      "step": 9880
    },
    {
      "epoch": 1.2585981992300594,
      "grad_norm": 0.28424710035324097,
      "learning_rate": 0.0001257763164326776,
      "loss": 0.3448,
      "step": 9890
    },
    {
      "epoch": 1.2598708281632782,
      "grad_norm": 0.22748622298240662,
      "learning_rate": 0.0001256469829855301,
      "loss": 0.332,
      "step": 9900
    },
    {
      "epoch": 1.2611434570964972,
      "grad_norm": 0.28457939624786377,
      "learning_rate": 0.00012551760360147413,
      "loss": 0.3392,
      "step": 9910
    },
    {
      "epoch": 1.2624160860297158,
      "grad_norm": 0.23216666281223297,
      "learning_rate": 0.00012538817851224417,
      "loss": 0.3375,
      "step": 9920
    },
    {
      "epoch": 1.2636887149629348,
      "grad_norm": 0.26894432306289673,
      "learning_rate": 0.00012525870794965647,
      "loss": 0.333,
      "step": 9930
    },
    {
      "epoch": 1.2649613438961536,
      "grad_norm": 0.3174472451210022,
      "learning_rate": 0.0001251291921456088,
      "loss": 0.3362,
      "step": 9940
    },
    {
      "epoch": 1.2662339728293723,
      "grad_norm": 0.2522273659706116,
      "learning_rate": 0.0001249996313320799,
      "loss": 0.3271,
      "step": 9950
    },
    {
      "epoch": 1.2675066017625911,
      "grad_norm": 0.22388340532779694,
      "learning_rate": 0.00012487002574112921,
      "loss": 0.3517,
      "step": 9960
    },
    {
      "epoch": 1.26877923069581,
      "grad_norm": 0.24099434912204742,
      "learning_rate": 0.0001247403756048963,
      "loss": 0.3191,
      "step": 9970
    },
    {
      "epoch": 1.2700518596290287,
      "grad_norm": 0.33156129717826843,
      "learning_rate": 0.00012461068115560055,
      "loss": 0.3475,
      "step": 9980
    },
    {
      "epoch": 1.2713244885622474,
      "grad_norm": 0.22525888681411743,
      "learning_rate": 0.00012448094262554067,
      "loss": 0.32,
      "step": 9990
    },
    {
      "epoch": 1.2725971174954662,
      "grad_norm": 0.20666098594665527,
      "learning_rate": 0.00012435116024709438,
      "loss": 0.3625,
      "step": 10000
    },
    {
      "epoch": 1.2725971174954662,
      "eval_loss": 0.3563210368156433,
      "eval_runtime": 754.3449,
      "eval_samples_per_second": 10.417,
      "eval_steps_per_second": 5.208,
      "step": 10000
    },
    {
      "epoch": 1.273869746428685,
      "grad_norm": 0.22634780406951904,
      "learning_rate": 0.00012422133425271797,
      "loss": 0.3289,
      "step": 10010
    },
    {
      "epoch": 1.2751423753619038,
      "grad_norm": 0.25287482142448425,
      "learning_rate": 0.00012409146487494575,
      "loss": 0.3479,
      "step": 10020
    },
    {
      "epoch": 1.2764150042951226,
      "grad_norm": 0.23980581760406494,
      "learning_rate": 0.0001239615523463898,
      "loss": 0.3276,
      "step": 10030
    },
    {
      "epoch": 1.2776876332283416,
      "grad_norm": 0.24705110490322113,
      "learning_rate": 0.00012383159689973943,
      "loss": 0.3316,
      "step": 10040
    },
    {
      "epoch": 1.2789602621615601,
      "grad_norm": 0.24347546696662903,
      "learning_rate": 0.000123701598767761,
      "loss": 0.3538,
      "step": 10050
    },
    {
      "epoch": 1.2802328910947791,
      "grad_norm": 0.2604919672012329,
      "learning_rate": 0.00012357155818329706,
      "loss": 0.3449,
      "step": 10060
    },
    {
      "epoch": 1.281505520027998,
      "grad_norm": 0.2709888219833374,
      "learning_rate": 0.00012344147537926635,
      "loss": 0.3407,
      "step": 10070
    },
    {
      "epoch": 1.2827781489612167,
      "grad_norm": 0.18181850016117096,
      "learning_rate": 0.00012331135058866324,
      "loss": 0.3108,
      "step": 10080
    },
    {
      "epoch": 1.2840507778944354,
      "grad_norm": 0.3086203336715698,
      "learning_rate": 0.0001231811840445573,
      "loss": 0.3295,
      "step": 10090
    },
    {
      "epoch": 1.2853234068276542,
      "grad_norm": 0.25141245126724243,
      "learning_rate": 0.00012305097598009281,
      "loss": 0.3521,
      "step": 10100
    },
    {
      "epoch": 1.286596035760873,
      "grad_norm": 0.4246445596218109,
      "learning_rate": 0.00012292072662848847,
      "loss": 0.3291,
      "step": 10110
    },
    {
      "epoch": 1.2878686646940918,
      "grad_norm": 0.2220783829689026,
      "learning_rate": 0.00012279043622303692,
      "loss": 0.3399,
      "step": 10120
    },
    {
      "epoch": 1.2891412936273106,
      "grad_norm": 0.25845733284950256,
      "learning_rate": 0.00012266010499710435,
      "loss": 0.3402,
      "step": 10130
    },
    {
      "epoch": 1.2904139225605293,
      "grad_norm": 0.25457584857940674,
      "learning_rate": 0.00012252973318413007,
      "loss": 0.3281,
      "step": 10140
    },
    {
      "epoch": 1.2916865514937483,
      "grad_norm": 0.2601991891860962,
      "learning_rate": 0.0001223993210176261,
      "loss": 0.3361,
      "step": 10150
    },
    {
      "epoch": 1.292959180426967,
      "grad_norm": 0.19450323283672333,
      "learning_rate": 0.00012226886873117662,
      "loss": 0.3017,
      "step": 10160
    },
    {
      "epoch": 1.294231809360186,
      "grad_norm": 0.24004508554935455,
      "learning_rate": 0.0001221383765584378,
      "loss": 0.3082,
      "step": 10170
    },
    {
      "epoch": 1.2955044382934047,
      "grad_norm": 0.250664085149765,
      "learning_rate": 0.00012200784473313723,
      "loss": 0.3071,
      "step": 10180
    },
    {
      "epoch": 1.2967770672266234,
      "grad_norm": 0.24606266617774963,
      "learning_rate": 0.00012187727348907347,
      "loss": 0.3316,
      "step": 10190
    },
    {
      "epoch": 1.2980496961598422,
      "grad_norm": 0.21499601006507874,
      "learning_rate": 0.00012174666306011577,
      "loss": 0.323,
      "step": 10200
    },
    {
      "epoch": 1.299322325093061,
      "grad_norm": 0.21433298289775848,
      "learning_rate": 0.00012161601368020344,
      "loss": 0.3221,
      "step": 10210
    },
    {
      "epoch": 1.3005949540262798,
      "grad_norm": 0.23702839016914368,
      "learning_rate": 0.00012148532558334569,
      "loss": 0.3557,
      "step": 10220
    },
    {
      "epoch": 1.3018675829594986,
      "grad_norm": 0.2449527382850647,
      "learning_rate": 0.00012135459900362093,
      "loss": 0.3486,
      "step": 10230
    },
    {
      "epoch": 1.3031402118927173,
      "grad_norm": 0.2274329662322998,
      "learning_rate": 0.00012122383417517666,
      "loss": 0.3076,
      "step": 10240
    },
    {
      "epoch": 1.3044128408259361,
      "grad_norm": 0.2623559534549713,
      "learning_rate": 0.0001210930313322288,
      "loss": 0.3245,
      "step": 10250
    },
    {
      "epoch": 1.305685469759155,
      "grad_norm": 0.22795897722244263,
      "learning_rate": 0.00012096219070906132,
      "loss": 0.3412,
      "step": 10260
    },
    {
      "epoch": 1.3069580986923737,
      "grad_norm": 0.2531203031539917,
      "learning_rate": 0.00012083131254002597,
      "loss": 0.3447,
      "step": 10270
    },
    {
      "epoch": 1.3082307276255927,
      "grad_norm": 0.2534365653991699,
      "learning_rate": 0.00012070039705954161,
      "loss": 0.314,
      "step": 10280
    },
    {
      "epoch": 1.3095033565588112,
      "grad_norm": 0.2259664237499237,
      "learning_rate": 0.00012056944450209409,
      "loss": 0.3333,
      "step": 10290
    },
    {
      "epoch": 1.3107759854920302,
      "grad_norm": 0.3228720426559448,
      "learning_rate": 0.00012043845510223551,
      "loss": 0.3267,
      "step": 10300
    },
    {
      "epoch": 1.312048614425249,
      "grad_norm": 0.21967072784900665,
      "learning_rate": 0.0001203074290945841,
      "loss": 0.3379,
      "step": 10310
    },
    {
      "epoch": 1.3133212433584678,
      "grad_norm": 0.20841774344444275,
      "learning_rate": 0.00012017636671382356,
      "loss": 0.3054,
      "step": 10320
    },
    {
      "epoch": 1.3145938722916866,
      "grad_norm": 0.35219186544418335,
      "learning_rate": 0.00012004526819470274,
      "loss": 0.3268,
      "step": 10330
    },
    {
      "epoch": 1.3158665012249053,
      "grad_norm": 0.2772178649902344,
      "learning_rate": 0.00011991413377203531,
      "loss": 0.3384,
      "step": 10340
    },
    {
      "epoch": 1.3171391301581241,
      "grad_norm": 0.2553512752056122,
      "learning_rate": 0.00011978296368069915,
      "loss": 0.3432,
      "step": 10350
    },
    {
      "epoch": 1.318411759091343,
      "grad_norm": 0.24397243559360504,
      "learning_rate": 0.0001196517581556361,
      "loss": 0.3236,
      "step": 10360
    },
    {
      "epoch": 1.3196843880245617,
      "grad_norm": 0.20838983356952667,
      "learning_rate": 0.00011952051743185137,
      "loss": 0.3277,
      "step": 10370
    },
    {
      "epoch": 1.3209570169577804,
      "grad_norm": 0.3137708902359009,
      "learning_rate": 0.00011938924174441335,
      "loss": 0.3181,
      "step": 10380
    },
    {
      "epoch": 1.3222296458909994,
      "grad_norm": 0.2754363715648651,
      "learning_rate": 0.00011925793132845292,
      "loss": 0.3342,
      "step": 10390
    },
    {
      "epoch": 1.323502274824218,
      "grad_norm": 0.24437659978866577,
      "learning_rate": 0.00011912658641916325,
      "loss": 0.328,
      "step": 10400
    },
    {
      "epoch": 1.324774903757437,
      "grad_norm": 0.2713484764099121,
      "learning_rate": 0.0001189952072517993,
      "loss": 0.3512,
      "step": 10410
    },
    {
      "epoch": 1.3260475326906558,
      "grad_norm": 0.21578752994537354,
      "learning_rate": 0.0001188637940616773,
      "loss": 0.3226,
      "step": 10420
    },
    {
      "epoch": 1.3273201616238746,
      "grad_norm": 0.23182353377342224,
      "learning_rate": 0.00011873234708417444,
      "loss": 0.3157,
      "step": 10430
    },
    {
      "epoch": 1.3285927905570933,
      "grad_norm": 0.22589047253131866,
      "learning_rate": 0.00011860086655472859,
      "loss": 0.3163,
      "step": 10440
    },
    {
      "epoch": 1.3298654194903121,
      "grad_norm": 0.27063408493995667,
      "learning_rate": 0.00011846935270883747,
      "loss": 0.3236,
      "step": 10450
    },
    {
      "epoch": 1.331138048423531,
      "grad_norm": 0.25064849853515625,
      "learning_rate": 0.00011833780578205869,
      "loss": 0.3389,
      "step": 10460
    },
    {
      "epoch": 1.3324106773567497,
      "grad_norm": 0.24209335446357727,
      "learning_rate": 0.00011820622601000893,
      "loss": 0.3451,
      "step": 10470
    },
    {
      "epoch": 1.3336833062899685,
      "grad_norm": 0.2860705554485321,
      "learning_rate": 0.0001180746136283638,
      "loss": 0.3515,
      "step": 10480
    },
    {
      "epoch": 1.3349559352231872,
      "grad_norm": 0.22794099152088165,
      "learning_rate": 0.00011794296887285734,
      "loss": 0.3419,
      "step": 10490
    },
    {
      "epoch": 1.3362285641564062,
      "grad_norm": 0.29653748869895935,
      "learning_rate": 0.00011781129197928149,
      "loss": 0.3392,
      "step": 10500
    },
    {
      "epoch": 1.3362285641564062,
      "eval_loss": 0.35598716139793396,
      "eval_runtime": 761.4118,
      "eval_samples_per_second": 10.32,
      "eval_steps_per_second": 5.16,
      "step": 10500
    },
    {
      "epoch": 1.3375011930896248,
      "grad_norm": 0.24838921427726746,
      "learning_rate": 0.00011767958318348586,
      "loss": 0.3241,
      "step": 10510
    },
    {
      "epoch": 1.3387738220228438,
      "grad_norm": 0.213349848985672,
      "learning_rate": 0.00011754784272137709,
      "loss": 0.3112,
      "step": 10520
    },
    {
      "epoch": 1.3400464509560626,
      "grad_norm": 0.19694441556930542,
      "learning_rate": 0.00011741607082891859,
      "loss": 0.3278,
      "step": 10530
    },
    {
      "epoch": 1.3413190798892813,
      "grad_norm": 0.323015958070755,
      "learning_rate": 0.00011728426774213006,
      "loss": 0.338,
      "step": 10540
    },
    {
      "epoch": 1.3425917088225001,
      "grad_norm": 0.2423015981912613,
      "learning_rate": 0.00011715243369708715,
      "loss": 0.3326,
      "step": 10550
    },
    {
      "epoch": 1.343864337755719,
      "grad_norm": 0.2525024712085724,
      "learning_rate": 0.0001170205689299208,
      "loss": 0.3259,
      "step": 10560
    },
    {
      "epoch": 1.3451369666889377,
      "grad_norm": 0.24110262095928192,
      "learning_rate": 0.0001168886736768171,
      "loss": 0.3183,
      "step": 10570
    },
    {
      "epoch": 1.3464095956221565,
      "grad_norm": 0.2778305113315582,
      "learning_rate": 0.00011675674817401674,
      "loss": 0.342,
      "step": 10580
    },
    {
      "epoch": 1.3476822245553752,
      "grad_norm": 0.260611355304718,
      "learning_rate": 0.00011662479265781448,
      "loss": 0.3328,
      "step": 10590
    },
    {
      "epoch": 1.348954853488594,
      "grad_norm": 0.18201439082622528,
      "learning_rate": 0.000116492807364559,
      "loss": 0.339,
      "step": 10600
    },
    {
      "epoch": 1.3502274824218128,
      "grad_norm": 0.24457892775535583,
      "learning_rate": 0.00011636079253065219,
      "loss": 0.3272,
      "step": 10610
    },
    {
      "epoch": 1.3515001113550316,
      "grad_norm": 0.2539921700954437,
      "learning_rate": 0.00011622874839254894,
      "loss": 0.3363,
      "step": 10620
    },
    {
      "epoch": 1.3527727402882506,
      "grad_norm": 0.25962507724761963,
      "learning_rate": 0.00011609667518675646,
      "loss": 0.3376,
      "step": 10630
    },
    {
      "epoch": 1.3540453692214691,
      "grad_norm": 0.2645050287246704,
      "learning_rate": 0.00011596457314983429,
      "loss": 0.3285,
      "step": 10640
    },
    {
      "epoch": 1.3553179981546881,
      "grad_norm": 0.25749173760414124,
      "learning_rate": 0.00011583244251839339,
      "loss": 0.3227,
      "step": 10650
    },
    {
      "epoch": 1.356590627087907,
      "grad_norm": 0.2028415948152542,
      "learning_rate": 0.00011570028352909603,
      "loss": 0.3154,
      "step": 10660
    },
    {
      "epoch": 1.3578632560211257,
      "grad_norm": 0.3152422308921814,
      "learning_rate": 0.00011556809641865522,
      "loss": 0.3257,
      "step": 10670
    },
    {
      "epoch": 1.3591358849543445,
      "grad_norm": 0.24131134152412415,
      "learning_rate": 0.00011543588142383441,
      "loss": 0.3169,
      "step": 10680
    },
    {
      "epoch": 1.3604085138875632,
      "grad_norm": 0.31535008549690247,
      "learning_rate": 0.00011530363878144694,
      "loss": 0.3384,
      "step": 10690
    },
    {
      "epoch": 1.361681142820782,
      "grad_norm": 0.21417255699634552,
      "learning_rate": 0.0001151713687283557,
      "loss": 0.3274,
      "step": 10700
    },
    {
      "epoch": 1.3629537717540008,
      "grad_norm": 0.3133143484592438,
      "learning_rate": 0.00011503907150147266,
      "loss": 0.3312,
      "step": 10710
    },
    {
      "epoch": 1.3642264006872196,
      "grad_norm": 0.23788796365261078,
      "learning_rate": 0.00011490674733775844,
      "loss": 0.3223,
      "step": 10720
    },
    {
      "epoch": 1.3654990296204383,
      "grad_norm": 0.24160067737102509,
      "learning_rate": 0.00011477439647422192,
      "loss": 0.3363,
      "step": 10730
    },
    {
      "epoch": 1.3667716585536573,
      "grad_norm": 0.29143378138542175,
      "learning_rate": 0.00011464201914791985,
      "loss": 0.3445,
      "step": 10740
    },
    {
      "epoch": 1.368044287486876,
      "grad_norm": 0.26355206966400146,
      "learning_rate": 0.00011450961559595637,
      "loss": 0.3287,
      "step": 10750
    },
    {
      "epoch": 1.369316916420095,
      "grad_norm": 0.20652122795581818,
      "learning_rate": 0.00011437718605548248,
      "loss": 0.3399,
      "step": 10760
    },
    {
      "epoch": 1.3705895453533137,
      "grad_norm": 0.2758137583732605,
      "learning_rate": 0.0001142447307636959,
      "loss": 0.3239,
      "step": 10770
    },
    {
      "epoch": 1.3718621742865325,
      "grad_norm": 0.23938816785812378,
      "learning_rate": 0.00011411224995784031,
      "loss": 0.3236,
      "step": 10780
    },
    {
      "epoch": 1.3731348032197512,
      "grad_norm": 0.20413172245025635,
      "learning_rate": 0.00011397974387520525,
      "loss": 0.333,
      "step": 10790
    },
    {
      "epoch": 1.37440743215297,
      "grad_norm": 0.2139868587255478,
      "learning_rate": 0.00011384721275312535,
      "loss": 0.3275,
      "step": 10800
    },
    {
      "epoch": 1.3756800610861888,
      "grad_norm": 0.27798980474472046,
      "learning_rate": 0.00011371465682898029,
      "loss": 0.3268,
      "step": 10810
    },
    {
      "epoch": 1.3769526900194076,
      "grad_norm": 0.29445865750312805,
      "learning_rate": 0.000113582076340194,
      "loss": 0.3271,
      "step": 10820
    },
    {
      "epoch": 1.3782253189526263,
      "grad_norm": 0.21144478023052216,
      "learning_rate": 0.00011344947152423451,
      "loss": 0.3201,
      "step": 10830
    },
    {
      "epoch": 1.3794979478858451,
      "grad_norm": 0.2184189409017563,
      "learning_rate": 0.00011331684261861339,
      "loss": 0.3165,
      "step": 10840
    },
    {
      "epoch": 1.380770576819064,
      "grad_norm": 0.2680659592151642,
      "learning_rate": 0.00011318418986088537,
      "loss": 0.3396,
      "step": 10850
    },
    {
      "epoch": 1.3820432057522827,
      "grad_norm": 0.29104965925216675,
      "learning_rate": 0.00011305151348864788,
      "loss": 0.3176,
      "step": 10860
    },
    {
      "epoch": 1.3833158346855017,
      "grad_norm": 0.28632330894470215,
      "learning_rate": 0.00011291881373954065,
      "loss": 0.3354,
      "step": 10870
    },
    {
      "epoch": 1.3845884636187202,
      "grad_norm": 0.2472260296344757,
      "learning_rate": 0.0001127860908512453,
      "loss": 0.3153,
      "step": 10880
    },
    {
      "epoch": 1.3858610925519392,
      "grad_norm": 0.29066526889801025,
      "learning_rate": 0.0001126533450614849,
      "loss": 0.3394,
      "step": 10890
    },
    {
      "epoch": 1.387133721485158,
      "grad_norm": 0.25056955218315125,
      "learning_rate": 0.00011252057660802354,
      "loss": 0.2898,
      "step": 10900
    },
    {
      "epoch": 1.3884063504183768,
      "grad_norm": 0.2329035848379135,
      "learning_rate": 0.00011238778572866584,
      "loss": 0.3263,
      "step": 10910
    },
    {
      "epoch": 1.3896789793515956,
      "grad_norm": 0.23278109729290009,
      "learning_rate": 0.00011225497266125669,
      "loss": 0.3239,
      "step": 10920
    },
    {
      "epoch": 1.3909516082848143,
      "grad_norm": 0.2834905982017517,
      "learning_rate": 0.00011212213764368059,
      "loss": 0.3271,
      "step": 10930
    },
    {
      "epoch": 1.3922242372180331,
      "grad_norm": 0.20817045867443085,
      "learning_rate": 0.0001119892809138615,
      "loss": 0.3337,
      "step": 10940
    },
    {
      "epoch": 1.393496866151252,
      "grad_norm": 0.27867522835731506,
      "learning_rate": 0.0001118564027097622,
      "loss": 0.344,
      "step": 10950
    },
    {
      "epoch": 1.3947694950844707,
      "grad_norm": 0.23762042820453644,
      "learning_rate": 0.0001117235032693839,
      "loss": 0.3233,
      "step": 10960
    },
    {
      "epoch": 1.3960421240176895,
      "grad_norm": 0.27417442202568054,
      "learning_rate": 0.00011159058283076592,
      "loss": 0.3486,
      "step": 10970
    },
    {
      "epoch": 1.3973147529509085,
      "grad_norm": 0.2259233295917511,
      "learning_rate": 0.00011145764163198509,
      "loss": 0.3005,
      "step": 10980
    },
    {
      "epoch": 1.398587381884127,
      "grad_norm": 0.2677168548107147,
      "learning_rate": 0.00011132467991115558,
      "loss": 0.3285,
      "step": 10990
    },
    {
      "epoch": 1.399860010817346,
      "grad_norm": 0.25612860918045044,
      "learning_rate": 0.00011119169790642816,
      "loss": 0.3466,
      "step": 11000
    },
    {
      "epoch": 1.399860010817346,
      "eval_loss": 0.3556883633136749,
      "eval_runtime": 768.3963,
      "eval_samples_per_second": 10.226,
      "eval_steps_per_second": 5.113,
      "step": 11000
    },
    {
      "epoch": 1.4011326397505648,
      "grad_norm": 0.21897214651107788,
      "learning_rate": 0.00011105869585599002,
      "loss": 0.3302,
      "step": 11010
    },
    {
      "epoch": 1.4024052686837836,
      "grad_norm": 0.22853003442287445,
      "learning_rate": 0.0001109256739980642,
      "loss": 0.3235,
      "step": 11020
    },
    {
      "epoch": 1.4036778976170023,
      "grad_norm": 0.2436928004026413,
      "learning_rate": 0.00011079263257090929,
      "loss": 0.3238,
      "step": 11030
    },
    {
      "epoch": 1.4049505265502211,
      "grad_norm": 0.2846188247203827,
      "learning_rate": 0.00011065957181281883,
      "loss": 0.3379,
      "step": 11040
    },
    {
      "epoch": 1.40622315548344,
      "grad_norm": 0.29972097277641296,
      "learning_rate": 0.00011052649196212112,
      "loss": 0.3326,
      "step": 11050
    },
    {
      "epoch": 1.4074957844166587,
      "grad_norm": 0.24203892052173615,
      "learning_rate": 0.0001103933932571785,
      "loss": 0.3092,
      "step": 11060
    },
    {
      "epoch": 1.4087684133498775,
      "grad_norm": 0.2793138921260834,
      "learning_rate": 0.00011026027593638724,
      "loss": 0.3287,
      "step": 11070
    },
    {
      "epoch": 1.4100410422830962,
      "grad_norm": 0.2475055307149887,
      "learning_rate": 0.00011012714023817681,
      "loss": 0.3227,
      "step": 11080
    },
    {
      "epoch": 1.4113136712163152,
      "grad_norm": 0.2964610159397125,
      "learning_rate": 0.00010999398640100966,
      "loss": 0.3067,
      "step": 11090
    },
    {
      "epoch": 1.4125863001495338,
      "grad_norm": 0.27609023451805115,
      "learning_rate": 0.00010986081466338079,
      "loss": 0.3364,
      "step": 11100
    },
    {
      "epoch": 1.4138589290827528,
      "grad_norm": 0.25352421402931213,
      "learning_rate": 0.00010972762526381712,
      "loss": 0.3143,
      "step": 11110
    },
    {
      "epoch": 1.4151315580159716,
      "grad_norm": 0.3298400640487671,
      "learning_rate": 0.00010959441844087735,
      "loss": 0.3507,
      "step": 11120
    },
    {
      "epoch": 1.4164041869491903,
      "grad_norm": 0.26044395565986633,
      "learning_rate": 0.00010946119443315123,
      "loss": 0.3175,
      "step": 11130
    },
    {
      "epoch": 1.4176768158824091,
      "grad_norm": 0.2860621213912964,
      "learning_rate": 0.00010932795347925953,
      "loss": 0.3284,
      "step": 11140
    },
    {
      "epoch": 1.418949444815628,
      "grad_norm": 0.2405112087726593,
      "learning_rate": 0.00010919469581785311,
      "loss": 0.3266,
      "step": 11150
    },
    {
      "epoch": 1.4202220737488467,
      "grad_norm": 0.25256794691085815,
      "learning_rate": 0.0001090614216876129,
      "loss": 0.3252,
      "step": 11160
    },
    {
      "epoch": 1.4214947026820655,
      "grad_norm": 0.2592286467552185,
      "learning_rate": 0.00010892813132724933,
      "loss": 0.3399,
      "step": 11170
    },
    {
      "epoch": 1.4227673316152842,
      "grad_norm": 0.2019771933555603,
      "learning_rate": 0.0001087948249755018,
      "loss": 0.3053,
      "step": 11180
    },
    {
      "epoch": 1.424039960548503,
      "grad_norm": 0.22560498118400574,
      "learning_rate": 0.0001086615028711385,
      "loss": 0.3129,
      "step": 11190
    },
    {
      "epoch": 1.4253125894817218,
      "grad_norm": 0.2359880954027176,
      "learning_rate": 0.00010852816525295568,
      "loss": 0.3378,
      "step": 11200
    },
    {
      "epoch": 1.4265852184149406,
      "grad_norm": 0.2625522017478943,
      "learning_rate": 0.00010839481235977753,
      "loss": 0.3327,
      "step": 11210
    },
    {
      "epoch": 1.4278578473481596,
      "grad_norm": 0.25915399193763733,
      "learning_rate": 0.00010826144443045545,
      "loss": 0.3248,
      "step": 11220
    },
    {
      "epoch": 1.4291304762813781,
      "grad_norm": 0.2552409768104553,
      "learning_rate": 0.00010812806170386786,
      "loss": 0.3355,
      "step": 11230
    },
    {
      "epoch": 1.4304031052145971,
      "grad_norm": 0.265865683555603,
      "learning_rate": 0.0001079946644189197,
      "loss": 0.3401,
      "step": 11240
    },
    {
      "epoch": 1.431675734147816,
      "grad_norm": 0.32611438632011414,
      "learning_rate": 0.00010786125281454195,
      "loss": 0.3472,
      "step": 11250
    },
    {
      "epoch": 1.4329483630810347,
      "grad_norm": 0.22776567935943604,
      "learning_rate": 0.00010772782712969123,
      "loss": 0.3408,
      "step": 11260
    },
    {
      "epoch": 1.4342209920142535,
      "grad_norm": 0.29155227541923523,
      "learning_rate": 0.00010759438760334939,
      "loss": 0.3283,
      "step": 11270
    },
    {
      "epoch": 1.4354936209474722,
      "grad_norm": 0.26967018842697144,
      "learning_rate": 0.00010746093447452301,
      "loss": 0.3239,
      "step": 11280
    },
    {
      "epoch": 1.436766249880691,
      "grad_norm": 0.2756986618041992,
      "learning_rate": 0.00010732746798224322,
      "loss": 0.3085,
      "step": 11290
    },
    {
      "epoch": 1.4380388788139098,
      "grad_norm": 0.23145920038223267,
      "learning_rate": 0.00010719398836556489,
      "loss": 0.3102,
      "step": 11300
    },
    {
      "epoch": 1.4393115077471286,
      "grad_norm": 0.26325151324272156,
      "learning_rate": 0.0001070604958635665,
      "loss": 0.3257,
      "step": 11310
    },
    {
      "epoch": 1.4405841366803473,
      "grad_norm": 0.3694950044155121,
      "learning_rate": 0.00010692699071534953,
      "loss": 0.3484,
      "step": 11320
    },
    {
      "epoch": 1.4418567656135663,
      "grad_norm": 0.28002893924713135,
      "learning_rate": 0.00010679347316003819,
      "loss": 0.3376,
      "step": 11330
    },
    {
      "epoch": 1.443129394546785,
      "grad_norm": 0.22651532292366028,
      "learning_rate": 0.00010665994343677888,
      "loss": 0.3127,
      "step": 11340
    },
    {
      "epoch": 1.444402023480004,
      "grad_norm": 0.2643214166164398,
      "learning_rate": 0.0001065264017847398,
      "loss": 0.3346,
      "step": 11350
    },
    {
      "epoch": 1.4456746524132227,
      "grad_norm": 0.32163920998573303,
      "learning_rate": 0.00010639284844311052,
      "loss": 0.3273,
      "step": 11360
    },
    {
      "epoch": 1.4469472813464415,
      "grad_norm": 0.24647891521453857,
      "learning_rate": 0.00010625928365110152,
      "loss": 0.3033,
      "step": 11370
    },
    {
      "epoch": 1.4482199102796602,
      "grad_norm": 0.2996882498264313,
      "learning_rate": 0.0001061257076479438,
      "loss": 0.3386,
      "step": 11380
    },
    {
      "epoch": 1.449492539212879,
      "grad_norm": 0.27223920822143555,
      "learning_rate": 0.00010599212067288848,
      "loss": 0.3412,
      "step": 11390
    },
    {
      "epoch": 1.4507651681460978,
      "grad_norm": 0.23863191902637482,
      "learning_rate": 0.00010585852296520633,
      "loss": 0.3241,
      "step": 11400
    },
    {
      "epoch": 1.4520377970793166,
      "grad_norm": 0.261631578207016,
      "learning_rate": 0.00010572491476418724,
      "loss": 0.3302,
      "step": 11410
    },
    {
      "epoch": 1.4533104260125354,
      "grad_norm": 0.22844237089157104,
      "learning_rate": 0.00010559129630914002,
      "loss": 0.3268,
      "step": 11420
    },
    {
      "epoch": 1.4545830549457541,
      "grad_norm": 0.2884453535079956,
      "learning_rate": 0.00010545766783939177,
      "loss": 0.3252,
      "step": 11430
    },
    {
      "epoch": 1.455855683878973,
      "grad_norm": 0.224858358502388,
      "learning_rate": 0.00010532402959428755,
      "loss": 0.3289,
      "step": 11440
    },
    {
      "epoch": 1.4571283128121917,
      "grad_norm": 0.24884025752544403,
      "learning_rate": 0.00010519038181318999,
      "loss": 0.3322,
      "step": 11450
    },
    {
      "epoch": 1.4584009417454107,
      "grad_norm": 0.23522363603115082,
      "learning_rate": 0.00010505672473547868,
      "loss": 0.3326,
      "step": 11460
    },
    {
      "epoch": 1.4596735706786295,
      "grad_norm": 0.25227120518684387,
      "learning_rate": 0.00010492305860054996,
      "loss": 0.3237,
      "step": 11470
    },
    {
      "epoch": 1.4609461996118482,
      "grad_norm": 0.25931650400161743,
      "learning_rate": 0.0001047893836478163,
      "loss": 0.3309,
      "step": 11480
    },
    {
      "epoch": 1.462218828545067,
      "grad_norm": 0.25363409519195557,
      "learning_rate": 0.00010465570011670611,
      "loss": 0.3115,
      "step": 11490
    },
    {
      "epoch": 1.4634914574782858,
      "grad_norm": 0.30509576201438904,
      "learning_rate": 0.00010452200824666301,
      "loss": 0.3181,
      "step": 11500
    },
    {
      "epoch": 1.4634914574782858,
      "eval_loss": 0.35477662086486816,
      "eval_runtime": 754.5217,
      "eval_samples_per_second": 10.415,
      "eval_steps_per_second": 5.207,
      "step": 11500
    },
    {
      "epoch": 1.4647640864115046,
      "grad_norm": 0.23842155933380127,
      "learning_rate": 0.00010438830827714565,
      "loss": 0.3185,
      "step": 11510
    },
    {
      "epoch": 1.4660367153447234,
      "grad_norm": 0.2886464595794678,
      "learning_rate": 0.00010425460044762712,
      "loss": 0.3143,
      "step": 11520
    },
    {
      "epoch": 1.4673093442779421,
      "grad_norm": 0.2817727327346802,
      "learning_rate": 0.00010412088499759467,
      "loss": 0.3306,
      "step": 11530
    },
    {
      "epoch": 1.468581973211161,
      "grad_norm": 0.3013974130153656,
      "learning_rate": 0.00010398716216654918,
      "loss": 0.3276,
      "step": 11540
    },
    {
      "epoch": 1.4698546021443797,
      "grad_norm": 0.30518069863319397,
      "learning_rate": 0.00010385343219400463,
      "loss": 0.3239,
      "step": 11550
    },
    {
      "epoch": 1.4711272310775985,
      "grad_norm": 0.24106936156749725,
      "learning_rate": 0.000103719695319488,
      "loss": 0.3302,
      "step": 11560
    },
    {
      "epoch": 1.4723998600108175,
      "grad_norm": 0.25816020369529724,
      "learning_rate": 0.00010358595178253842,
      "loss": 0.3058,
      "step": 11570
    },
    {
      "epoch": 1.473672488944036,
      "grad_norm": 0.20238925516605377,
      "learning_rate": 0.00010345220182270712,
      "loss": 0.3149,
      "step": 11580
    },
    {
      "epoch": 1.474945117877255,
      "grad_norm": 0.2583608031272888,
      "learning_rate": 0.00010331844567955675,
      "loss": 0.33,
      "step": 11590
    },
    {
      "epoch": 1.4762177468104738,
      "grad_norm": 0.23656173050403595,
      "learning_rate": 0.00010318468359266104,
      "loss": 0.3393,
      "step": 11600
    },
    {
      "epoch": 1.4774903757436926,
      "grad_norm": 0.21650853753089905,
      "learning_rate": 0.0001030509158016044,
      "loss": 0.3036,
      "step": 11610
    },
    {
      "epoch": 1.4787630046769114,
      "grad_norm": 0.3022911250591278,
      "learning_rate": 0.00010291714254598144,
      "loss": 0.3462,
      "step": 11620
    },
    {
      "epoch": 1.4800356336101301,
      "grad_norm": 0.27359575033187866,
      "learning_rate": 0.00010278336406539648,
      "loss": 0.3416,
      "step": 11630
    },
    {
      "epoch": 1.481308262543349,
      "grad_norm": 0.3051159977912903,
      "learning_rate": 0.00010264958059946339,
      "loss": 0.3274,
      "step": 11640
    },
    {
      "epoch": 1.4825808914765677,
      "grad_norm": 0.26607561111450195,
      "learning_rate": 0.00010251579238780475,
      "loss": 0.3225,
      "step": 11650
    },
    {
      "epoch": 1.4838535204097865,
      "grad_norm": 0.241928830742836,
      "learning_rate": 0.00010238199967005182,
      "loss": 0.3322,
      "step": 11660
    },
    {
      "epoch": 1.4851261493430052,
      "grad_norm": 0.3050496280193329,
      "learning_rate": 0.0001022482026858438,
      "loss": 0.3325,
      "step": 11670
    },
    {
      "epoch": 1.4863987782762242,
      "grad_norm": 0.2533072531223297,
      "learning_rate": 0.00010211440167482757,
      "loss": 0.3262,
      "step": 11680
    },
    {
      "epoch": 1.4876714072094428,
      "grad_norm": 0.4742822051048279,
      "learning_rate": 0.00010198059687665731,
      "loss": 0.3283,
      "step": 11690
    },
    {
      "epoch": 1.4889440361426618,
      "grad_norm": 0.2514771521091461,
      "learning_rate": 0.00010184678853099384,
      "loss": 0.307,
      "step": 11700
    },
    {
      "epoch": 1.4902166650758806,
      "grad_norm": 0.22864384949207306,
      "learning_rate": 0.00010171297687750443,
      "loss": 0.3307,
      "step": 11710
    },
    {
      "epoch": 1.4914892940090994,
      "grad_norm": 0.21084079146385193,
      "learning_rate": 0.00010157916215586225,
      "loss": 0.3158,
      "step": 11720
    },
    {
      "epoch": 1.4927619229423181,
      "grad_norm": 0.24825474619865417,
      "learning_rate": 0.00010144534460574595,
      "loss": 0.3196,
      "step": 11730
    },
    {
      "epoch": 1.494034551875537,
      "grad_norm": 0.2891831398010254,
      "learning_rate": 0.00010131152446683927,
      "loss": 0.302,
      "step": 11740
    },
    {
      "epoch": 1.4953071808087557,
      "grad_norm": 0.2862190008163452,
      "learning_rate": 0.00010117770197883058,
      "loss": 0.3178,
      "step": 11750
    },
    {
      "epoch": 1.4965798097419745,
      "grad_norm": 0.24470387399196625,
      "learning_rate": 0.00010104387738141245,
      "loss": 0.3527,
      "step": 11760
    },
    {
      "epoch": 1.4978524386751932,
      "grad_norm": 0.2248566448688507,
      "learning_rate": 0.00010091005091428128,
      "loss": 0.3384,
      "step": 11770
    },
    {
      "epoch": 1.499125067608412,
      "grad_norm": 0.27852725982666016,
      "learning_rate": 0.00010077622281713666,
      "loss": 0.3303,
      "step": 11780
    },
    {
      "epoch": 1.500397696541631,
      "grad_norm": 0.18422093987464905,
      "learning_rate": 0.0001006423933296813,
      "loss": 0.3117,
      "step": 11790
    },
    {
      "epoch": 1.5016703254748496,
      "grad_norm": 0.24991236627101898,
      "learning_rate": 0.0001005085626916203,
      "loss": 0.3336,
      "step": 11800
    },
    {
      "epoch": 1.5029429544080686,
      "grad_norm": 0.2498013973236084,
      "learning_rate": 0.0001003747311426608,
      "loss": 0.3193,
      "step": 11810
    },
    {
      "epoch": 1.5042155833412871,
      "grad_norm": 0.2553377151489258,
      "learning_rate": 0.00010024089892251167,
      "loss": 0.3226,
      "step": 11820
    },
    {
      "epoch": 1.5054882122745061,
      "grad_norm": 0.2382604330778122,
      "learning_rate": 0.00010010706627088279,
      "loss": 0.3345,
      "step": 11830
    },
    {
      "epoch": 1.506760841207725,
      "grad_norm": 0.2785032391548157,
      "learning_rate": 9.997323342748509e-05,
      "loss": 0.3079,
      "step": 11840
    },
    {
      "epoch": 1.5080334701409437,
      "grad_norm": 0.25742554664611816,
      "learning_rate": 9.983940063202956e-05,
      "loss": 0.3187,
      "step": 11850
    },
    {
      "epoch": 1.5093060990741625,
      "grad_norm": 0.2104780226945877,
      "learning_rate": 9.970556812422737e-05,
      "loss": 0.3221,
      "step": 11860
    },
    {
      "epoch": 1.5105787280073812,
      "grad_norm": 0.2540413439273834,
      "learning_rate": 9.957173614378892e-05,
      "loss": 0.3423,
      "step": 11870
    },
    {
      "epoch": 1.5118513569406,
      "grad_norm": 0.19916272163391113,
      "learning_rate": 9.943790493042388e-05,
      "loss": 0.3273,
      "step": 11880
    },
    {
      "epoch": 1.5131239858738188,
      "grad_norm": 0.2503020763397217,
      "learning_rate": 9.930407472384035e-05,
      "loss": 0.3243,
      "step": 11890
    },
    {
      "epoch": 1.5143966148070378,
      "grad_norm": 0.25431206822395325,
      "learning_rate": 9.91702457637448e-05,
      "loss": 0.3098,
      "step": 11900
    },
    {
      "epoch": 1.5156692437402564,
      "grad_norm": 0.2500157058238983,
      "learning_rate": 9.903641828984141e-05,
      "loss": 0.3214,
      "step": 11910
    },
    {
      "epoch": 1.5169418726734754,
      "grad_norm": 0.22475247085094452,
      "learning_rate": 9.890259254183165e-05,
      "loss": 0.3308,
      "step": 11920
    },
    {
      "epoch": 1.518214501606694,
      "grad_norm": 0.2479618638753891,
      "learning_rate": 9.876876875941396e-05,
      "loss": 0.3255,
      "step": 11930
    },
    {
      "epoch": 1.519487130539913,
      "grad_norm": 0.2963757812976837,
      "learning_rate": 9.863494718228317e-05,
      "loss": 0.3214,
      "step": 11940
    },
    {
      "epoch": 1.5207597594731315,
      "grad_norm": 0.2912064492702484,
      "learning_rate": 9.85011280501303e-05,
      "loss": 0.318,
      "step": 11950
    },
    {
      "epoch": 1.5220323884063505,
      "grad_norm": 0.31157371401786804,
      "learning_rate": 9.836731160264188e-05,
      "loss": 0.342,
      "step": 11960
    },
    {
      "epoch": 1.5233050173395692,
      "grad_norm": 0.2626962661743164,
      "learning_rate": 9.823349807949966e-05,
      "loss": 0.3178,
      "step": 11970
    },
    {
      "epoch": 1.524577646272788,
      "grad_norm": 0.21694539487361908,
      "learning_rate": 9.809968772038018e-05,
      "loss": 0.3105,
      "step": 11980
    },
    {
      "epoch": 1.5258502752060068,
      "grad_norm": 0.3023063838481903,
      "learning_rate": 9.796588076495427e-05,
      "loss": 0.3235,
      "step": 11990
    },
    {
      "epoch": 1.5271229041392256,
      "grad_norm": 0.27832120656967163,
      "learning_rate": 9.783207745288666e-05,
      "loss": 0.3302,
      "step": 12000
    },
    {
      "epoch": 1.5271229041392256,
      "eval_loss": 0.3532593846321106,
      "eval_runtime": 761.4893,
      "eval_samples_per_second": 10.319,
      "eval_steps_per_second": 5.16,
      "step": 12000
    },
    {
      "epoch": 1.5283955330724444,
      "grad_norm": 0.2650018632411957,
      "learning_rate": 9.769827802383564e-05,
      "loss": 0.323,
      "step": 12010
    },
    {
      "epoch": 1.5296681620056631,
      "grad_norm": 0.25893914699554443,
      "learning_rate": 9.756448271745244e-05,
      "loss": 0.313,
      "step": 12020
    },
    {
      "epoch": 1.5309407909388821,
      "grad_norm": 0.25593990087509155,
      "learning_rate": 9.743069177338096e-05,
      "loss": 0.2946,
      "step": 12030
    },
    {
      "epoch": 1.5322134198721007,
      "grad_norm": 0.23935237526893616,
      "learning_rate": 9.729690543125727e-05,
      "loss": 0.3064,
      "step": 12040
    },
    {
      "epoch": 1.5334860488053197,
      "grad_norm": 0.319789320230484,
      "learning_rate": 9.716312393070916e-05,
      "loss": 0.3187,
      "step": 12050
    },
    {
      "epoch": 1.5347586777385382,
      "grad_norm": 0.3721383213996887,
      "learning_rate": 9.702934751135592e-05,
      "loss": 0.3199,
      "step": 12060
    },
    {
      "epoch": 1.5360313066717572,
      "grad_norm": 0.3295016586780548,
      "learning_rate": 9.689557641280746e-05,
      "loss": 0.338,
      "step": 12070
    },
    {
      "epoch": 1.537303935604976,
      "grad_norm": 0.23917853832244873,
      "learning_rate": 9.676181087466444e-05,
      "loss": 0.3094,
      "step": 12080
    },
    {
      "epoch": 1.5385765645381948,
      "grad_norm": 0.24263574182987213,
      "learning_rate": 9.66280511365173e-05,
      "loss": 0.3416,
      "step": 12090
    },
    {
      "epoch": 1.5398491934714136,
      "grad_norm": 0.26136088371276855,
      "learning_rate": 9.649429743794632e-05,
      "loss": 0.3296,
      "step": 12100
    },
    {
      "epoch": 1.5411218224046324,
      "grad_norm": 0.23280735313892365,
      "learning_rate": 9.636055001852083e-05,
      "loss": 0.3256,
      "step": 12110
    },
    {
      "epoch": 1.5423944513378511,
      "grad_norm": 0.2794989049434662,
      "learning_rate": 9.622680911779895e-05,
      "loss": 0.3255,
      "step": 12120
    },
    {
      "epoch": 1.54366708027107,
      "grad_norm": 0.2899921238422394,
      "learning_rate": 9.609307497532714e-05,
      "loss": 0.3227,
      "step": 12130
    },
    {
      "epoch": 1.544939709204289,
      "grad_norm": 0.2790534496307373,
      "learning_rate": 9.595934783063969e-05,
      "loss": 0.3134,
      "step": 12140
    },
    {
      "epoch": 1.5462123381375075,
      "grad_norm": 0.2547493875026703,
      "learning_rate": 9.582562792325843e-05,
      "loss": 0.3387,
      "step": 12150
    },
    {
      "epoch": 1.5474849670707265,
      "grad_norm": 0.2159629613161087,
      "learning_rate": 9.569191549269222e-05,
      "loss": 0.3226,
      "step": 12160
    },
    {
      "epoch": 1.548757596003945,
      "grad_norm": 0.26701620221138,
      "learning_rate": 9.555821077843649e-05,
      "loss": 0.3267,
      "step": 12170
    },
    {
      "epoch": 1.550030224937164,
      "grad_norm": 0.23420265316963196,
      "learning_rate": 9.542451401997287e-05,
      "loss": 0.3131,
      "step": 12180
    },
    {
      "epoch": 1.5513028538703826,
      "grad_norm": 0.21309132874011993,
      "learning_rate": 9.529082545676871e-05,
      "loss": 0.3183,
      "step": 12190
    },
    {
      "epoch": 1.5525754828036016,
      "grad_norm": 0.25115713477134705,
      "learning_rate": 9.515714532827671e-05,
      "loss": 0.3264,
      "step": 12200
    },
    {
      "epoch": 1.5538481117368204,
      "grad_norm": 0.2963319718837738,
      "learning_rate": 9.502347387393456e-05,
      "loss": 0.3314,
      "step": 12210
    },
    {
      "epoch": 1.5551207406700391,
      "grad_norm": 0.27376988530158997,
      "learning_rate": 9.488981133316416e-05,
      "loss": 0.3162,
      "step": 12220
    },
    {
      "epoch": 1.556393369603258,
      "grad_norm": 0.25446662306785583,
      "learning_rate": 9.475615794537173e-05,
      "loss": 0.3251,
      "step": 12230
    },
    {
      "epoch": 1.5576659985364767,
      "grad_norm": 0.2760402262210846,
      "learning_rate": 9.462251394994687e-05,
      "loss": 0.3153,
      "step": 12240
    },
    {
      "epoch": 1.5589386274696955,
      "grad_norm": 0.2565188407897949,
      "learning_rate": 9.44888795862625e-05,
      "loss": 0.3138,
      "step": 12250
    },
    {
      "epoch": 1.5602112564029142,
      "grad_norm": 0.2112094908952713,
      "learning_rate": 9.435525509367427e-05,
      "loss": 0.3165,
      "step": 12260
    },
    {
      "epoch": 1.5614838853361332,
      "grad_norm": 0.326676607131958,
      "learning_rate": 9.422164071152006e-05,
      "loss": 0.3148,
      "step": 12270
    },
    {
      "epoch": 1.5627565142693518,
      "grad_norm": 0.2696566879749298,
      "learning_rate": 9.408803667911974e-05,
      "loss": 0.3491,
      "step": 12280
    },
    {
      "epoch": 1.5640291432025708,
      "grad_norm": 0.26331397891044617,
      "learning_rate": 9.395444323577457e-05,
      "loss": 0.3272,
      "step": 12290
    },
    {
      "epoch": 1.5653017721357894,
      "grad_norm": 0.23137500882148743,
      "learning_rate": 9.38208606207669e-05,
      "loss": 0.3292,
      "step": 12300
    },
    {
      "epoch": 1.5665744010690084,
      "grad_norm": 0.25401172041893005,
      "learning_rate": 9.368728907335968e-05,
      "loss": 0.328,
      "step": 12310
    },
    {
      "epoch": 1.5678470300022271,
      "grad_norm": 0.27382710576057434,
      "learning_rate": 9.355372883279597e-05,
      "loss": 0.3131,
      "step": 12320
    },
    {
      "epoch": 1.569119658935446,
      "grad_norm": 0.31729862093925476,
      "learning_rate": 9.342018013829868e-05,
      "loss": 0.3343,
      "step": 12330
    },
    {
      "epoch": 1.5703922878686647,
      "grad_norm": 0.32153263688087463,
      "learning_rate": 9.328664322906994e-05,
      "loss": 0.3222,
      "step": 12340
    },
    {
      "epoch": 1.5716649168018835,
      "grad_norm": 0.25121623277664185,
      "learning_rate": 9.315311834429085e-05,
      "loss": 0.3212,
      "step": 12350
    },
    {
      "epoch": 1.5729375457351022,
      "grad_norm": 0.2742295563220978,
      "learning_rate": 9.301960572312094e-05,
      "loss": 0.3052,
      "step": 12360
    },
    {
      "epoch": 1.574210174668321,
      "grad_norm": 0.28222334384918213,
      "learning_rate": 9.288610560469775e-05,
      "loss": 0.3142,
      "step": 12370
    },
    {
      "epoch": 1.57548280360154,
      "grad_norm": 0.3094383776187897,
      "learning_rate": 9.275261822813647e-05,
      "loss": 0.3185,
      "step": 12380
    },
    {
      "epoch": 1.5767554325347586,
      "grad_norm": 0.2744957208633423,
      "learning_rate": 9.261914383252944e-05,
      "loss": 0.3116,
      "step": 12390
    },
    {
      "epoch": 1.5780280614679776,
      "grad_norm": 0.33427923917770386,
      "learning_rate": 9.248568265694574e-05,
      "loss": 0.3227,
      "step": 12400
    },
    {
      "epoch": 1.5793006904011961,
      "grad_norm": 0.2623482048511505,
      "learning_rate": 9.235223494043087e-05,
      "loss": 0.3144,
      "step": 12410
    },
    {
      "epoch": 1.5805733193344151,
      "grad_norm": 0.2531767189502716,
      "learning_rate": 9.221880092200601e-05,
      "loss": 0.322,
      "step": 12420
    },
    {
      "epoch": 1.581845948267634,
      "grad_norm": 0.24264873564243317,
      "learning_rate": 9.20853808406681e-05,
      "loss": 0.3255,
      "step": 12430
    },
    {
      "epoch": 1.5831185772008527,
      "grad_norm": 0.29745030403137207,
      "learning_rate": 9.195197493538877e-05,
      "loss": 0.3087,
      "step": 12440
    },
    {
      "epoch": 1.5843912061340715,
      "grad_norm": 0.3763047158718109,
      "learning_rate": 9.181858344511458e-05,
      "loss": 0.3244,
      "step": 12450
    },
    {
      "epoch": 1.5856638350672903,
      "grad_norm": 0.22273169457912445,
      "learning_rate": 9.168520660876611e-05,
      "loss": 0.297,
      "step": 12460
    },
    {
      "epoch": 1.586936464000509,
      "grad_norm": 0.2746936082839966,
      "learning_rate": 9.155184466523767e-05,
      "loss": 0.3138,
      "step": 12470
    },
    {
      "epoch": 1.5882090929337278,
      "grad_norm": 0.2861240804195404,
      "learning_rate": 9.141849785339701e-05,
      "loss": 0.3252,
      "step": 12480
    },
    {
      "epoch": 1.5894817218669468,
      "grad_norm": 0.2960801422595978,
      "learning_rate": 9.128516641208464e-05,
      "loss": 0.3449,
      "step": 12490
    },
    {
      "epoch": 1.5907543508001654,
      "grad_norm": 0.2745448052883148,
      "learning_rate": 9.115185058011365e-05,
      "loss": 0.3143,
      "step": 12500
    },
    {
      "epoch": 1.5907543508001654,
      "eval_loss": 0.3523302972316742,
      "eval_runtime": 783.3033,
      "eval_samples_per_second": 10.032,
      "eval_steps_per_second": 5.016,
      "step": 12500
    },
    {
      "epoch": 1.5920269797333844,
      "grad_norm": 0.24804072082042694,
      "learning_rate": 9.101855059626914e-05,
      "loss": 0.3244,
      "step": 12510
    },
    {
      "epoch": 1.593299608666603,
      "grad_norm": 0.2550484836101532,
      "learning_rate": 9.088526669930777e-05,
      "loss": 0.3091,
      "step": 12520
    },
    {
      "epoch": 1.594572237599822,
      "grad_norm": 0.30070993304252625,
      "learning_rate": 9.07519991279575e-05,
      "loss": 0.3344,
      "step": 12530
    },
    {
      "epoch": 1.5958448665330405,
      "grad_norm": 0.244460329413414,
      "learning_rate": 9.06187481209169e-05,
      "loss": 0.3283,
      "step": 12540
    },
    {
      "epoch": 1.5971174954662595,
      "grad_norm": 0.2800757586956024,
      "learning_rate": 9.048551391685499e-05,
      "loss": 0.3489,
      "step": 12550
    },
    {
      "epoch": 1.5983901243994783,
      "grad_norm": 0.23891732096672058,
      "learning_rate": 9.035229675441071e-05,
      "loss": 0.3166,
      "step": 12560
    },
    {
      "epoch": 1.599662753332697,
      "grad_norm": 0.30104175209999084,
      "learning_rate": 9.021909687219231e-05,
      "loss": 0.3154,
      "step": 12570
    },
    {
      "epoch": 1.6009353822659158,
      "grad_norm": 0.23335739970207214,
      "learning_rate": 9.008591450877732e-05,
      "loss": 0.3085,
      "step": 12580
    },
    {
      "epoch": 1.6022080111991346,
      "grad_norm": 0.2872069478034973,
      "learning_rate": 8.995274990271165e-05,
      "loss": 0.3302,
      "step": 12590
    },
    {
      "epoch": 1.6034806401323534,
      "grad_norm": 0.24337680637836456,
      "learning_rate": 8.98196032925096e-05,
      "loss": 0.3252,
      "step": 12600
    },
    {
      "epoch": 1.6047532690655721,
      "grad_norm": 0.3269044756889343,
      "learning_rate": 8.968647491665319e-05,
      "loss": 0.3236,
      "step": 12610
    },
    {
      "epoch": 1.6060258979987911,
      "grad_norm": 0.29521772265434265,
      "learning_rate": 8.955336501359169e-05,
      "loss": 0.3131,
      "step": 12620
    },
    {
      "epoch": 1.6072985269320097,
      "grad_norm": 0.32828667759895325,
      "learning_rate": 8.942027382174138e-05,
      "loss": 0.3217,
      "step": 12630
    },
    {
      "epoch": 1.6085711558652287,
      "grad_norm": 0.2940322756767273,
      "learning_rate": 8.928720157948498e-05,
      "loss": 0.3165,
      "step": 12640
    },
    {
      "epoch": 1.6098437847984473,
      "grad_norm": 0.2532538175582886,
      "learning_rate": 8.915414852517128e-05,
      "loss": 0.323,
      "step": 12650
    },
    {
      "epoch": 1.6111164137316663,
      "grad_norm": 0.2776462137699127,
      "learning_rate": 8.902111489711474e-05,
      "loss": 0.3325,
      "step": 12660
    },
    {
      "epoch": 1.612389042664885,
      "grad_norm": 0.25045812129974365,
      "learning_rate": 8.888810093359494e-05,
      "loss": 0.3259,
      "step": 12670
    },
    {
      "epoch": 1.6136616715981038,
      "grad_norm": 0.2516268193721771,
      "learning_rate": 8.875510687285634e-05,
      "loss": 0.3091,
      "step": 12680
    },
    {
      "epoch": 1.6149343005313226,
      "grad_norm": 0.23188713192939758,
      "learning_rate": 8.862213295310762e-05,
      "loss": 0.327,
      "step": 12690
    },
    {
      "epoch": 1.6162069294645414,
      "grad_norm": 0.3010713756084442,
      "learning_rate": 8.84891794125215e-05,
      "loss": 0.3045,
      "step": 12700
    },
    {
      "epoch": 1.6174795583977601,
      "grad_norm": 0.3119451701641083,
      "learning_rate": 8.835624648923425e-05,
      "loss": 0.3084,
      "step": 12710
    },
    {
      "epoch": 1.618752187330979,
      "grad_norm": 0.30440646409988403,
      "learning_rate": 8.822333442134499e-05,
      "loss": 0.3202,
      "step": 12720
    },
    {
      "epoch": 1.620024816264198,
      "grad_norm": 0.30306190252304077,
      "learning_rate": 8.809044344691572e-05,
      "loss": 0.3439,
      "step": 12730
    },
    {
      "epoch": 1.6212974451974165,
      "grad_norm": 0.308992475271225,
      "learning_rate": 8.795757380397046e-05,
      "loss": 0.3355,
      "step": 12740
    },
    {
      "epoch": 1.6225700741306355,
      "grad_norm": 0.2777215242385864,
      "learning_rate": 8.782472573049521e-05,
      "loss": 0.3229,
      "step": 12750
    },
    {
      "epoch": 1.623842703063854,
      "grad_norm": 0.33518272638320923,
      "learning_rate": 8.769189946443723e-05,
      "loss": 0.3396,
      "step": 12760
    },
    {
      "epoch": 1.625115331997073,
      "grad_norm": 0.33147624135017395,
      "learning_rate": 8.755909524370471e-05,
      "loss": 0.3002,
      "step": 12770
    },
    {
      "epoch": 1.6263879609302916,
      "grad_norm": 0.2671622335910797,
      "learning_rate": 8.742631330616642e-05,
      "loss": 0.3194,
      "step": 12780
    },
    {
      "epoch": 1.6276605898635106,
      "grad_norm": 0.27084919810295105,
      "learning_rate": 8.729355388965112e-05,
      "loss": 0.3181,
      "step": 12790
    },
    {
      "epoch": 1.6289332187967294,
      "grad_norm": 0.2531411647796631,
      "learning_rate": 8.716081723194734e-05,
      "loss": 0.3176,
      "step": 12800
    },
    {
      "epoch": 1.6302058477299481,
      "grad_norm": 0.2640056610107422,
      "learning_rate": 8.702810357080281e-05,
      "loss": 0.3401,
      "step": 12810
    },
    {
      "epoch": 1.631478476663167,
      "grad_norm": 0.22961844503879547,
      "learning_rate": 8.689541314392402e-05,
      "loss": 0.3004,
      "step": 12820
    },
    {
      "epoch": 1.6327511055963857,
      "grad_norm": 0.2419082373380661,
      "learning_rate": 8.67627461889759e-05,
      "loss": 0.3158,
      "step": 12830
    },
    {
      "epoch": 1.6340237345296045,
      "grad_norm": 0.2930021286010742,
      "learning_rate": 8.663010294358133e-05,
      "loss": 0.3222,
      "step": 12840
    },
    {
      "epoch": 1.6352963634628233,
      "grad_norm": 0.28005731105804443,
      "learning_rate": 8.649748364532069e-05,
      "loss": 0.3186,
      "step": 12850
    },
    {
      "epoch": 1.6365689923960423,
      "grad_norm": 0.2533799707889557,
      "learning_rate": 8.636488853173155e-05,
      "loss": 0.3255,
      "step": 12860
    },
    {
      "epoch": 1.6378416213292608,
      "grad_norm": 0.25262632966041565,
      "learning_rate": 8.623231784030802e-05,
      "loss": 0.3138,
      "step": 12870
    },
    {
      "epoch": 1.6391142502624798,
      "grad_norm": 0.3372672498226166,
      "learning_rate": 8.609977180850065e-05,
      "loss": 0.3233,
      "step": 12880
    },
    {
      "epoch": 1.6403868791956984,
      "grad_norm": 0.33929765224456787,
      "learning_rate": 8.596725067371563e-05,
      "loss": 0.2944,
      "step": 12890
    },
    {
      "epoch": 1.6416595081289174,
      "grad_norm": 0.2678365111351013,
      "learning_rate": 8.583475467331468e-05,
      "loss": 0.3044,
      "step": 12900
    },
    {
      "epoch": 1.6429321370621361,
      "grad_norm": 0.2831602394580841,
      "learning_rate": 8.570228404461454e-05,
      "loss": 0.3272,
      "step": 12910
    },
    {
      "epoch": 1.644204765995355,
      "grad_norm": 0.3031449019908905,
      "learning_rate": 8.556983902488633e-05,
      "loss": 0.3363,
      "step": 12920
    },
    {
      "epoch": 1.6454773949285737,
      "grad_norm": 0.31341344118118286,
      "learning_rate": 8.543741985135552e-05,
      "loss": 0.332,
      "step": 12930
    },
    {
      "epoch": 1.6467500238617925,
      "grad_norm": 0.283033549785614,
      "learning_rate": 8.530502676120107e-05,
      "loss": 0.3321,
      "step": 12940
    },
    {
      "epoch": 1.6480226527950113,
      "grad_norm": 0.28758010268211365,
      "learning_rate": 8.517265999155538e-05,
      "loss": 0.3159,
      "step": 12950
    },
    {
      "epoch": 1.64929528172823,
      "grad_norm": 0.29013100266456604,
      "learning_rate": 8.504031977950366e-05,
      "loss": 0.3221,
      "step": 12960
    },
    {
      "epoch": 1.650567910661449,
      "grad_norm": 0.3266698122024536,
      "learning_rate": 8.490800636208354e-05,
      "loss": 0.3021,
      "step": 12970
    },
    {
      "epoch": 1.6518405395946676,
      "grad_norm": 0.23648567497730255,
      "learning_rate": 8.477571997628465e-05,
      "loss": 0.3224,
      "step": 12980
    },
    {
      "epoch": 1.6531131685278866,
      "grad_norm": 0.2808336019515991,
      "learning_rate": 8.464346085904821e-05,
      "loss": 0.3023,
      "step": 12990
    },
    {
      "epoch": 1.6543857974611051,
      "grad_norm": 0.2523978650569916,
      "learning_rate": 8.451122924726661e-05,
      "loss": 0.3301,
      "step": 13000
    },
    {
      "epoch": 1.6543857974611051,
      "eval_loss": 0.35184499621391296,
      "eval_runtime": 795.803,
      "eval_samples_per_second": 9.874,
      "eval_steps_per_second": 4.937,
      "step": 13000
    },
    {
      "epoch": 1.6556584263943241,
      "grad_norm": 0.26239538192749023,
      "learning_rate": 8.437902537778302e-05,
      "loss": 0.3033,
      "step": 13010
    },
    {
      "epoch": 1.656931055327543,
      "grad_norm": 0.22824309766292572,
      "learning_rate": 8.424684948739078e-05,
      "loss": 0.3027,
      "step": 13020
    },
    {
      "epoch": 1.6582036842607617,
      "grad_norm": 0.3660065829753876,
      "learning_rate": 8.411470181283327e-05,
      "loss": 0.3409,
      "step": 13030
    },
    {
      "epoch": 1.6594763131939805,
      "grad_norm": 0.29568347334861755,
      "learning_rate": 8.398258259080325e-05,
      "loss": 0.3111,
      "step": 13040
    },
    {
      "epoch": 1.6607489421271993,
      "grad_norm": 0.3511677086353302,
      "learning_rate": 8.385049205794249e-05,
      "loss": 0.3164,
      "step": 13050
    },
    {
      "epoch": 1.662021571060418,
      "grad_norm": 0.2727739214897156,
      "learning_rate": 8.371843045084153e-05,
      "loss": 0.3066,
      "step": 13060
    },
    {
      "epoch": 1.6632941999936368,
      "grad_norm": 0.32128235697746277,
      "learning_rate": 8.358639800603886e-05,
      "loss": 0.3129,
      "step": 13070
    },
    {
      "epoch": 1.6645668289268558,
      "grad_norm": 0.34411200881004333,
      "learning_rate": 8.345439496002099e-05,
      "loss": 0.3293,
      "step": 13080
    },
    {
      "epoch": 1.6658394578600744,
      "grad_norm": 0.2110840380191803,
      "learning_rate": 8.332242154922151e-05,
      "loss": 0.3211,
      "step": 13090
    },
    {
      "epoch": 1.6671120867932934,
      "grad_norm": 0.278697669506073,
      "learning_rate": 8.319047801002118e-05,
      "loss": 0.3243,
      "step": 13100
    },
    {
      "epoch": 1.668384715726512,
      "grad_norm": 0.32670465111732483,
      "learning_rate": 8.305856457874713e-05,
      "loss": 0.3333,
      "step": 13110
    },
    {
      "epoch": 1.669657344659731,
      "grad_norm": 0.27680185437202454,
      "learning_rate": 8.292668149167254e-05,
      "loss": 0.31,
      "step": 13120
    },
    {
      "epoch": 1.6709299735929495,
      "grad_norm": 0.239023819565773,
      "learning_rate": 8.279482898501633e-05,
      "loss": 0.3221,
      "step": 13130
    },
    {
      "epoch": 1.6722026025261685,
      "grad_norm": 0.31655246019363403,
      "learning_rate": 8.266300729494251e-05,
      "loss": 0.3054,
      "step": 13140
    },
    {
      "epoch": 1.6734752314593873,
      "grad_norm": 0.2922411561012268,
      "learning_rate": 8.253121665756007e-05,
      "loss": 0.3143,
      "step": 13150
    },
    {
      "epoch": 1.674747860392606,
      "grad_norm": 0.26564228534698486,
      "learning_rate": 8.239945730892225e-05,
      "loss": 0.3307,
      "step": 13160
    },
    {
      "epoch": 1.6760204893258248,
      "grad_norm": 0.3421812057495117,
      "learning_rate": 8.226772948502628e-05,
      "loss": 0.3044,
      "step": 13170
    },
    {
      "epoch": 1.6772931182590436,
      "grad_norm": 0.282481849193573,
      "learning_rate": 8.213603342181295e-05,
      "loss": 0.3219,
      "step": 13180
    },
    {
      "epoch": 1.6785657471922624,
      "grad_norm": 0.25477707386016846,
      "learning_rate": 8.200436935516612e-05,
      "loss": 0.3184,
      "step": 13190
    },
    {
      "epoch": 1.6798383761254811,
      "grad_norm": 0.3215925395488739,
      "learning_rate": 8.187273752091239e-05,
      "loss": 0.319,
      "step": 13200
    },
    {
      "epoch": 1.6811110050587001,
      "grad_norm": 0.2815430760383606,
      "learning_rate": 8.174113815482061e-05,
      "loss": 0.3342,
      "step": 13210
    },
    {
      "epoch": 1.6823836339919187,
      "grad_norm": 0.27902382612228394,
      "learning_rate": 8.160957149260145e-05,
      "loss": 0.336,
      "step": 13220
    },
    {
      "epoch": 1.6836562629251377,
      "grad_norm": 0.25899454951286316,
      "learning_rate": 8.147803776990703e-05,
      "loss": 0.3361,
      "step": 13230
    },
    {
      "epoch": 1.6849288918583563,
      "grad_norm": 0.2996755540370941,
      "learning_rate": 8.134653722233044e-05,
      "loss": 0.3137,
      "step": 13240
    },
    {
      "epoch": 1.6862015207915753,
      "grad_norm": 0.2580454647541046,
      "learning_rate": 8.121507008540538e-05,
      "loss": 0.3128,
      "step": 13250
    },
    {
      "epoch": 1.687474149724794,
      "grad_norm": 0.26572349667549133,
      "learning_rate": 8.108363659460579e-05,
      "loss": 0.3134,
      "step": 13260
    },
    {
      "epoch": 1.6887467786580128,
      "grad_norm": 0.29261425137519836,
      "learning_rate": 8.095223698534509e-05,
      "loss": 0.3119,
      "step": 13270
    },
    {
      "epoch": 1.6900194075912316,
      "grad_norm": 0.28441497683525085,
      "learning_rate": 8.082087149297635e-05,
      "loss": 0.315,
      "step": 13280
    },
    {
      "epoch": 1.6912920365244504,
      "grad_norm": 0.21658632159233093,
      "learning_rate": 8.068954035279121e-05,
      "loss": 0.2957,
      "step": 13290
    },
    {
      "epoch": 1.6925646654576691,
      "grad_norm": 0.307929664850235,
      "learning_rate": 8.055824380002005e-05,
      "loss": 0.3113,
      "step": 13300
    },
    {
      "epoch": 1.693837294390888,
      "grad_norm": 0.28753596544265747,
      "learning_rate": 8.042698206983113e-05,
      "loss": 0.3016,
      "step": 13310
    },
    {
      "epoch": 1.695109923324107,
      "grad_norm": 0.2155734747648239,
      "learning_rate": 8.02957553973304e-05,
      "loss": 0.3112,
      "step": 13320
    },
    {
      "epoch": 1.6963825522573255,
      "grad_norm": 0.28430142998695374,
      "learning_rate": 8.016456401756102e-05,
      "loss": 0.3102,
      "step": 13330
    },
    {
      "epoch": 1.6976551811905445,
      "grad_norm": 0.3482561409473419,
      "learning_rate": 8.00334081655029e-05,
      "loss": 0.3207,
      "step": 13340
    },
    {
      "epoch": 1.698927810123763,
      "grad_norm": 0.29350972175598145,
      "learning_rate": 7.990228807607235e-05,
      "loss": 0.3209,
      "step": 13350
    },
    {
      "epoch": 1.700200439056982,
      "grad_norm": 0.3125939965248108,
      "learning_rate": 7.977120398412165e-05,
      "loss": 0.3213,
      "step": 13360
    },
    {
      "epoch": 1.7014730679902006,
      "grad_norm": 0.3286362588405609,
      "learning_rate": 7.964015612443851e-05,
      "loss": 0.3356,
      "step": 13370
    },
    {
      "epoch": 1.7027456969234196,
      "grad_norm": 0.3137268126010895,
      "learning_rate": 7.950914473174585e-05,
      "loss": 0.3169,
      "step": 13380
    },
    {
      "epoch": 1.7040183258566384,
      "grad_norm": 0.25287890434265137,
      "learning_rate": 7.93781700407012e-05,
      "loss": 0.3079,
      "step": 13390
    },
    {
      "epoch": 1.7052909547898571,
      "grad_norm": 0.29038530588150024,
      "learning_rate": 7.924723228589636e-05,
      "loss": 0.3344,
      "step": 13400
    },
    {
      "epoch": 1.706563583723076,
      "grad_norm": 0.2484855353832245,
      "learning_rate": 7.91163317018571e-05,
      "loss": 0.3344,
      "step": 13410
    },
    {
      "epoch": 1.7078362126562947,
      "grad_norm": 0.2730982005596161,
      "learning_rate": 7.898546852304233e-05,
      "loss": 0.3178,
      "step": 13420
    },
    {
      "epoch": 1.7091088415895135,
      "grad_norm": 0.3357030749320984,
      "learning_rate": 7.885464298384432e-05,
      "loss": 0.3348,
      "step": 13430
    },
    {
      "epoch": 1.7103814705227323,
      "grad_norm": 0.3557148873806,
      "learning_rate": 7.872385531858757e-05,
      "loss": 0.32,
      "step": 13440
    },
    {
      "epoch": 1.7116540994559513,
      "grad_norm": 0.25479814410209656,
      "learning_rate": 7.859310576152904e-05,
      "loss": 0.3187,
      "step": 13450
    },
    {
      "epoch": 1.7129267283891698,
      "grad_norm": 0.22860588133335114,
      "learning_rate": 7.846239454685727e-05,
      "loss": 0.3288,
      "step": 13460
    },
    {
      "epoch": 1.7141993573223888,
      "grad_norm": 0.28332334756851196,
      "learning_rate": 7.833172190869212e-05,
      "loss": 0.3257,
      "step": 13470
    },
    {
      "epoch": 1.7154719862556074,
      "grad_norm": 0.2491077482700348,
      "learning_rate": 7.820108808108444e-05,
      "loss": 0.3205,
      "step": 13480
    },
    {
      "epoch": 1.7167446151888264,
      "grad_norm": 0.3292315602302551,
      "learning_rate": 7.80704932980155e-05,
      "loss": 0.3416,
      "step": 13490
    },
    {
      "epoch": 1.7180172441220452,
      "grad_norm": 0.29027992486953735,
      "learning_rate": 7.793993779339665e-05,
      "loss": 0.3115,
      "step": 13500
    },
    {
      "epoch": 1.7180172441220452,
      "eval_loss": 0.35016143321990967,
      "eval_runtime": 826.8945,
      "eval_samples_per_second": 9.503,
      "eval_steps_per_second": 4.752,
      "step": 13500
    },
    {
      "epoch": 1.719289873055264,
      "grad_norm": 0.23733378946781158,
      "learning_rate": 7.780942180106895e-05,
      "loss": 0.3285,
      "step": 13510
    },
    {
      "epoch": 1.7205625019884827,
      "grad_norm": 0.28144821524620056,
      "learning_rate": 7.767894555480256e-05,
      "loss": 0.308,
      "step": 13520
    },
    {
      "epoch": 1.7218351309217015,
      "grad_norm": 0.23234985768795013,
      "learning_rate": 7.754850928829655e-05,
      "loss": 0.3264,
      "step": 13530
    },
    {
      "epoch": 1.7231077598549203,
      "grad_norm": 0.30710411071777344,
      "learning_rate": 7.741811323517836e-05,
      "loss": 0.3299,
      "step": 13540
    },
    {
      "epoch": 1.724380388788139,
      "grad_norm": 0.27453112602233887,
      "learning_rate": 7.728775762900338e-05,
      "loss": 0.3402,
      "step": 13550
    },
    {
      "epoch": 1.725653017721358,
      "grad_norm": 0.3143596351146698,
      "learning_rate": 7.715744270325464e-05,
      "loss": 0.3228,
      "step": 13560
    },
    {
      "epoch": 1.7269256466545766,
      "grad_norm": 0.28253626823425293,
      "learning_rate": 7.702716869134211e-05,
      "loss": 0.319,
      "step": 13570
    },
    {
      "epoch": 1.7281982755877956,
      "grad_norm": 0.3118860423564911,
      "learning_rate": 7.689693582660275e-05,
      "loss": 0.3143,
      "step": 13580
    },
    {
      "epoch": 1.7294709045210142,
      "grad_norm": 0.25796011090278625,
      "learning_rate": 7.676674434229955e-05,
      "loss": 0.3068,
      "step": 13590
    },
    {
      "epoch": 1.7307435334542332,
      "grad_norm": 0.30043935775756836,
      "learning_rate": 7.663659447162159e-05,
      "loss": 0.3244,
      "step": 13600
    },
    {
      "epoch": 1.732016162387452,
      "grad_norm": 0.3375853896141052,
      "learning_rate": 7.650648644768332e-05,
      "loss": 0.3347,
      "step": 13610
    },
    {
      "epoch": 1.7332887913206707,
      "grad_norm": 0.26949816942214966,
      "learning_rate": 7.637642050352424e-05,
      "loss": 0.3239,
      "step": 13620
    },
    {
      "epoch": 1.7345614202538895,
      "grad_norm": 0.30138981342315674,
      "learning_rate": 7.624639687210849e-05,
      "loss": 0.3239,
      "step": 13630
    },
    {
      "epoch": 1.7358340491871083,
      "grad_norm": 0.29420122504234314,
      "learning_rate": 7.611641578632443e-05,
      "loss": 0.3215,
      "step": 13640
    },
    {
      "epoch": 1.737106678120327,
      "grad_norm": 0.3137451708316803,
      "learning_rate": 7.598647747898418e-05,
      "loss": 0.3331,
      "step": 13650
    },
    {
      "epoch": 1.7383793070535458,
      "grad_norm": 0.2847093641757965,
      "learning_rate": 7.585658218282333e-05,
      "loss": 0.3111,
      "step": 13660
    },
    {
      "epoch": 1.7396519359867648,
      "grad_norm": 0.27688804268836975,
      "learning_rate": 7.572673013050032e-05,
      "loss": 0.3141,
      "step": 13670
    },
    {
      "epoch": 1.7409245649199834,
      "grad_norm": 0.24222774803638458,
      "learning_rate": 7.559692155459621e-05,
      "loss": 0.3344,
      "step": 13680
    },
    {
      "epoch": 1.7421971938532024,
      "grad_norm": 0.25201454758644104,
      "learning_rate": 7.546715668761412e-05,
      "loss": 0.3163,
      "step": 13690
    },
    {
      "epoch": 1.743469822786421,
      "grad_norm": 0.2398170679807663,
      "learning_rate": 7.533743576197898e-05,
      "loss": 0.3221,
      "step": 13700
    },
    {
      "epoch": 1.74474245171964,
      "grad_norm": 0.2507196366786957,
      "learning_rate": 7.520775901003695e-05,
      "loss": 0.3198,
      "step": 13710
    },
    {
      "epoch": 1.7460150806528585,
      "grad_norm": 0.24925392866134644,
      "learning_rate": 7.507812666405505e-05,
      "loss": 0.3359,
      "step": 13720
    },
    {
      "epoch": 1.7472877095860775,
      "grad_norm": 0.30806535482406616,
      "learning_rate": 7.494853895622083e-05,
      "loss": 0.3358,
      "step": 13730
    },
    {
      "epoch": 1.7485603385192963,
      "grad_norm": 0.2738070487976074,
      "learning_rate": 7.48189961186418e-05,
      "loss": 0.3355,
      "step": 13740
    },
    {
      "epoch": 1.749832967452515,
      "grad_norm": 0.3674236238002777,
      "learning_rate": 7.468949838334516e-05,
      "loss": 0.3427,
      "step": 13750
    },
    {
      "epoch": 1.7511055963857338,
      "grad_norm": 0.2720787227153778,
      "learning_rate": 7.456004598227741e-05,
      "loss": 0.3346,
      "step": 13760
    },
    {
      "epoch": 1.7523782253189526,
      "grad_norm": 0.22561416029930115,
      "learning_rate": 7.443063914730365e-05,
      "loss": 0.2994,
      "step": 13770
    },
    {
      "epoch": 1.7536508542521714,
      "grad_norm": 0.24727103114128113,
      "learning_rate": 7.430127811020757e-05,
      "loss": 0.3076,
      "step": 13780
    },
    {
      "epoch": 1.7549234831853902,
      "grad_norm": 0.30812326073646545,
      "learning_rate": 7.417196310269062e-05,
      "loss": 0.311,
      "step": 13790
    },
    {
      "epoch": 1.7561961121186092,
      "grad_norm": 0.26521292328834534,
      "learning_rate": 7.404269435637201e-05,
      "loss": 0.3407,
      "step": 13800
    },
    {
      "epoch": 1.7574687410518277,
      "grad_norm": 0.3206522464752197,
      "learning_rate": 7.391347210278801e-05,
      "loss": 0.3397,
      "step": 13810
    },
    {
      "epoch": 1.7587413699850467,
      "grad_norm": 0.2837716341018677,
      "learning_rate": 7.378429657339155e-05,
      "loss": 0.3147,
      "step": 13820
    },
    {
      "epoch": 1.7600139989182653,
      "grad_norm": 0.22677645087242126,
      "learning_rate": 7.365516799955197e-05,
      "loss": 0.312,
      "step": 13830
    },
    {
      "epoch": 1.7612866278514843,
      "grad_norm": 0.3395921587944031,
      "learning_rate": 7.352608661255442e-05,
      "loss": 0.3209,
      "step": 13840
    },
    {
      "epoch": 1.762559256784703,
      "grad_norm": 0.25734636187553406,
      "learning_rate": 7.339705264359962e-05,
      "loss": 0.3252,
      "step": 13850
    },
    {
      "epoch": 1.7638318857179218,
      "grad_norm": 0.2840256690979004,
      "learning_rate": 7.326806632380332e-05,
      "loss": 0.3167,
      "step": 13860
    },
    {
      "epoch": 1.7651045146511406,
      "grad_norm": 0.2619750499725342,
      "learning_rate": 7.313912788419587e-05,
      "loss": 0.3329,
      "step": 13870
    },
    {
      "epoch": 1.7663771435843594,
      "grad_norm": 0.27333882451057434,
      "learning_rate": 7.3010237555722e-05,
      "loss": 0.3406,
      "step": 13880
    },
    {
      "epoch": 1.7676497725175782,
      "grad_norm": 0.34128594398498535,
      "learning_rate": 7.288139556924008e-05,
      "loss": 0.3184,
      "step": 13890
    },
    {
      "epoch": 1.768922401450797,
      "grad_norm": 0.3091717064380646,
      "learning_rate": 7.275260215552202e-05,
      "loss": 0.3353,
      "step": 13900
    },
    {
      "epoch": 1.770195030384016,
      "grad_norm": 0.31605449318885803,
      "learning_rate": 7.26238575452528e-05,
      "loss": 0.3093,
      "step": 13910
    },
    {
      "epoch": 1.7714676593172345,
      "grad_norm": 0.31367820501327515,
      "learning_rate": 7.249516196902972e-05,
      "loss": 0.3152,
      "step": 13920
    },
    {
      "epoch": 1.7727402882504535,
      "grad_norm": 0.2969973087310791,
      "learning_rate": 7.236651565736259e-05,
      "loss": 0.3465,
      "step": 13930
    },
    {
      "epoch": 1.774012917183672,
      "grad_norm": 0.2763221859931946,
      "learning_rate": 7.223791884067268e-05,
      "loss": 0.3128,
      "step": 13940
    },
    {
      "epoch": 1.775285546116891,
      "grad_norm": 0.3620033860206604,
      "learning_rate": 7.210937174929282e-05,
      "loss": 0.3195,
      "step": 13950
    },
    {
      "epoch": 1.7765581750501096,
      "grad_norm": 0.2818026840686798,
      "learning_rate": 7.198087461346669e-05,
      "loss": 0.3294,
      "step": 13960
    },
    {
      "epoch": 1.7778308039833286,
      "grad_norm": 0.3162069022655487,
      "learning_rate": 7.185242766334848e-05,
      "loss": 0.3145,
      "step": 13970
    },
    {
      "epoch": 1.7791034329165474,
      "grad_norm": 0.22883343696594238,
      "learning_rate": 7.172403112900254e-05,
      "loss": 0.3361,
      "step": 13980
    },
    {
      "epoch": 1.7803760618497662,
      "grad_norm": 0.2726796567440033,
      "learning_rate": 7.159568524040285e-05,
      "loss": 0.3214,
      "step": 13990
    },
    {
      "epoch": 1.781648690782985,
      "grad_norm": 0.278603732585907,
      "learning_rate": 7.146739022743276e-05,
      "loss": 0.3071,
      "step": 14000
    },
    {
      "epoch": 1.781648690782985,
      "eval_loss": 0.34863409399986267,
      "eval_runtime": 775.4585,
      "eval_samples_per_second": 10.133,
      "eval_steps_per_second": 5.067,
      "step": 14000
    },
    {
      "epoch": 1.7829213197162037,
      "grad_norm": 0.3008212745189667,
      "learning_rate": 7.133914631988445e-05,
      "loss": 0.3462,
      "step": 14010
    },
    {
      "epoch": 1.7841939486494225,
      "grad_norm": 0.32969239354133606,
      "learning_rate": 7.121095374745854e-05,
      "loss": 0.3122,
      "step": 14020
    },
    {
      "epoch": 1.7854665775826413,
      "grad_norm": 0.310640424489975,
      "learning_rate": 7.108281273976378e-05,
      "loss": 0.3074,
      "step": 14030
    },
    {
      "epoch": 1.7867392065158603,
      "grad_norm": 0.2658417224884033,
      "learning_rate": 7.095472352631647e-05,
      "loss": 0.3026,
      "step": 14040
    },
    {
      "epoch": 1.7880118354490788,
      "grad_norm": 0.27799275517463684,
      "learning_rate": 7.082668633654019e-05,
      "loss": 0.2963,
      "step": 14050
    },
    {
      "epoch": 1.7892844643822978,
      "grad_norm": 0.27560198307037354,
      "learning_rate": 7.069870139976536e-05,
      "loss": 0.3287,
      "step": 14060
    },
    {
      "epoch": 1.7905570933155164,
      "grad_norm": 0.2420549988746643,
      "learning_rate": 7.057076894522874e-05,
      "loss": 0.3221,
      "step": 14070
    },
    {
      "epoch": 1.7918297222487354,
      "grad_norm": 0.3028004765510559,
      "learning_rate": 7.044288920207318e-05,
      "loss": 0.3265,
      "step": 14080
    },
    {
      "epoch": 1.7931023511819542,
      "grad_norm": 0.25081267952919006,
      "learning_rate": 7.0315062399347e-05,
      "loss": 0.3218,
      "step": 14090
    },
    {
      "epoch": 1.794374980115173,
      "grad_norm": 0.24731843173503876,
      "learning_rate": 7.018728876600378e-05,
      "loss": 0.2962,
      "step": 14100
    },
    {
      "epoch": 1.7956476090483917,
      "grad_norm": 0.3026806712150574,
      "learning_rate": 7.005956853090194e-05,
      "loss": 0.3068,
      "step": 14110
    },
    {
      "epoch": 1.7969202379816105,
      "grad_norm": 0.26465320587158203,
      "learning_rate": 6.993190192280403e-05,
      "loss": 0.3034,
      "step": 14120
    },
    {
      "epoch": 1.7981928669148293,
      "grad_norm": 0.3370199203491211,
      "learning_rate": 6.98042891703768e-05,
      "loss": 0.3039,
      "step": 14130
    },
    {
      "epoch": 1.799465495848048,
      "grad_norm": 0.29041165113449097,
      "learning_rate": 6.967673050219033e-05,
      "loss": 0.3291,
      "step": 14140
    },
    {
      "epoch": 1.800738124781267,
      "grad_norm": 0.29844537377357483,
      "learning_rate": 6.954922614671795e-05,
      "loss": 0.3131,
      "step": 14150
    },
    {
      "epoch": 1.8020107537144856,
      "grad_norm": 0.2723473012447357,
      "learning_rate": 6.942177633233574e-05,
      "loss": 0.3265,
      "step": 14160
    },
    {
      "epoch": 1.8032833826477046,
      "grad_norm": 0.26325932145118713,
      "learning_rate": 6.929438128732195e-05,
      "loss": 0.3317,
      "step": 14170
    },
    {
      "epoch": 1.8045560115809232,
      "grad_norm": 0.25296342372894287,
      "learning_rate": 6.916704123985689e-05,
      "loss": 0.308,
      "step": 14180
    },
    {
      "epoch": 1.8058286405141422,
      "grad_norm": 0.27401506900787354,
      "learning_rate": 6.90397564180222e-05,
      "loss": 0.3155,
      "step": 14190
    },
    {
      "epoch": 1.807101269447361,
      "grad_norm": 0.2996078431606293,
      "learning_rate": 6.891252704980071e-05,
      "loss": 0.3132,
      "step": 14200
    },
    {
      "epoch": 1.8083738983805797,
      "grad_norm": 0.2829519808292389,
      "learning_rate": 6.878535336307597e-05,
      "loss": 0.2996,
      "step": 14210
    },
    {
      "epoch": 1.8096465273137985,
      "grad_norm": 0.28167128562927246,
      "learning_rate": 6.865823558563164e-05,
      "loss": 0.3181,
      "step": 14220
    },
    {
      "epoch": 1.8109191562470173,
      "grad_norm": 0.2999226152896881,
      "learning_rate": 6.853117394515143e-05,
      "loss": 0.3431,
      "step": 14230
    },
    {
      "epoch": 1.812191785180236,
      "grad_norm": 0.3549167811870575,
      "learning_rate": 6.84041686692183e-05,
      "loss": 0.3437,
      "step": 14240
    },
    {
      "epoch": 1.8134644141134548,
      "grad_norm": 0.26375189423561096,
      "learning_rate": 6.827721998531439e-05,
      "loss": 0.3127,
      "step": 14250
    },
    {
      "epoch": 1.8147370430466738,
      "grad_norm": 0.2844795286655426,
      "learning_rate": 6.815032812082052e-05,
      "loss": 0.3158,
      "step": 14260
    },
    {
      "epoch": 1.8160096719798924,
      "grad_norm": 0.2817551791667938,
      "learning_rate": 6.802349330301554e-05,
      "loss": 0.3347,
      "step": 14270
    },
    {
      "epoch": 1.8172823009131114,
      "grad_norm": 0.27918267250061035,
      "learning_rate": 6.789671575907637e-05,
      "loss": 0.3149,
      "step": 14280
    },
    {
      "epoch": 1.81855492984633,
      "grad_norm": 0.2514546811580658,
      "learning_rate": 6.776999571607709e-05,
      "loss": 0.3193,
      "step": 14290
    },
    {
      "epoch": 1.819827558779549,
      "grad_norm": 0.34963852167129517,
      "learning_rate": 6.764333340098902e-05,
      "loss": 0.3162,
      "step": 14300
    },
    {
      "epoch": 1.8211001877127675,
      "grad_norm": 0.2833668291568756,
      "learning_rate": 6.751672904067997e-05,
      "loss": 0.306,
      "step": 14310
    },
    {
      "epoch": 1.8223728166459865,
      "grad_norm": 0.26879268884658813,
      "learning_rate": 6.73901828619139e-05,
      "loss": 0.3109,
      "step": 14320
    },
    {
      "epoch": 1.8236454455792053,
      "grad_norm": 0.22021181881427765,
      "learning_rate": 6.72636950913507e-05,
      "loss": 0.2996,
      "step": 14330
    },
    {
      "epoch": 1.824918074512424,
      "grad_norm": 0.2698112726211548,
      "learning_rate": 6.713726595554549e-05,
      "loss": 0.3108,
      "step": 14340
    },
    {
      "epoch": 1.8261907034456428,
      "grad_norm": 0.30398884415626526,
      "learning_rate": 6.701089568094845e-05,
      "loss": 0.3134,
      "step": 14350
    },
    {
      "epoch": 1.8274633323788616,
      "grad_norm": 0.3442233204841614,
      "learning_rate": 6.688458449390437e-05,
      "loss": 0.3288,
      "step": 14360
    },
    {
      "epoch": 1.8287359613120804,
      "grad_norm": 0.29485952854156494,
      "learning_rate": 6.67583326206521e-05,
      "loss": 0.3359,
      "step": 14370
    },
    {
      "epoch": 1.8300085902452992,
      "grad_norm": 0.25229454040527344,
      "learning_rate": 6.663214028732437e-05,
      "loss": 0.3087,
      "step": 14380
    },
    {
      "epoch": 1.8312812191785182,
      "grad_norm": 0.26887068152427673,
      "learning_rate": 6.650600771994715e-05,
      "loss": 0.3128,
      "step": 14390
    },
    {
      "epoch": 1.8325538481117367,
      "grad_norm": 0.32134461402893066,
      "learning_rate": 6.63799351444394e-05,
      "loss": 0.3146,
      "step": 14400
    },
    {
      "epoch": 1.8338264770449557,
      "grad_norm": 0.3071373999118805,
      "learning_rate": 6.625392278661278e-05,
      "loss": 0.3256,
      "step": 14410
    },
    {
      "epoch": 1.8350991059781743,
      "grad_norm": 0.33941787481307983,
      "learning_rate": 6.612797087217077e-05,
      "loss": 0.3087,
      "step": 14420
    },
    {
      "epoch": 1.8363717349113933,
      "grad_norm": 0.28379911184310913,
      "learning_rate": 6.600207962670896e-05,
      "loss": 0.3192,
      "step": 14430
    },
    {
      "epoch": 1.837644363844612,
      "grad_norm": 0.30082228779792786,
      "learning_rate": 6.587624927571394e-05,
      "loss": 0.3347,
      "step": 14440
    },
    {
      "epoch": 1.8389169927778308,
      "grad_norm": 0.3523917496204376,
      "learning_rate": 6.575048004456345e-05,
      "loss": 0.3196,
      "step": 14450
    },
    {
      "epoch": 1.8401896217110496,
      "grad_norm": 0.27649617195129395,
      "learning_rate": 6.562477215852571e-05,
      "loss": 0.308,
      "step": 14460
    },
    {
      "epoch": 1.8414622506442684,
      "grad_norm": 0.3068091869354248,
      "learning_rate": 6.549912584275901e-05,
      "loss": 0.3183,
      "step": 14470
    },
    {
      "epoch": 1.8427348795774872,
      "grad_norm": 0.24566638469696045,
      "learning_rate": 6.537354132231141e-05,
      "loss": 0.3039,
      "step": 14480
    },
    {
      "epoch": 1.844007508510706,
      "grad_norm": 0.25593042373657227,
      "learning_rate": 6.524801882212024e-05,
      "loss": 0.3398,
      "step": 14490
    },
    {
      "epoch": 1.845280137443925,
      "grad_norm": 0.3198683559894562,
      "learning_rate": 6.512255856701177e-05,
      "loss": 0.3053,
      "step": 14500
    },
    {
      "epoch": 1.845280137443925,
      "eval_loss": 0.3477150499820709,
      "eval_runtime": 738.4059,
      "eval_samples_per_second": 10.642,
      "eval_steps_per_second": 5.321,
      "step": 14500
    },
    {
      "epoch": 1.8465527663771435,
      "grad_norm": 0.35028982162475586,
      "learning_rate": 6.499716078170083e-05,
      "loss": 0.3401,
      "step": 14510
    },
    {
      "epoch": 1.8478253953103625,
      "grad_norm": 0.29384517669677734,
      "learning_rate": 6.487182569079029e-05,
      "loss": 0.331,
      "step": 14520
    },
    {
      "epoch": 1.849098024243581,
      "grad_norm": 0.29255592823028564,
      "learning_rate": 6.474655351877074e-05,
      "loss": 0.337,
      "step": 14530
    },
    {
      "epoch": 1.8503706531768,
      "grad_norm": 0.3136346936225891,
      "learning_rate": 6.462134449002009e-05,
      "loss": 0.3119,
      "step": 14540
    },
    {
      "epoch": 1.8516432821100186,
      "grad_norm": 0.27497541904449463,
      "learning_rate": 6.449619882880314e-05,
      "loss": 0.3208,
      "step": 14550
    },
    {
      "epoch": 1.8529159110432376,
      "grad_norm": 0.28691568970680237,
      "learning_rate": 6.437111675927123e-05,
      "loss": 0.3158,
      "step": 14560
    },
    {
      "epoch": 1.8541885399764564,
      "grad_norm": 0.2694578170776367,
      "learning_rate": 6.424609850546173e-05,
      "loss": 0.3348,
      "step": 14570
    },
    {
      "epoch": 1.8554611689096752,
      "grad_norm": 0.3447398543357849,
      "learning_rate": 6.412114429129776e-05,
      "loss": 0.3102,
      "step": 14580
    },
    {
      "epoch": 1.856733797842894,
      "grad_norm": 0.3080105483531952,
      "learning_rate": 6.399625434058771e-05,
      "loss": 0.3292,
      "step": 14590
    },
    {
      "epoch": 1.8580064267761127,
      "grad_norm": 0.2959338128566742,
      "learning_rate": 6.387142887702489e-05,
      "loss": 0.3283,
      "step": 14600
    },
    {
      "epoch": 1.8592790557093315,
      "grad_norm": 0.2926691174507141,
      "learning_rate": 6.374666812418714e-05,
      "loss": 0.3192,
      "step": 14610
    },
    {
      "epoch": 1.8605516846425503,
      "grad_norm": 0.3375013768672943,
      "learning_rate": 6.362197230553623e-05,
      "loss": 0.2927,
      "step": 14620
    },
    {
      "epoch": 1.8618243135757693,
      "grad_norm": 0.3485175371170044,
      "learning_rate": 6.349734164441791e-05,
      "loss": 0.3489,
      "step": 14630
    },
    {
      "epoch": 1.8630969425089878,
      "grad_norm": 0.2834895849227905,
      "learning_rate": 6.337277636406089e-05,
      "loss": 0.3172,
      "step": 14640
    },
    {
      "epoch": 1.8643695714422068,
      "grad_norm": 0.3138692080974579,
      "learning_rate": 6.324827668757704e-05,
      "loss": 0.339,
      "step": 14650
    },
    {
      "epoch": 1.8656422003754254,
      "grad_norm": 0.24631983041763306,
      "learning_rate": 6.312384283796065e-05,
      "loss": 0.3097,
      "step": 14660
    },
    {
      "epoch": 1.8669148293086444,
      "grad_norm": 0.3897445499897003,
      "learning_rate": 6.2999475038088e-05,
      "loss": 0.3259,
      "step": 14670
    },
    {
      "epoch": 1.8681874582418632,
      "grad_norm": 0.27642592787742615,
      "learning_rate": 6.287517351071725e-05,
      "loss": 0.3091,
      "step": 14680
    },
    {
      "epoch": 1.869460087175082,
      "grad_norm": 0.30883991718292236,
      "learning_rate": 6.275093847848768e-05,
      "loss": 0.3265,
      "step": 14690
    },
    {
      "epoch": 1.8707327161083007,
      "grad_norm": 0.29578158259391785,
      "learning_rate": 6.262677016391958e-05,
      "loss": 0.3145,
      "step": 14700
    },
    {
      "epoch": 1.8720053450415195,
      "grad_norm": 0.2451498806476593,
      "learning_rate": 6.250266878941373e-05,
      "loss": 0.3205,
      "step": 14710
    },
    {
      "epoch": 1.8732779739747383,
      "grad_norm": 0.285091370344162,
      "learning_rate": 6.237863457725095e-05,
      "loss": 0.323,
      "step": 14720
    },
    {
      "epoch": 1.874550602907957,
      "grad_norm": 0.3202884793281555,
      "learning_rate": 6.225466774959186e-05,
      "loss": 0.3184,
      "step": 14730
    },
    {
      "epoch": 1.875823231841176,
      "grad_norm": 0.2934403717517853,
      "learning_rate": 6.213076852847625e-05,
      "loss": 0.323,
      "step": 14740
    },
    {
      "epoch": 1.8770958607743946,
      "grad_norm": 0.30759868025779724,
      "learning_rate": 6.200693713582295e-05,
      "loss": 0.3276,
      "step": 14750
    },
    {
      "epoch": 1.8783684897076136,
      "grad_norm": 0.31083524227142334,
      "learning_rate": 6.188317379342929e-05,
      "loss": 0.3099,
      "step": 14760
    },
    {
      "epoch": 1.8796411186408322,
      "grad_norm": 0.2631738483905792,
      "learning_rate": 6.17594787229706e-05,
      "loss": 0.3096,
      "step": 14770
    },
    {
      "epoch": 1.8809137475740512,
      "grad_norm": 0.31330665946006775,
      "learning_rate": 6.163585214600009e-05,
      "loss": 0.3101,
      "step": 14780
    },
    {
      "epoch": 1.88218637650727,
      "grad_norm": 0.3417770564556122,
      "learning_rate": 6.151229428394807e-05,
      "loss": 0.3235,
      "step": 14790
    },
    {
      "epoch": 1.8834590054404887,
      "grad_norm": 0.30980464816093445,
      "learning_rate": 6.138880535812202e-05,
      "loss": 0.3132,
      "step": 14800
    },
    {
      "epoch": 1.8847316343737075,
      "grad_norm": 0.3210594654083252,
      "learning_rate": 6.12653855897058e-05,
      "loss": 0.32,
      "step": 14810
    },
    {
      "epoch": 1.8860042633069263,
      "grad_norm": 0.3028092682361603,
      "learning_rate": 6.114203519975939e-05,
      "loss": 0.3039,
      "step": 14820
    },
    {
      "epoch": 1.887276892240145,
      "grad_norm": 0.3102392256259918,
      "learning_rate": 6.1018754409218605e-05,
      "loss": 0.3221,
      "step": 14830
    },
    {
      "epoch": 1.8885495211733638,
      "grad_norm": 0.22269600629806519,
      "learning_rate": 6.08955434388945e-05,
      "loss": 0.3123,
      "step": 14840
    },
    {
      "epoch": 1.8898221501065828,
      "grad_norm": 0.273395299911499,
      "learning_rate": 6.077240250947311e-05,
      "loss": 0.3222,
      "step": 14850
    },
    {
      "epoch": 1.8910947790398014,
      "grad_norm": 0.2810845971107483,
      "learning_rate": 6.064933184151507e-05,
      "loss": 0.3247,
      "step": 14860
    },
    {
      "epoch": 1.8923674079730204,
      "grad_norm": 0.3032900393009186,
      "learning_rate": 6.052633165545507e-05,
      "loss": 0.3295,
      "step": 14870
    },
    {
      "epoch": 1.893640036906239,
      "grad_norm": 0.2811482548713684,
      "learning_rate": 6.040340217160163e-05,
      "loss": 0.3163,
      "step": 14880
    },
    {
      "epoch": 1.894912665839458,
      "grad_norm": 0.30865007638931274,
      "learning_rate": 6.0280543610136586e-05,
      "loss": 0.3413,
      "step": 14890
    },
    {
      "epoch": 1.8961852947726765,
      "grad_norm": 0.4219021797180176,
      "learning_rate": 6.015775619111479e-05,
      "loss": 0.3064,
      "step": 14900
    },
    {
      "epoch": 1.8974579237058955,
      "grad_norm": 0.2791445851325989,
      "learning_rate": 6.003504013446366e-05,
      "loss": 0.3226,
      "step": 14910
    },
    {
      "epoch": 1.8987305526391143,
      "grad_norm": 0.2949976325035095,
      "learning_rate": 5.991239565998275e-05,
      "loss": 0.3228,
      "step": 14920
    },
    {
      "epoch": 1.900003181572333,
      "grad_norm": 0.39272215962409973,
      "learning_rate": 5.9789822987343455e-05,
      "loss": 0.3155,
      "step": 14930
    },
    {
      "epoch": 1.9012758105055518,
      "grad_norm": 0.346960186958313,
      "learning_rate": 5.9667322336088535e-05,
      "loss": 0.3118,
      "step": 14940
    },
    {
      "epoch": 1.9025484394387706,
      "grad_norm": 0.25176751613616943,
      "learning_rate": 5.954489392563174e-05,
      "loss": 0.3185,
      "step": 14950
    },
    {
      "epoch": 1.9038210683719894,
      "grad_norm": 0.35849082469940186,
      "learning_rate": 5.942253797525753e-05,
      "loss": 0.325,
      "step": 14960
    },
    {
      "epoch": 1.9050936973052082,
      "grad_norm": 0.24975034594535828,
      "learning_rate": 5.9300254704120376e-05,
      "loss": 0.3182,
      "step": 14970
    },
    {
      "epoch": 1.9063663262384272,
      "grad_norm": 0.26968106627464294,
      "learning_rate": 5.9178044331244806e-05,
      "loss": 0.3117,
      "step": 14980
    },
    {
      "epoch": 1.9076389551716457,
      "grad_norm": 0.23915588855743408,
      "learning_rate": 5.9055907075524565e-05,
      "loss": 0.3208,
      "step": 14990
    },
    {
      "epoch": 1.9089115841048647,
      "grad_norm": 0.31243911385536194,
      "learning_rate": 5.893384315572259e-05,
      "loss": 0.3132,
      "step": 15000
    },
    {
      "epoch": 1.9089115841048647,
      "eval_loss": 0.34584781527519226,
      "eval_runtime": 740.6501,
      "eval_samples_per_second": 10.61,
      "eval_steps_per_second": 5.305,
      "step": 15000
    },
    {
      "epoch": 1.9101842130380833,
      "grad_norm": 0.35008925199508667,
      "learning_rate": 5.8811852790470425e-05,
      "loss": 0.2988,
      "step": 15010
    },
    {
      "epoch": 1.9114568419713023,
      "grad_norm": 0.293912410736084,
      "learning_rate": 5.8689936198267815e-05,
      "loss": 0.3312,
      "step": 15020
    },
    {
      "epoch": 1.912729470904521,
      "grad_norm": 0.3750914931297302,
      "learning_rate": 5.856809359748243e-05,
      "loss": 0.3127,
      "step": 15030
    },
    {
      "epoch": 1.9140020998377398,
      "grad_norm": 0.35343632102012634,
      "learning_rate": 5.844632520634938e-05,
      "loss": 0.3237,
      "step": 15040
    },
    {
      "epoch": 1.9152747287709586,
      "grad_norm": 0.3121326267719269,
      "learning_rate": 5.832463124297085e-05,
      "loss": 0.3047,
      "step": 15050
    },
    {
      "epoch": 1.9165473577041774,
      "grad_norm": 0.3007097840309143,
      "learning_rate": 5.820301192531579e-05,
      "loss": 0.3097,
      "step": 15060
    },
    {
      "epoch": 1.9178199866373962,
      "grad_norm": 0.2706410884857178,
      "learning_rate": 5.8081467471219295e-05,
      "loss": 0.3144,
      "step": 15070
    },
    {
      "epoch": 1.919092615570615,
      "grad_norm": 0.24656032025814056,
      "learning_rate": 5.7959998098382574e-05,
      "loss": 0.3066,
      "step": 15080
    },
    {
      "epoch": 1.920365244503834,
      "grad_norm": 0.33778586983680725,
      "learning_rate": 5.78386040243722e-05,
      "loss": 0.32,
      "step": 15090
    },
    {
      "epoch": 1.9216378734370525,
      "grad_norm": 0.2549939453601837,
      "learning_rate": 5.7717285466619876e-05,
      "loss": 0.3072,
      "step": 15100
    },
    {
      "epoch": 1.9229105023702715,
      "grad_norm": 0.28499114513397217,
      "learning_rate": 5.75960426424222e-05,
      "loss": 0.3266,
      "step": 15110
    },
    {
      "epoch": 1.92418313130349,
      "grad_norm": 0.24971874058246613,
      "learning_rate": 5.747487576893995e-05,
      "loss": 0.3058,
      "step": 15120
    },
    {
      "epoch": 1.925455760236709,
      "grad_norm": 0.27459797263145447,
      "learning_rate": 5.7353785063197953e-05,
      "loss": 0.3109,
      "step": 15130
    },
    {
      "epoch": 1.9267283891699276,
      "grad_norm": 0.2995174527168274,
      "learning_rate": 5.723277074208454e-05,
      "loss": 0.2921,
      "step": 15140
    },
    {
      "epoch": 1.9280010181031466,
      "grad_norm": 0.27856874465942383,
      "learning_rate": 5.711183302235137e-05,
      "loss": 0.3223,
      "step": 15150
    },
    {
      "epoch": 1.9292736470363654,
      "grad_norm": 0.2840428650379181,
      "learning_rate": 5.699097212061276e-05,
      "loss": 0.3302,
      "step": 15160
    },
    {
      "epoch": 1.9305462759695842,
      "grad_norm": 0.2847955524921417,
      "learning_rate": 5.6870188253345444e-05,
      "loss": 0.3178,
      "step": 15170
    },
    {
      "epoch": 1.931818904902803,
      "grad_norm": 0.3458790183067322,
      "learning_rate": 5.6749481636888326e-05,
      "loss": 0.3182,
      "step": 15180
    },
    {
      "epoch": 1.9330915338360217,
      "grad_norm": 0.3467586934566498,
      "learning_rate": 5.6628852487441763e-05,
      "loss": 0.3076,
      "step": 15190
    },
    {
      "epoch": 1.9343641627692407,
      "grad_norm": 0.37234199047088623,
      "learning_rate": 5.650830102106741e-05,
      "loss": 0.3013,
      "step": 15200
    },
    {
      "epoch": 1.9356367917024593,
      "grad_norm": 0.2651546895503998,
      "learning_rate": 5.638782745368787e-05,
      "loss": 0.3277,
      "step": 15210
    },
    {
      "epoch": 1.9369094206356783,
      "grad_norm": 0.27993831038475037,
      "learning_rate": 5.626743200108611e-05,
      "loss": 0.3226,
      "step": 15220
    },
    {
      "epoch": 1.9381820495688968,
      "grad_norm": 0.285267174243927,
      "learning_rate": 5.614711487890531e-05,
      "loss": 0.3086,
      "step": 15230
    },
    {
      "epoch": 1.9394546785021158,
      "grad_norm": 0.42546215653419495,
      "learning_rate": 5.602687630264812e-05,
      "loss": 0.3145,
      "step": 15240
    },
    {
      "epoch": 1.9407273074353344,
      "grad_norm": 0.28646281361579895,
      "learning_rate": 5.590671648767676e-05,
      "loss": 0.3064,
      "step": 15250
    },
    {
      "epoch": 1.9419999363685534,
      "grad_norm": 0.22058196365833282,
      "learning_rate": 5.578663564921227e-05,
      "loss": 0.3163,
      "step": 15260
    },
    {
      "epoch": 1.9432725653017722,
      "grad_norm": 0.27764102816581726,
      "learning_rate": 5.5666634002334226e-05,
      "loss": 0.3194,
      "step": 15270
    },
    {
      "epoch": 1.944545194234991,
      "grad_norm": 0.2974869906902313,
      "learning_rate": 5.554671176198036e-05,
      "loss": 0.3143,
      "step": 15280
    },
    {
      "epoch": 1.9458178231682097,
      "grad_norm": 0.45157676935195923,
      "learning_rate": 5.542686914294617e-05,
      "loss": 0.3193,
      "step": 15290
    },
    {
      "epoch": 1.9470904521014285,
      "grad_norm": 0.3941275179386139,
      "learning_rate": 5.530710635988461e-05,
      "loss": 0.338,
      "step": 15300
    },
    {
      "epoch": 1.9483630810346473,
      "grad_norm": 0.28186124563217163,
      "learning_rate": 5.518742362730557e-05,
      "loss": 0.3067,
      "step": 15310
    },
    {
      "epoch": 1.949635709967866,
      "grad_norm": 0.31569600105285645,
      "learning_rate": 5.506782115957553e-05,
      "loss": 0.3168,
      "step": 15320
    },
    {
      "epoch": 1.950908338901085,
      "grad_norm": 0.2815660238265991,
      "learning_rate": 5.4948299170917325e-05,
      "loss": 0.3144,
      "step": 15330
    },
    {
      "epoch": 1.9521809678343036,
      "grad_norm": 0.30332261323928833,
      "learning_rate": 5.482885787540957e-05,
      "loss": 0.3149,
      "step": 15340
    },
    {
      "epoch": 1.9534535967675226,
      "grad_norm": 0.22984595596790314,
      "learning_rate": 5.470949748698627e-05,
      "loss": 0.308,
      "step": 15350
    },
    {
      "epoch": 1.9547262257007412,
      "grad_norm": 0.2785532474517822,
      "learning_rate": 5.4590218219436706e-05,
      "loss": 0.3206,
      "step": 15360
    },
    {
      "epoch": 1.9559988546339602,
      "grad_norm": 0.33323919773101807,
      "learning_rate": 5.447102028640465e-05,
      "loss": 0.3196,
      "step": 15370
    },
    {
      "epoch": 1.957271483567179,
      "grad_norm": 0.24250172078609467,
      "learning_rate": 5.435190390138841e-05,
      "loss": 0.3105,
      "step": 15380
    },
    {
      "epoch": 1.9585441125003977,
      "grad_norm": 0.3276868760585785,
      "learning_rate": 5.4232869277739985e-05,
      "loss": 0.3334,
      "step": 15390
    },
    {
      "epoch": 1.9598167414336165,
      "grad_norm": 0.2836942970752716,
      "learning_rate": 5.411391662866513e-05,
      "loss": 0.2923,
      "step": 15400
    },
    {
      "epoch": 1.9610893703668353,
      "grad_norm": 0.2958522140979767,
      "learning_rate": 5.399504616722273e-05,
      "loss": 0.3392,
      "step": 15410
    },
    {
      "epoch": 1.962361999300054,
      "grad_norm": 0.3337842524051666,
      "learning_rate": 5.387625810632442e-05,
      "loss": 0.3342,
      "step": 15420
    },
    {
      "epoch": 1.9636346282332728,
      "grad_norm": 0.2898337244987488,
      "learning_rate": 5.3757552658734234e-05,
      "loss": 0.3215,
      "step": 15430
    },
    {
      "epoch": 1.9649072571664918,
      "grad_norm": 0.3596876263618469,
      "learning_rate": 5.363893003706826e-05,
      "loss": 0.3123,
      "step": 15440
    },
    {
      "epoch": 1.9661798860997104,
      "grad_norm": 0.2591642439365387,
      "learning_rate": 5.352039045379428e-05,
      "loss": 0.3316,
      "step": 15450
    },
    {
      "epoch": 1.9674525150329294,
      "grad_norm": 0.34910911321640015,
      "learning_rate": 5.340193412123128e-05,
      "loss": 0.325,
      "step": 15460
    },
    {
      "epoch": 1.968725143966148,
      "grad_norm": 0.26616835594177246,
      "learning_rate": 5.328356125154912e-05,
      "loss": 0.3326,
      "step": 15470
    },
    {
      "epoch": 1.969997772899367,
      "grad_norm": 0.2797244191169739,
      "learning_rate": 5.3165272056768264e-05,
      "loss": 0.3236,
      "step": 15480
    },
    {
      "epoch": 1.9712704018325855,
      "grad_norm": 0.329014390707016,
      "learning_rate": 5.304706674875923e-05,
      "loss": 0.3123,
      "step": 15490
    },
    {
      "epoch": 1.9725430307658045,
      "grad_norm": 0.24866631627082825,
      "learning_rate": 5.292894553924226e-05,
      "loss": 0.3111,
      "step": 15500
    },
    {
      "epoch": 1.9725430307658045,
      "eval_loss": 0.3443021774291992,
      "eval_runtime": 740.8635,
      "eval_samples_per_second": 10.607,
      "eval_steps_per_second": 5.303,
      "step": 15500
    },
    {
      "epoch": 1.9738156596990233,
      "grad_norm": 0.4120728075504303,
      "learning_rate": 5.281090863978704e-05,
      "loss": 0.3047,
      "step": 15510
    },
    {
      "epoch": 1.975088288632242,
      "grad_norm": 0.27388104796409607,
      "learning_rate": 5.269295626181216e-05,
      "loss": 0.3077,
      "step": 15520
    },
    {
      "epoch": 1.9763609175654608,
      "grad_norm": 0.2830871045589447,
      "learning_rate": 5.2575088616585e-05,
      "loss": 0.3305,
      "step": 15530
    },
    {
      "epoch": 1.9776335464986796,
      "grad_norm": 0.3351905643939972,
      "learning_rate": 5.2457305915220865e-05,
      "loss": 0.321,
      "step": 15540
    },
    {
      "epoch": 1.9789061754318984,
      "grad_norm": 0.3284716010093689,
      "learning_rate": 5.233960836868319e-05,
      "loss": 0.3153,
      "step": 15550
    },
    {
      "epoch": 1.9801788043651172,
      "grad_norm": 0.3076052963733673,
      "learning_rate": 5.2221996187782805e-05,
      "loss": 0.314,
      "step": 15560
    },
    {
      "epoch": 1.9814514332983362,
      "grad_norm": 0.33008939027786255,
      "learning_rate": 5.210446958317763e-05,
      "loss": 0.3018,
      "step": 15570
    },
    {
      "epoch": 1.9827240622315547,
      "grad_norm": 0.34052497148513794,
      "learning_rate": 5.198702876537225e-05,
      "loss": 0.3387,
      "step": 15580
    },
    {
      "epoch": 1.9839966911647737,
      "grad_norm": 0.2971736490726471,
      "learning_rate": 5.186967394471765e-05,
      "loss": 0.3412,
      "step": 15590
    },
    {
      "epoch": 1.9852693200979923,
      "grad_norm": 0.37411198019981384,
      "learning_rate": 5.175240533141084e-05,
      "loss": 0.3307,
      "step": 15600
    },
    {
      "epoch": 1.9865419490312113,
      "grad_norm": 0.26161837577819824,
      "learning_rate": 5.1635223135494324e-05,
      "loss": 0.3073,
      "step": 15610
    },
    {
      "epoch": 1.98781457796443,
      "grad_norm": 0.26940324902534485,
      "learning_rate": 5.151812756685583e-05,
      "loss": 0.3155,
      "step": 15620
    },
    {
      "epoch": 1.9890872068976488,
      "grad_norm": 0.3148728609085083,
      "learning_rate": 5.1401118835228046e-05,
      "loss": 0.331,
      "step": 15630
    },
    {
      "epoch": 1.9903598358308676,
      "grad_norm": 0.30637356638908386,
      "learning_rate": 5.1284197150187986e-05,
      "loss": 0.3265,
      "step": 15640
    },
    {
      "epoch": 1.9916324647640864,
      "grad_norm": 0.3351247012615204,
      "learning_rate": 5.116736272115677e-05,
      "loss": 0.3443,
      "step": 15650
    },
    {
      "epoch": 1.9929050936973052,
      "grad_norm": 0.20182456076145172,
      "learning_rate": 5.1050615757399314e-05,
      "loss": 0.302,
      "step": 15660
    },
    {
      "epoch": 1.994177722630524,
      "grad_norm": 0.3010644018650055,
      "learning_rate": 5.093395646802382e-05,
      "loss": 0.3361,
      "step": 15670
    },
    {
      "epoch": 1.995450351563743,
      "grad_norm": 0.25151821970939636,
      "learning_rate": 5.081738506198144e-05,
      "loss": 0.303,
      "step": 15680
    },
    {
      "epoch": 1.9967229804969615,
      "grad_norm": 0.2969066798686981,
      "learning_rate": 5.07009017480659e-05,
      "loss": 0.3214,
      "step": 15690
    },
    {
      "epoch": 1.9979956094301805,
      "grad_norm": 0.25564345717430115,
      "learning_rate": 5.0584506734913215e-05,
      "loss": 0.2972,
      "step": 15700
    },
    {
      "epoch": 1.999268238363399,
      "grad_norm": 0.29324913024902344,
      "learning_rate": 5.0468200231001286e-05,
      "loss": 0.314,
      "step": 15710
    },
    {
      "epoch": 2.0005090515732875,
      "grad_norm": 0.295035719871521,
      "learning_rate": 5.0351982444649226e-05,
      "loss": 0.3094,
      "step": 15720
    },
    {
      "epoch": 2.0017816805065065,
      "grad_norm": 0.26326602697372437,
      "learning_rate": 5.0235853584017565e-05,
      "loss": 0.3018,
      "step": 15730
    },
    {
      "epoch": 2.003054309439725,
      "grad_norm": 0.32647940516471863,
      "learning_rate": 5.01198138571073e-05,
      "loss": 0.3031,
      "step": 15740
    },
    {
      "epoch": 2.004326938372944,
      "grad_norm": 0.335603803396225,
      "learning_rate": 5.0003863471759983e-05,
      "loss": 0.2898,
      "step": 15750
    },
    {
      "epoch": 2.0055995673061626,
      "grad_norm": 0.3695593774318695,
      "learning_rate": 4.988800263565701e-05,
      "loss": 0.3185,
      "step": 15760
    },
    {
      "epoch": 2.0068721962393816,
      "grad_norm": 0.26556798815727234,
      "learning_rate": 4.9772231556319384e-05,
      "loss": 0.3027,
      "step": 15770
    },
    {
      "epoch": 2.0081448251726,
      "grad_norm": 0.5717970132827759,
      "learning_rate": 4.965655044110746e-05,
      "loss": 0.3286,
      "step": 15780
    },
    {
      "epoch": 2.009417454105819,
      "grad_norm": 0.26772820949554443,
      "learning_rate": 4.954095949722033e-05,
      "loss": 0.3097,
      "step": 15790
    },
    {
      "epoch": 2.0106900830390377,
      "grad_norm": 0.3060186505317688,
      "learning_rate": 4.942545893169559e-05,
      "loss": 0.2973,
      "step": 15800
    },
    {
      "epoch": 2.0119627119722567,
      "grad_norm": 0.28490719199180603,
      "learning_rate": 4.931004895140907e-05,
      "loss": 0.2954,
      "step": 15810
    },
    {
      "epoch": 2.0132353409054753,
      "grad_norm": 0.316278338432312,
      "learning_rate": 4.919472976307423e-05,
      "loss": 0.277,
      "step": 15820
    },
    {
      "epoch": 2.0145079698386943,
      "grad_norm": 0.29679301381111145,
      "learning_rate": 4.907950157324197e-05,
      "loss": 0.2867,
      "step": 15830
    },
    {
      "epoch": 2.0157805987719133,
      "grad_norm": 0.34829264879226685,
      "learning_rate": 4.896436458830014e-05,
      "loss": 0.2873,
      "step": 15840
    },
    {
      "epoch": 2.017053227705132,
      "grad_norm": 0.3493528962135315,
      "learning_rate": 4.884931901447329e-05,
      "loss": 0.2902,
      "step": 15850
    },
    {
      "epoch": 2.018325856638351,
      "grad_norm": 0.3004542589187622,
      "learning_rate": 4.873436505782233e-05,
      "loss": 0.3155,
      "step": 15860
    },
    {
      "epoch": 2.0195984855715694,
      "grad_norm": 0.3607960641384125,
      "learning_rate": 4.861950292424381e-05,
      "loss": 0.2993,
      "step": 15870
    },
    {
      "epoch": 2.0208711145047884,
      "grad_norm": 0.4180656373500824,
      "learning_rate": 4.850473281947008e-05,
      "loss": 0.2888,
      "step": 15880
    },
    {
      "epoch": 2.022143743438007,
      "grad_norm": 0.28051987290382385,
      "learning_rate": 4.8390054949068464e-05,
      "loss": 0.291,
      "step": 15890
    },
    {
      "epoch": 2.023416372371226,
      "grad_norm": 0.27659550309181213,
      "learning_rate": 4.8275469518441265e-05,
      "loss": 0.2988,
      "step": 15900
    },
    {
      "epoch": 2.0246890013044445,
      "grad_norm": 0.37705451250076294,
      "learning_rate": 4.816097673282506e-05,
      "loss": 0.3006,
      "step": 15910
    },
    {
      "epoch": 2.0259616302376635,
      "grad_norm": 0.2906440794467926,
      "learning_rate": 4.804657679729051e-05,
      "loss": 0.3046,
      "step": 15920
    },
    {
      "epoch": 2.027234259170882,
      "grad_norm": 0.31409263610839844,
      "learning_rate": 4.7932269916742075e-05,
      "loss": 0.299,
      "step": 15930
    },
    {
      "epoch": 2.028506888104101,
      "grad_norm": 0.30638328194618225,
      "learning_rate": 4.781805629591745e-05,
      "loss": 0.303,
      "step": 15940
    },
    {
      "epoch": 2.0297795170373196,
      "grad_norm": 0.4205401837825775,
      "learning_rate": 4.770393613938725e-05,
      "loss": 0.3118,
      "step": 15950
    },
    {
      "epoch": 2.0310521459705386,
      "grad_norm": 0.3351760804653168,
      "learning_rate": 4.7589909651554834e-05,
      "loss": 0.315,
      "step": 15960
    },
    {
      "epoch": 2.0323247749037576,
      "grad_norm": 0.4776533544063568,
      "learning_rate": 4.747597703665565e-05,
      "loss": 0.2811,
      "step": 15970
    },
    {
      "epoch": 2.033597403836976,
      "grad_norm": 0.36903610825538635,
      "learning_rate": 4.736213849875708e-05,
      "loss": 0.298,
      "step": 15980
    },
    {
      "epoch": 2.034870032770195,
      "grad_norm": 0.30834293365478516,
      "learning_rate": 4.724839424175792e-05,
      "loss": 0.3107,
      "step": 15990
    },
    {
      "epoch": 2.0361426617034137,
      "grad_norm": 0.3468208312988281,
      "learning_rate": 4.7134744469388236e-05,
      "loss": 0.3075,
      "step": 16000
    },
    {
      "epoch": 2.0361426617034137,
      "eval_loss": 0.3464380204677582,
      "eval_runtime": 738.6242,
      "eval_samples_per_second": 10.639,
      "eval_steps_per_second": 5.319,
      "step": 16000
    },
    {
      "epoch": 2.0374152906366327,
      "grad_norm": 0.34514838457107544,
      "learning_rate": 4.7021189385208764e-05,
      "loss": 0.315,
      "step": 16010
    },
    {
      "epoch": 2.0386879195698513,
      "grad_norm": 0.30165237188339233,
      "learning_rate": 4.6907729192610594e-05,
      "loss": 0.2963,
      "step": 16020
    },
    {
      "epoch": 2.0399605485030703,
      "grad_norm": 0.310065358877182,
      "learning_rate": 4.6794364094815013e-05,
      "loss": 0.3083,
      "step": 16030
    },
    {
      "epoch": 2.041233177436289,
      "grad_norm": 0.326781690120697,
      "learning_rate": 4.668109429487284e-05,
      "loss": 0.291,
      "step": 16040
    },
    {
      "epoch": 2.042505806369508,
      "grad_norm": 0.3581312596797943,
      "learning_rate": 4.656791999566422e-05,
      "loss": 0.3097,
      "step": 16050
    },
    {
      "epoch": 2.0437784353027264,
      "grad_norm": 0.2673890292644501,
      "learning_rate": 4.645484139989835e-05,
      "loss": 0.3053,
      "step": 16060
    },
    {
      "epoch": 2.0450510642359454,
      "grad_norm": 0.31745263934135437,
      "learning_rate": 4.634185871011286e-05,
      "loss": 0.2928,
      "step": 16070
    },
    {
      "epoch": 2.0463236931691644,
      "grad_norm": 0.2893970310688019,
      "learning_rate": 4.6228972128673796e-05,
      "loss": 0.2898,
      "step": 16080
    },
    {
      "epoch": 2.047596322102383,
      "grad_norm": 0.36399129033088684,
      "learning_rate": 4.6116181857774774e-05,
      "loss": 0.3154,
      "step": 16090
    },
    {
      "epoch": 2.048868951035602,
      "grad_norm": 0.2983141839504242,
      "learning_rate": 4.600348809943716e-05,
      "loss": 0.3214,
      "step": 16100
    },
    {
      "epoch": 2.0501415799688205,
      "grad_norm": 0.2905992567539215,
      "learning_rate": 4.589089105550942e-05,
      "loss": 0.3069,
      "step": 16110
    },
    {
      "epoch": 2.0514142089020395,
      "grad_norm": 0.30509719252586365,
      "learning_rate": 4.5778390927666684e-05,
      "loss": 0.3043,
      "step": 16120
    },
    {
      "epoch": 2.052686837835258,
      "grad_norm": 0.3444196879863739,
      "learning_rate": 4.566598791741056e-05,
      "loss": 0.2975,
      "step": 16130
    },
    {
      "epoch": 2.053959466768477,
      "grad_norm": 0.3427126705646515,
      "learning_rate": 4.555368222606865e-05,
      "loss": 0.2979,
      "step": 16140
    },
    {
      "epoch": 2.0552320957016956,
      "grad_norm": 0.3838360607624054,
      "learning_rate": 4.5441474054794376e-05,
      "loss": 0.286,
      "step": 16150
    },
    {
      "epoch": 2.0565047246349146,
      "grad_norm": 0.28090083599090576,
      "learning_rate": 4.532936360456636e-05,
      "loss": 0.3081,
      "step": 16160
    },
    {
      "epoch": 2.057777353568133,
      "grad_norm": 0.33318787813186646,
      "learning_rate": 4.521735107618823e-05,
      "loss": 0.2877,
      "step": 16170
    },
    {
      "epoch": 2.059049982501352,
      "grad_norm": 0.24883806705474854,
      "learning_rate": 4.510543667028828e-05,
      "loss": 0.2922,
      "step": 16180
    },
    {
      "epoch": 2.060322611434571,
      "grad_norm": 0.32666015625,
      "learning_rate": 4.499362058731899e-05,
      "loss": 0.3023,
      "step": 16190
    },
    {
      "epoch": 2.0615952403677897,
      "grad_norm": 0.31310439109802246,
      "learning_rate": 4.488190302755668e-05,
      "loss": 0.3044,
      "step": 16200
    },
    {
      "epoch": 2.0628678693010087,
      "grad_norm": 0.3182072639465332,
      "learning_rate": 4.47702841911014e-05,
      "loss": 0.2971,
      "step": 16210
    },
    {
      "epoch": 2.0641404982342273,
      "grad_norm": 0.37151092290878296,
      "learning_rate": 4.465876427787612e-05,
      "loss": 0.2956,
      "step": 16220
    },
    {
      "epoch": 2.0654131271674463,
      "grad_norm": 0.31777113676071167,
      "learning_rate": 4.454734348762689e-05,
      "loss": 0.3079,
      "step": 16230
    },
    {
      "epoch": 2.066685756100665,
      "grad_norm": 0.3564566969871521,
      "learning_rate": 4.4436022019921943e-05,
      "loss": 0.294,
      "step": 16240
    },
    {
      "epoch": 2.067958385033884,
      "grad_norm": 0.34450921416282654,
      "learning_rate": 4.4324800074151805e-05,
      "loss": 0.3087,
      "step": 16250
    },
    {
      "epoch": 2.0692310139671024,
      "grad_norm": 0.3223913013935089,
      "learning_rate": 4.4213677849528744e-05,
      "loss": 0.3056,
      "step": 16260
    },
    {
      "epoch": 2.0705036429003214,
      "grad_norm": 0.35076063871383667,
      "learning_rate": 4.4102655545086326e-05,
      "loss": 0.2972,
      "step": 16270
    },
    {
      "epoch": 2.07177627183354,
      "grad_norm": 0.317145973443985,
      "learning_rate": 4.399173335967914e-05,
      "loss": 0.2966,
      "step": 16280
    },
    {
      "epoch": 2.073048900766759,
      "grad_norm": 0.2834616005420685,
      "learning_rate": 4.388091149198258e-05,
      "loss": 0.299,
      "step": 16290
    },
    {
      "epoch": 2.0743215296999775,
      "grad_norm": 0.2757419943809509,
      "learning_rate": 4.377019014049223e-05,
      "loss": 0.286,
      "step": 16300
    },
    {
      "epoch": 2.0755941586331965,
      "grad_norm": 0.3095635175704956,
      "learning_rate": 4.3659569503523675e-05,
      "loss": 0.3076,
      "step": 16310
    },
    {
      "epoch": 2.0768667875664155,
      "grad_norm": 0.28173068165779114,
      "learning_rate": 4.354904977921209e-05,
      "loss": 0.3081,
      "step": 16320
    },
    {
      "epoch": 2.078139416499634,
      "grad_norm": 0.3364529609680176,
      "learning_rate": 4.343863116551196e-05,
      "loss": 0.2985,
      "step": 16330
    },
    {
      "epoch": 2.079412045432853,
      "grad_norm": 0.23656432330608368,
      "learning_rate": 4.33283138601967e-05,
      "loss": 0.3249,
      "step": 16340
    },
    {
      "epoch": 2.0806846743660716,
      "grad_norm": 0.28301453590393066,
      "learning_rate": 4.321809806085807e-05,
      "loss": 0.293,
      "step": 16350
    },
    {
      "epoch": 2.0819573032992906,
      "grad_norm": 0.3622712194919586,
      "learning_rate": 4.310798396490625e-05,
      "loss": 0.288,
      "step": 16360
    },
    {
      "epoch": 2.083229932232509,
      "grad_norm": 0.3310622572898865,
      "learning_rate": 4.299797176956911e-05,
      "loss": 0.3026,
      "step": 16370
    },
    {
      "epoch": 2.084502561165728,
      "grad_norm": 0.3452334702014923,
      "learning_rate": 4.288806167189211e-05,
      "loss": 0.287,
      "step": 16380
    },
    {
      "epoch": 2.0857751900989467,
      "grad_norm": 0.2943424582481384,
      "learning_rate": 4.277825386873775e-05,
      "loss": 0.2912,
      "step": 16390
    },
    {
      "epoch": 2.0870478190321657,
      "grad_norm": 0.3509853184223175,
      "learning_rate": 4.2668548556785315e-05,
      "loss": 0.3204,
      "step": 16400
    },
    {
      "epoch": 2.0883204479653843,
      "grad_norm": 0.3489258885383606,
      "learning_rate": 4.25589459325306e-05,
      "loss": 0.312,
      "step": 16410
    },
    {
      "epoch": 2.0895930768986033,
      "grad_norm": 0.3283692002296448,
      "learning_rate": 4.2449446192285417e-05,
      "loss": 0.3116,
      "step": 16420
    },
    {
      "epoch": 2.0908657058318223,
      "grad_norm": 0.27597102522850037,
      "learning_rate": 4.234004953217722e-05,
      "loss": 0.2929,
      "step": 16430
    },
    {
      "epoch": 2.092138334765041,
      "grad_norm": 0.34242597222328186,
      "learning_rate": 4.223075614814902e-05,
      "loss": 0.3133,
      "step": 16440
    },
    {
      "epoch": 2.09341096369826,
      "grad_norm": 0.3136730194091797,
      "learning_rate": 4.212156623595869e-05,
      "loss": 0.3135,
      "step": 16450
    },
    {
      "epoch": 2.0946835926314784,
      "grad_norm": 0.3902595639228821,
      "learning_rate": 4.201247999117882e-05,
      "loss": 0.2888,
      "step": 16460
    },
    {
      "epoch": 2.0959562215646974,
      "grad_norm": 0.33018749952316284,
      "learning_rate": 4.1903497609196295e-05,
      "loss": 0.3003,
      "step": 16470
    },
    {
      "epoch": 2.097228850497916,
      "grad_norm": 0.31273677945137024,
      "learning_rate": 4.179461928521208e-05,
      "loss": 0.2931,
      "step": 16480
    },
    {
      "epoch": 2.098501479431135,
      "grad_norm": 0.39758041501045227,
      "learning_rate": 4.1685845214240616e-05,
      "loss": 0.2988,
      "step": 16490
    },
    {
      "epoch": 2.0997741083643535,
      "grad_norm": 0.3384193480014801,
      "learning_rate": 4.1577175591109664e-05,
      "loss": 0.2985,
      "step": 16500
    },
    {
      "epoch": 2.0997741083643535,
      "eval_loss": 0.34505495429039,
      "eval_runtime": 740.0047,
      "eval_samples_per_second": 10.619,
      "eval_steps_per_second": 5.309,
      "step": 16500
    },
    {
      "epoch": 2.1010467372975725,
      "grad_norm": 0.29362019896507263,
      "learning_rate": 4.146861061045997e-05,
      "loss": 0.2939,
      "step": 16510
    },
    {
      "epoch": 2.102319366230791,
      "grad_norm": 0.2623547315597534,
      "learning_rate": 4.136015046674476e-05,
      "loss": 0.3057,
      "step": 16520
    },
    {
      "epoch": 2.10359199516401,
      "grad_norm": 0.343851238489151,
      "learning_rate": 4.1251795354229514e-05,
      "loss": 0.2888,
      "step": 16530
    },
    {
      "epoch": 2.104864624097229,
      "grad_norm": 0.343606561422348,
      "learning_rate": 4.114354546699164e-05,
      "loss": 0.2896,
      "step": 16540
    },
    {
      "epoch": 2.1061372530304476,
      "grad_norm": 0.28998979926109314,
      "learning_rate": 4.103540099891997e-05,
      "loss": 0.2931,
      "step": 16550
    },
    {
      "epoch": 2.1074098819636666,
      "grad_norm": 0.29549816250801086,
      "learning_rate": 4.09273621437147e-05,
      "loss": 0.3071,
      "step": 16560
    },
    {
      "epoch": 2.108682510896885,
      "grad_norm": 0.35723933577537537,
      "learning_rate": 4.081942909488657e-05,
      "loss": 0.3176,
      "step": 16570
    },
    {
      "epoch": 2.109955139830104,
      "grad_norm": 0.2834007143974304,
      "learning_rate": 4.071160204575707e-05,
      "loss": 0.2982,
      "step": 16580
    },
    {
      "epoch": 2.1112277687633227,
      "grad_norm": 0.3221503794193268,
      "learning_rate": 4.060388118945776e-05,
      "loss": 0.2882,
      "step": 16590
    },
    {
      "epoch": 2.1125003976965417,
      "grad_norm": 0.3014307916164398,
      "learning_rate": 4.0496266718929955e-05,
      "loss": 0.2901,
      "step": 16600
    },
    {
      "epoch": 2.1137730266297603,
      "grad_norm": 0.28091493248939514,
      "learning_rate": 4.038875882692442e-05,
      "loss": 0.2839,
      "step": 16610
    },
    {
      "epoch": 2.1150456555629793,
      "grad_norm": 0.2857804298400879,
      "learning_rate": 4.028135770600102e-05,
      "loss": 0.2865,
      "step": 16620
    },
    {
      "epoch": 2.116318284496198,
      "grad_norm": 0.27045926451683044,
      "learning_rate": 4.017406354852847e-05,
      "loss": 0.2909,
      "step": 16630
    },
    {
      "epoch": 2.117590913429417,
      "grad_norm": 0.3268454074859619,
      "learning_rate": 4.006687654668381e-05,
      "loss": 0.2963,
      "step": 16640
    },
    {
      "epoch": 2.1188635423626354,
      "grad_norm": 0.2633812427520752,
      "learning_rate": 3.995979689245212e-05,
      "loss": 0.3106,
      "step": 16650
    },
    {
      "epoch": 2.1201361712958544,
      "grad_norm": 0.3673838973045349,
      "learning_rate": 3.985282477762634e-05,
      "loss": 0.3023,
      "step": 16660
    },
    {
      "epoch": 2.1214088002290734,
      "grad_norm": 0.33507367968559265,
      "learning_rate": 3.974596039380669e-05,
      "loss": 0.2873,
      "step": 16670
    },
    {
      "epoch": 2.122681429162292,
      "grad_norm": 0.3388611972332001,
      "learning_rate": 3.963920393240042e-05,
      "loss": 0.3089,
      "step": 16680
    },
    {
      "epoch": 2.123954058095511,
      "grad_norm": 0.48872947692871094,
      "learning_rate": 3.953255558462157e-05,
      "loss": 0.2823,
      "step": 16690
    },
    {
      "epoch": 2.1252266870287295,
      "grad_norm": 0.43055298924446106,
      "learning_rate": 3.9426015541490415e-05,
      "loss": 0.3039,
      "step": 16700
    },
    {
      "epoch": 2.1264993159619485,
      "grad_norm": 0.36315760016441345,
      "learning_rate": 3.931958399383342e-05,
      "loss": 0.3138,
      "step": 16710
    },
    {
      "epoch": 2.127771944895167,
      "grad_norm": 0.3377402126789093,
      "learning_rate": 3.921326113228246e-05,
      "loss": 0.2801,
      "step": 16720
    },
    {
      "epoch": 2.129044573828386,
      "grad_norm": 0.3350951373577118,
      "learning_rate": 3.9107047147274966e-05,
      "loss": 0.2978,
      "step": 16730
    },
    {
      "epoch": 2.1303172027616046,
      "grad_norm": 0.44692227244377136,
      "learning_rate": 3.9000942229053304e-05,
      "loss": 0.301,
      "step": 16740
    },
    {
      "epoch": 2.1315898316948236,
      "grad_norm": 0.44404512643814087,
      "learning_rate": 3.889494656766445e-05,
      "loss": 0.3035,
      "step": 16750
    },
    {
      "epoch": 2.132862460628042,
      "grad_norm": 0.29646188020706177,
      "learning_rate": 3.8789060352959674e-05,
      "loss": 0.2895,
      "step": 16760
    },
    {
      "epoch": 2.134135089561261,
      "grad_norm": 0.35406559705734253,
      "learning_rate": 3.868328377459421e-05,
      "loss": 0.2874,
      "step": 16770
    },
    {
      "epoch": 2.1354077184944797,
      "grad_norm": 0.31286728382110596,
      "learning_rate": 3.8577617022027046e-05,
      "loss": 0.3003,
      "step": 16780
    },
    {
      "epoch": 2.1366803474276987,
      "grad_norm": 0.3881225883960724,
      "learning_rate": 3.8472060284520296e-05,
      "loss": 0.3097,
      "step": 16790
    },
    {
      "epoch": 2.1379529763609177,
      "grad_norm": 0.3354596793651581,
      "learning_rate": 3.836661375113908e-05,
      "loss": 0.318,
      "step": 16800
    },
    {
      "epoch": 2.1392256052941363,
      "grad_norm": 0.3841726779937744,
      "learning_rate": 3.826127761075119e-05,
      "loss": 0.3214,
      "step": 16810
    },
    {
      "epoch": 2.1404982342273553,
      "grad_norm": 0.29478493332862854,
      "learning_rate": 3.815605205202663e-05,
      "loss": 0.3082,
      "step": 16820
    },
    {
      "epoch": 2.141770863160574,
      "grad_norm": 0.2705240249633789,
      "learning_rate": 3.805093726343728e-05,
      "loss": 0.3034,
      "step": 16830
    },
    {
      "epoch": 2.143043492093793,
      "grad_norm": 0.3739599287509918,
      "learning_rate": 3.7945933433256786e-05,
      "loss": 0.3053,
      "step": 16840
    },
    {
      "epoch": 2.1443161210270114,
      "grad_norm": 0.3422391414642334,
      "learning_rate": 3.7841040749559894e-05,
      "loss": 0.3043,
      "step": 16850
    },
    {
      "epoch": 2.1455887499602304,
      "grad_norm": 0.3216989040374756,
      "learning_rate": 3.7736259400222364e-05,
      "loss": 0.3116,
      "step": 16860
    },
    {
      "epoch": 2.146861378893449,
      "grad_norm": 0.36769506335258484,
      "learning_rate": 3.7631589572920445e-05,
      "loss": 0.2931,
      "step": 16870
    },
    {
      "epoch": 2.148134007826668,
      "grad_norm": 0.3096393644809723,
      "learning_rate": 3.7527031455130745e-05,
      "loss": 0.305,
      "step": 16880
    },
    {
      "epoch": 2.1494066367598865,
      "grad_norm": 0.32884499430656433,
      "learning_rate": 3.7422585234129816e-05,
      "loss": 0.2986,
      "step": 16890
    },
    {
      "epoch": 2.1506792656931055,
      "grad_norm": 0.35051217675209045,
      "learning_rate": 3.7318251096993584e-05,
      "loss": 0.3099,
      "step": 16900
    },
    {
      "epoch": 2.1519518946263245,
      "grad_norm": 0.39722731709480286,
      "learning_rate": 3.721402923059745e-05,
      "loss": 0.3007,
      "step": 16910
    },
    {
      "epoch": 2.153224523559543,
      "grad_norm": 0.3963108956813812,
      "learning_rate": 3.710991982161555e-05,
      "loss": 0.2976,
      "step": 16920
    },
    {
      "epoch": 2.154497152492762,
      "grad_norm": 0.3944529592990875,
      "learning_rate": 3.700592305652074e-05,
      "loss": 0.2986,
      "step": 16930
    },
    {
      "epoch": 2.1557697814259806,
      "grad_norm": 0.3259184658527374,
      "learning_rate": 3.690203912158403e-05,
      "loss": 0.2933,
      "step": 16940
    },
    {
      "epoch": 2.1570424103591996,
      "grad_norm": 0.33486250042915344,
      "learning_rate": 3.67982682028743e-05,
      "loss": 0.2993,
      "step": 16950
    },
    {
      "epoch": 2.158315039292418,
      "grad_norm": 0.3822545111179352,
      "learning_rate": 3.669461048625814e-05,
      "loss": 0.3079,
      "step": 16960
    },
    {
      "epoch": 2.159587668225637,
      "grad_norm": 0.3541099429130554,
      "learning_rate": 3.659106615739927e-05,
      "loss": 0.2918,
      "step": 16970
    },
    {
      "epoch": 2.1608602971588557,
      "grad_norm": 0.29265424609184265,
      "learning_rate": 3.64876354017583e-05,
      "loss": 0.3015,
      "step": 16980
    },
    {
      "epoch": 2.1621329260920747,
      "grad_norm": 0.2523247003555298,
      "learning_rate": 3.638431840459253e-05,
      "loss": 0.2912,
      "step": 16990
    },
    {
      "epoch": 2.1634055550252933,
      "grad_norm": 0.2764325737953186,
      "learning_rate": 3.628111535095543e-05,
      "loss": 0.2791,
      "step": 17000
    },
    {
      "epoch": 2.1634055550252933,
      "eval_loss": 0.3445364236831665,
      "eval_runtime": 740.0584,
      "eval_samples_per_second": 10.618,
      "eval_steps_per_second": 5.309,
      "step": 17000
    },
    {
      "epoch": 2.1646781839585123,
      "grad_norm": 0.2706364095211029,
      "learning_rate": 3.617802642569637e-05,
      "loss": 0.2995,
      "step": 17010
    },
    {
      "epoch": 2.1659508128917313,
      "grad_norm": 0.33319953083992004,
      "learning_rate": 3.607505181346032e-05,
      "loss": 0.3002,
      "step": 17020
    },
    {
      "epoch": 2.16722344182495,
      "grad_norm": 0.2617270052433014,
      "learning_rate": 3.5972191698687496e-05,
      "loss": 0.2998,
      "step": 17030
    },
    {
      "epoch": 2.168496070758169,
      "grad_norm": 0.34603753685951233,
      "learning_rate": 3.586944626561314e-05,
      "loss": 0.3037,
      "step": 17040
    },
    {
      "epoch": 2.1697686996913874,
      "grad_norm": 0.2831517457962036,
      "learning_rate": 3.576681569826684e-05,
      "loss": 0.3041,
      "step": 17050
    },
    {
      "epoch": 2.1710413286246064,
      "grad_norm": 0.35430318117141724,
      "learning_rate": 3.566430018047272e-05,
      "loss": 0.2868,
      "step": 17060
    },
    {
      "epoch": 2.172313957557825,
      "grad_norm": 0.31369683146476746,
      "learning_rate": 3.556189989584863e-05,
      "loss": 0.291,
      "step": 17070
    },
    {
      "epoch": 2.173586586491044,
      "grad_norm": 0.3627931773662567,
      "learning_rate": 3.5459615027806157e-05,
      "loss": 0.3039,
      "step": 17080
    },
    {
      "epoch": 2.1748592154242625,
      "grad_norm": 0.3150716722011566,
      "learning_rate": 3.53574457595501e-05,
      "loss": 0.3036,
      "step": 17090
    },
    {
      "epoch": 2.1761318443574815,
      "grad_norm": 0.3463481068611145,
      "learning_rate": 3.525539227407817e-05,
      "loss": 0.3021,
      "step": 17100
    },
    {
      "epoch": 2.1774044732907,
      "grad_norm": 0.36909225583076477,
      "learning_rate": 3.5153454754180805e-05,
      "loss": 0.3036,
      "step": 17110
    },
    {
      "epoch": 2.178677102223919,
      "grad_norm": 0.3536665737628937,
      "learning_rate": 3.505163338244064e-05,
      "loss": 0.2886,
      "step": 17120
    },
    {
      "epoch": 2.179949731157138,
      "grad_norm": 0.2490367442369461,
      "learning_rate": 3.4949928341232283e-05,
      "loss": 0.3017,
      "step": 17130
    },
    {
      "epoch": 2.1812223600903566,
      "grad_norm": 0.42745357751846313,
      "learning_rate": 3.484833981272205e-05,
      "loss": 0.2911,
      "step": 17140
    },
    {
      "epoch": 2.1824949890235756,
      "grad_norm": 0.35167646408081055,
      "learning_rate": 3.47468679788675e-05,
      "loss": 0.2932,
      "step": 17150
    },
    {
      "epoch": 2.183767617956794,
      "grad_norm": 0.36273452639579773,
      "learning_rate": 3.4645513021417195e-05,
      "loss": 0.3061,
      "step": 17160
    },
    {
      "epoch": 2.185040246890013,
      "grad_norm": 0.4041876792907715,
      "learning_rate": 3.454427512191032e-05,
      "loss": 0.3174,
      "step": 17170
    },
    {
      "epoch": 2.1863128758232317,
      "grad_norm": 0.3643489181995392,
      "learning_rate": 3.444315446167646e-05,
      "loss": 0.2985,
      "step": 17180
    },
    {
      "epoch": 2.1875855047564507,
      "grad_norm": 0.3264223635196686,
      "learning_rate": 3.434215122183527e-05,
      "loss": 0.2995,
      "step": 17190
    },
    {
      "epoch": 2.1888581336896693,
      "grad_norm": 0.3508080244064331,
      "learning_rate": 3.424126558329588e-05,
      "loss": 0.316,
      "step": 17200
    },
    {
      "epoch": 2.1901307626228883,
      "grad_norm": 0.326315313577652,
      "learning_rate": 3.414049772675697e-05,
      "loss": 0.3063,
      "step": 17210
    },
    {
      "epoch": 2.191403391556107,
      "grad_norm": 0.38811415433883667,
      "learning_rate": 3.403984783270615e-05,
      "loss": 0.3148,
      "step": 17220
    },
    {
      "epoch": 2.192676020489326,
      "grad_norm": 0.3222638964653015,
      "learning_rate": 3.3939316081419855e-05,
      "loss": 0.3018,
      "step": 17230
    },
    {
      "epoch": 2.1939486494225444,
      "grad_norm": 0.29503822326660156,
      "learning_rate": 3.383890265296281e-05,
      "loss": 0.2976,
      "step": 17240
    },
    {
      "epoch": 2.1952212783557634,
      "grad_norm": 0.22584325075149536,
      "learning_rate": 3.373860772718782e-05,
      "loss": 0.2935,
      "step": 17250
    },
    {
      "epoch": 2.1964939072889824,
      "grad_norm": 0.4057084023952484,
      "learning_rate": 3.363843148373551e-05,
      "loss": 0.3028,
      "step": 17260
    },
    {
      "epoch": 2.197766536222201,
      "grad_norm": 0.3292093276977539,
      "learning_rate": 3.3538374102033866e-05,
      "loss": 0.2985,
      "step": 17270
    },
    {
      "epoch": 2.19903916515542,
      "grad_norm": 0.37566548585891724,
      "learning_rate": 3.343843576129796e-05,
      "loss": 0.2921,
      "step": 17280
    },
    {
      "epoch": 2.2003117940886385,
      "grad_norm": 0.3344871699810028,
      "learning_rate": 3.3338616640529727e-05,
      "loss": 0.2971,
      "step": 17290
    },
    {
      "epoch": 2.2015844230218575,
      "grad_norm": 0.3068912923336029,
      "learning_rate": 3.3238916918517515e-05,
      "loss": 0.3167,
      "step": 17300
    },
    {
      "epoch": 2.202857051955076,
      "grad_norm": 0.31195560097694397,
      "learning_rate": 3.3139336773835804e-05,
      "loss": 0.2848,
      "step": 17310
    },
    {
      "epoch": 2.204129680888295,
      "grad_norm": 0.33797815442085266,
      "learning_rate": 3.303987638484487e-05,
      "loss": 0.3093,
      "step": 17320
    },
    {
      "epoch": 2.2054023098215136,
      "grad_norm": 0.2982427179813385,
      "learning_rate": 3.2940535929690606e-05,
      "loss": 0.2903,
      "step": 17330
    },
    {
      "epoch": 2.2066749387547326,
      "grad_norm": 0.3101838231086731,
      "learning_rate": 3.2841315586303976e-05,
      "loss": 0.2934,
      "step": 17340
    },
    {
      "epoch": 2.207947567687951,
      "grad_norm": 0.27896299958229065,
      "learning_rate": 3.2742215532400825e-05,
      "loss": 0.3055,
      "step": 17350
    },
    {
      "epoch": 2.20922019662117,
      "grad_norm": 0.4634440839290619,
      "learning_rate": 3.2643235945481623e-05,
      "loss": 0.3038,
      "step": 17360
    },
    {
      "epoch": 2.2104928255543888,
      "grad_norm": 0.30810412764549255,
      "learning_rate": 3.2544377002830984e-05,
      "loss": 0.2866,
      "step": 17370
    },
    {
      "epoch": 2.2117654544876078,
      "grad_norm": 0.37021803855895996,
      "learning_rate": 3.2445638881517424e-05,
      "loss": 0.294,
      "step": 17380
    },
    {
      "epoch": 2.2130380834208268,
      "grad_norm": 0.3115372955799103,
      "learning_rate": 3.234702175839317e-05,
      "loss": 0.2915,
      "step": 17390
    },
    {
      "epoch": 2.2143107123540453,
      "grad_norm": 0.35197901725769043,
      "learning_rate": 3.2248525810093566e-05,
      "loss": 0.2856,
      "step": 17400
    },
    {
      "epoch": 2.2155833412872643,
      "grad_norm": 0.3878135085105896,
      "learning_rate": 3.2150151213037116e-05,
      "loss": 0.3164,
      "step": 17410
    },
    {
      "epoch": 2.216855970220483,
      "grad_norm": 0.2829205393791199,
      "learning_rate": 3.20518981434247e-05,
      "loss": 0.2942,
      "step": 17420
    },
    {
      "epoch": 2.218128599153702,
      "grad_norm": 0.35250672698020935,
      "learning_rate": 3.1953766777239756e-05,
      "loss": 0.3055,
      "step": 17430
    },
    {
      "epoch": 2.2194012280869204,
      "grad_norm": 0.26607829332351685,
      "learning_rate": 3.185575729024769e-05,
      "loss": 0.303,
      "step": 17440
    },
    {
      "epoch": 2.2206738570201394,
      "grad_norm": 0.3322920799255371,
      "learning_rate": 3.175786985799554e-05,
      "loss": 0.2877,
      "step": 17450
    },
    {
      "epoch": 2.221946485953358,
      "grad_norm": 0.30738794803619385,
      "learning_rate": 3.166010465581177e-05,
      "loss": 0.3127,
      "step": 17460
    },
    {
      "epoch": 2.223219114886577,
      "grad_norm": 0.3864952325820923,
      "learning_rate": 3.156246185880588e-05,
      "loss": 0.3008,
      "step": 17470
    },
    {
      "epoch": 2.2244917438197955,
      "grad_norm": 0.32515060901641846,
      "learning_rate": 3.1464941641868215e-05,
      "loss": 0.3025,
      "step": 17480
    },
    {
      "epoch": 2.2257643727530145,
      "grad_norm": 0.3691534996032715,
      "learning_rate": 3.136754417966947e-05,
      "loss": 0.2862,
      "step": 17490
    },
    {
      "epoch": 2.2270370016862335,
      "grad_norm": 0.3912619948387146,
      "learning_rate": 3.12702696466605e-05,
      "loss": 0.3004,
      "step": 17500
    },
    {
      "epoch": 2.2270370016862335,
      "eval_loss": 0.34381723403930664,
      "eval_runtime": 740.2472,
      "eval_samples_per_second": 10.615,
      "eval_steps_per_second": 5.308,
      "step": 17500
    },
    {
      "epoch": 2.228309630619452,
      "grad_norm": 0.3807332217693329,
      "learning_rate": 3.117311821707202e-05,
      "loss": 0.2991,
      "step": 17510
    },
    {
      "epoch": 2.229582259552671,
      "grad_norm": 0.3733745813369751,
      "learning_rate": 3.10760900649142e-05,
      "loss": 0.2998,
      "step": 17520
    },
    {
      "epoch": 2.2308548884858896,
      "grad_norm": 0.3251148760318756,
      "learning_rate": 3.0979185363976395e-05,
      "loss": 0.3066,
      "step": 17530
    },
    {
      "epoch": 2.2321275174191086,
      "grad_norm": 0.30505767464637756,
      "learning_rate": 3.088240428782693e-05,
      "loss": 0.3143,
      "step": 17540
    },
    {
      "epoch": 2.233400146352327,
      "grad_norm": 0.23557016253471375,
      "learning_rate": 3.078574700981257e-05,
      "loss": 0.292,
      "step": 17550
    },
    {
      "epoch": 2.234672775285546,
      "grad_norm": 0.24661822617053986,
      "learning_rate": 3.068921370305853e-05,
      "loss": 0.2971,
      "step": 17560
    },
    {
      "epoch": 2.2359454042187648,
      "grad_norm": 0.29047122597694397,
      "learning_rate": 3.059280454046772e-05,
      "loss": 0.2837,
      "step": 17570
    },
    {
      "epoch": 2.2372180331519838,
      "grad_norm": 0.3033979535102844,
      "learning_rate": 3.0496519694720926e-05,
      "loss": 0.3078,
      "step": 17580
    },
    {
      "epoch": 2.2384906620852023,
      "grad_norm": 0.4019489288330078,
      "learning_rate": 3.0400359338276186e-05,
      "loss": 0.3105,
      "step": 17590
    },
    {
      "epoch": 2.2397632910184213,
      "grad_norm": 0.279826819896698,
      "learning_rate": 3.0304323643368514e-05,
      "loss": 0.2854,
      "step": 17600
    },
    {
      "epoch": 2.2410359199516403,
      "grad_norm": 0.36021479964256287,
      "learning_rate": 3.0208412782009697e-05,
      "loss": 0.2847,
      "step": 17610
    },
    {
      "epoch": 2.242308548884859,
      "grad_norm": 0.339141309261322,
      "learning_rate": 3.0112626925987885e-05,
      "loss": 0.2818,
      "step": 17620
    },
    {
      "epoch": 2.243581177818078,
      "grad_norm": 0.3229760229587555,
      "learning_rate": 3.0016966246867405e-05,
      "loss": 0.2932,
      "step": 17630
    },
    {
      "epoch": 2.2448538067512964,
      "grad_norm": 0.379829466342926,
      "learning_rate": 2.992143091598829e-05,
      "loss": 0.3034,
      "step": 17640
    },
    {
      "epoch": 2.2461264356845154,
      "grad_norm": 0.34753337502479553,
      "learning_rate": 2.9826021104466084e-05,
      "loss": 0.3068,
      "step": 17650
    },
    {
      "epoch": 2.247399064617734,
      "grad_norm": 0.28133612871170044,
      "learning_rate": 2.9730736983191577e-05,
      "loss": 0.3061,
      "step": 17660
    },
    {
      "epoch": 2.248671693550953,
      "grad_norm": 0.3596072196960449,
      "learning_rate": 2.9635578722830336e-05,
      "loss": 0.2992,
      "step": 17670
    },
    {
      "epoch": 2.2499443224841715,
      "grad_norm": 0.30920058488845825,
      "learning_rate": 2.9540546493822518e-05,
      "loss": 0.3055,
      "step": 17680
    },
    {
      "epoch": 2.2512169514173905,
      "grad_norm": 0.4262079894542694,
      "learning_rate": 2.944564046638263e-05,
      "loss": 0.3091,
      "step": 17690
    },
    {
      "epoch": 2.252489580350609,
      "grad_norm": 0.3249802589416504,
      "learning_rate": 2.9350860810499015e-05,
      "loss": 0.3029,
      "step": 17700
    },
    {
      "epoch": 2.253762209283828,
      "grad_norm": 0.30979886651039124,
      "learning_rate": 2.9256207695933723e-05,
      "loss": 0.3037,
      "step": 17710
    },
    {
      "epoch": 2.255034838217047,
      "grad_norm": 0.27075615525245667,
      "learning_rate": 2.9161681292222152e-05,
      "loss": 0.2924,
      "step": 17720
    },
    {
      "epoch": 2.2563074671502656,
      "grad_norm": 0.3131425082683563,
      "learning_rate": 2.9067281768672737e-05,
      "loss": 0.2816,
      "step": 17730
    },
    {
      "epoch": 2.2575800960834846,
      "grad_norm": 0.29279792308807373,
      "learning_rate": 2.8973009294366748e-05,
      "loss": 0.2931,
      "step": 17740
    },
    {
      "epoch": 2.258852725016703,
      "grad_norm": 0.2500394880771637,
      "learning_rate": 2.8878864038157683e-05,
      "loss": 0.3002,
      "step": 17750
    },
    {
      "epoch": 2.260125353949922,
      "grad_norm": 0.387336403131485,
      "learning_rate": 2.8784846168671387e-05,
      "loss": 0.2968,
      "step": 17760
    },
    {
      "epoch": 2.2613979828831408,
      "grad_norm": 0.29802370071411133,
      "learning_rate": 2.86909558543054e-05,
      "loss": 0.2882,
      "step": 17770
    },
    {
      "epoch": 2.2626706118163598,
      "grad_norm": 0.3628524839878082,
      "learning_rate": 2.8597193263228904e-05,
      "loss": 0.2936,
      "step": 17780
    },
    {
      "epoch": 2.2639432407495783,
      "grad_norm": 0.2686256170272827,
      "learning_rate": 2.8503558563382238e-05,
      "loss": 0.2982,
      "step": 17790
    },
    {
      "epoch": 2.2652158696827973,
      "grad_norm": 0.3391004800796509,
      "learning_rate": 2.8410051922476664e-05,
      "loss": 0.3056,
      "step": 17800
    },
    {
      "epoch": 2.266488498616016,
      "grad_norm": 0.30329209566116333,
      "learning_rate": 2.831667350799415e-05,
      "loss": 0.3025,
      "step": 17810
    },
    {
      "epoch": 2.267761127549235,
      "grad_norm": 0.3231417238712311,
      "learning_rate": 2.822342348718694e-05,
      "loss": 0.2948,
      "step": 17820
    },
    {
      "epoch": 2.269033756482454,
      "grad_norm": 0.2910039722919464,
      "learning_rate": 2.813030202707727e-05,
      "loss": 0.2988,
      "step": 17830
    },
    {
      "epoch": 2.2703063854156724,
      "grad_norm": 0.3338572084903717,
      "learning_rate": 2.8037309294457226e-05,
      "loss": 0.3038,
      "step": 17840
    },
    {
      "epoch": 2.271579014348891,
      "grad_norm": 0.2752605974674225,
      "learning_rate": 2.7944445455888212e-05,
      "loss": 0.3141,
      "step": 17850
    },
    {
      "epoch": 2.27285164328211,
      "grad_norm": 0.29817792773246765,
      "learning_rate": 2.7851710677700836e-05,
      "loss": 0.304,
      "step": 17860
    },
    {
      "epoch": 2.274124272215329,
      "grad_norm": 0.3104429841041565,
      "learning_rate": 2.7759105125994467e-05,
      "loss": 0.3007,
      "step": 17870
    },
    {
      "epoch": 2.2753969011485475,
      "grad_norm": 0.446583092212677,
      "learning_rate": 2.7666628966637096e-05,
      "loss": 0.3059,
      "step": 17880
    },
    {
      "epoch": 2.2766695300817665,
      "grad_norm": 0.43575790524482727,
      "learning_rate": 2.7574282365265003e-05,
      "loss": 0.2878,
      "step": 17890
    },
    {
      "epoch": 2.277942159014985,
      "grad_norm": 0.372798889875412,
      "learning_rate": 2.7482065487282205e-05,
      "loss": 0.2989,
      "step": 17900
    },
    {
      "epoch": 2.279214787948204,
      "grad_norm": 0.3251318633556366,
      "learning_rate": 2.738997849786058e-05,
      "loss": 0.3084,
      "step": 17910
    },
    {
      "epoch": 2.2804874168814226,
      "grad_norm": 0.31302040815353394,
      "learning_rate": 2.7298021561939234e-05,
      "loss": 0.2876,
      "step": 17920
    },
    {
      "epoch": 2.2817600458146416,
      "grad_norm": 0.3355717658996582,
      "learning_rate": 2.720619484422444e-05,
      "loss": 0.309,
      "step": 17930
    },
    {
      "epoch": 2.28303267474786,
      "grad_norm": 0.39882412552833557,
      "learning_rate": 2.7114498509189124e-05,
      "loss": 0.3148,
      "step": 17940
    },
    {
      "epoch": 2.284305303681079,
      "grad_norm": 0.479784220457077,
      "learning_rate": 2.7022932721072703e-05,
      "loss": 0.2948,
      "step": 17950
    },
    {
      "epoch": 2.2855779326142978,
      "grad_norm": 0.3501317799091339,
      "learning_rate": 2.6931497643880853e-05,
      "loss": 0.2872,
      "step": 17960
    },
    {
      "epoch": 2.2868505615475168,
      "grad_norm": 0.29977554082870483,
      "learning_rate": 2.6840193441385042e-05,
      "loss": 0.3005,
      "step": 17970
    },
    {
      "epoch": 2.2881231904807358,
      "grad_norm": 0.32377904653549194,
      "learning_rate": 2.6749020277122328e-05,
      "loss": 0.3145,
      "step": 17980
    },
    {
      "epoch": 2.2893958194139543,
      "grad_norm": 0.31009992957115173,
      "learning_rate": 2.6657978314395138e-05,
      "loss": 0.298,
      "step": 17990
    },
    {
      "epoch": 2.2906684483471733,
      "grad_norm": 0.3175504505634308,
      "learning_rate": 2.656706771627082e-05,
      "loss": 0.2948,
      "step": 18000
    },
    {
      "epoch": 2.2906684483471733,
      "eval_loss": 0.3429020643234253,
      "eval_runtime": 740.1063,
      "eval_samples_per_second": 10.617,
      "eval_steps_per_second": 5.309,
      "step": 18000
    },
    {
      "epoch": 2.291941077280392,
      "grad_norm": 0.3038370609283447,
      "learning_rate": 2.647628864558147e-05,
      "loss": 0.2871,
      "step": 18010
    },
    {
      "epoch": 2.293213706213611,
      "grad_norm": 0.36712390184402466,
      "learning_rate": 2.6385641264923567e-05,
      "loss": 0.2963,
      "step": 18020
    },
    {
      "epoch": 2.2944863351468294,
      "grad_norm": 0.27687695622444153,
      "learning_rate": 2.6295125736657778e-05,
      "loss": 0.2966,
      "step": 18030
    },
    {
      "epoch": 2.2957589640800484,
      "grad_norm": 0.3101307451725006,
      "learning_rate": 2.6204742222908617e-05,
      "loss": 0.2934,
      "step": 18040
    },
    {
      "epoch": 2.297031593013267,
      "grad_norm": 0.36423662304878235,
      "learning_rate": 2.6114490885564003e-05,
      "loss": 0.3191,
      "step": 18050
    },
    {
      "epoch": 2.298304221946486,
      "grad_norm": 0.3097430467605591,
      "learning_rate": 2.6024371886275277e-05,
      "loss": 0.2995,
      "step": 18060
    },
    {
      "epoch": 2.2995768508797045,
      "grad_norm": 0.38211590051651,
      "learning_rate": 2.5934385386456627e-05,
      "loss": 0.3102,
      "step": 18070
    },
    {
      "epoch": 2.3008494798129235,
      "grad_norm": 0.3408685326576233,
      "learning_rate": 2.5844531547285034e-05,
      "loss": 0.2923,
      "step": 18080
    },
    {
      "epoch": 2.3021221087461425,
      "grad_norm": 0.3355252742767334,
      "learning_rate": 2.575481052969976e-05,
      "loss": 0.3002,
      "step": 18090
    },
    {
      "epoch": 2.303394737679361,
      "grad_norm": 0.33302751183509827,
      "learning_rate": 2.5665222494402187e-05,
      "loss": 0.3054,
      "step": 18100
    },
    {
      "epoch": 2.30466736661258,
      "grad_norm": 0.2995370626449585,
      "learning_rate": 2.557576760185558e-05,
      "loss": 0.2956,
      "step": 18110
    },
    {
      "epoch": 2.3059399955457986,
      "grad_norm": 0.38509637117385864,
      "learning_rate": 2.548644601228467e-05,
      "loss": 0.2747,
      "step": 18120
    },
    {
      "epoch": 2.3072126244790176,
      "grad_norm": 0.26090705394744873,
      "learning_rate": 2.5397257885675397e-05,
      "loss": 0.3011,
      "step": 18130
    },
    {
      "epoch": 2.308485253412236,
      "grad_norm": 0.36035922169685364,
      "learning_rate": 2.530820338177473e-05,
      "loss": 0.2973,
      "step": 18140
    },
    {
      "epoch": 2.309757882345455,
      "grad_norm": 0.48980066180229187,
      "learning_rate": 2.521928266009027e-05,
      "loss": 0.2958,
      "step": 18150
    },
    {
      "epoch": 2.3110305112786738,
      "grad_norm": 0.31252214312553406,
      "learning_rate": 2.513049587988997e-05,
      "loss": 0.2928,
      "step": 18160
    },
    {
      "epoch": 2.3123031402118928,
      "grad_norm": 0.3600216209888458,
      "learning_rate": 2.5041843200201874e-05,
      "loss": 0.3123,
      "step": 18170
    },
    {
      "epoch": 2.3135757691451113,
      "grad_norm": 0.26763081550598145,
      "learning_rate": 2.4953324779813923e-05,
      "loss": 0.3116,
      "step": 18180
    },
    {
      "epoch": 2.3148483980783303,
      "grad_norm": 0.3728047013282776,
      "learning_rate": 2.4864940777273495e-05,
      "loss": 0.3182,
      "step": 18190
    },
    {
      "epoch": 2.3161210270115493,
      "grad_norm": 0.3190769553184509,
      "learning_rate": 2.4776691350887195e-05,
      "loss": 0.3025,
      "step": 18200
    },
    {
      "epoch": 2.317393655944768,
      "grad_norm": 0.4168556332588196,
      "learning_rate": 2.4688576658720684e-05,
      "loss": 0.3014,
      "step": 18210
    },
    {
      "epoch": 2.318666284877987,
      "grad_norm": 0.2969818711280823,
      "learning_rate": 2.4600596858598225e-05,
      "loss": 0.2961,
      "step": 18220
    },
    {
      "epoch": 2.3199389138112054,
      "grad_norm": 0.2988417148590088,
      "learning_rate": 2.4512752108102443e-05,
      "loss": 0.2941,
      "step": 18230
    },
    {
      "epoch": 2.3212115427444244,
      "grad_norm": 0.25127124786376953,
      "learning_rate": 2.4425042564574184e-05,
      "loss": 0.2802,
      "step": 18240
    },
    {
      "epoch": 2.322484171677643,
      "grad_norm": 0.39509299397468567,
      "learning_rate": 2.4337468385111984e-05,
      "loss": 0.3,
      "step": 18250
    },
    {
      "epoch": 2.323756800610862,
      "grad_norm": 0.30128732323646545,
      "learning_rate": 2.4250029726572098e-05,
      "loss": 0.2866,
      "step": 18260
    },
    {
      "epoch": 2.3250294295440805,
      "grad_norm": 0.4013385474681854,
      "learning_rate": 2.416272674556781e-05,
      "loss": 0.2914,
      "step": 18270
    },
    {
      "epoch": 2.3263020584772995,
      "grad_norm": 0.3685484528541565,
      "learning_rate": 2.40755595984696e-05,
      "loss": 0.3215,
      "step": 18280
    },
    {
      "epoch": 2.327574687410518,
      "grad_norm": 0.32966864109039307,
      "learning_rate": 2.398852844140458e-05,
      "loss": 0.3029,
      "step": 18290
    },
    {
      "epoch": 2.328847316343737,
      "grad_norm": 0.4098418951034546,
      "learning_rate": 2.3901633430256276e-05,
      "loss": 0.3092,
      "step": 18300
    },
    {
      "epoch": 2.330119945276956,
      "grad_norm": 0.2921774983406067,
      "learning_rate": 2.381487472066435e-05,
      "loss": 0.2845,
      "step": 18310
    },
    {
      "epoch": 2.3313925742101747,
      "grad_norm": 0.2908449172973633,
      "learning_rate": 2.3728252468024325e-05,
      "loss": 0.2915,
      "step": 18320
    },
    {
      "epoch": 2.3326652031433937,
      "grad_norm": 0.3279052972793579,
      "learning_rate": 2.36417668274874e-05,
      "loss": 0.3001,
      "step": 18330
    },
    {
      "epoch": 2.333937832076612,
      "grad_norm": 0.2819328010082245,
      "learning_rate": 2.355541795395997e-05,
      "loss": 0.2981,
      "step": 18340
    },
    {
      "epoch": 2.335210461009831,
      "grad_norm": 0.3202240467071533,
      "learning_rate": 2.3469206002103507e-05,
      "loss": 0.2963,
      "step": 18350
    },
    {
      "epoch": 2.3364830899430498,
      "grad_norm": 0.5035780668258667,
      "learning_rate": 2.3383131126334278e-05,
      "loss": 0.3064,
      "step": 18360
    },
    {
      "epoch": 2.3377557188762688,
      "grad_norm": 0.34717851877212524,
      "learning_rate": 2.3297193480822998e-05,
      "loss": 0.2976,
      "step": 18370
    },
    {
      "epoch": 2.3390283478094873,
      "grad_norm": 0.3284602761268616,
      "learning_rate": 2.3211393219494538e-05,
      "loss": 0.3158,
      "step": 18380
    },
    {
      "epoch": 2.3403009767427063,
      "grad_norm": 0.30623000860214233,
      "learning_rate": 2.3125730496027796e-05,
      "loss": 0.2943,
      "step": 18390
    },
    {
      "epoch": 2.341573605675925,
      "grad_norm": 0.3184042274951935,
      "learning_rate": 2.3040205463855226e-05,
      "loss": 0.3026,
      "step": 18400
    },
    {
      "epoch": 2.342846234609144,
      "grad_norm": 0.3917137682437897,
      "learning_rate": 2.2954818276162792e-05,
      "loss": 0.2828,
      "step": 18410
    },
    {
      "epoch": 2.344118863542363,
      "grad_norm": 0.4958382248878479,
      "learning_rate": 2.286956908588935e-05,
      "loss": 0.2907,
      "step": 18420
    },
    {
      "epoch": 2.3453914924755814,
      "grad_norm": 0.28505513072013855,
      "learning_rate": 2.2784458045726776e-05,
      "loss": 0.2945,
      "step": 18430
    },
    {
      "epoch": 2.3466641214088,
      "grad_norm": 0.3682939410209656,
      "learning_rate": 2.269948530811945e-05,
      "loss": 0.3008,
      "step": 18440
    },
    {
      "epoch": 2.347936750342019,
      "grad_norm": 0.3210921883583069,
      "learning_rate": 2.261465102526401e-05,
      "loss": 0.2972,
      "step": 18450
    },
    {
      "epoch": 2.349209379275238,
      "grad_norm": 0.30222460627555847,
      "learning_rate": 2.252995534910911e-05,
      "loss": 0.2933,
      "step": 18460
    },
    {
      "epoch": 2.3504820082084565,
      "grad_norm": 0.41234469413757324,
      "learning_rate": 2.2445398431355115e-05,
      "loss": 0.2941,
      "step": 18470
    },
    {
      "epoch": 2.3517546371416755,
      "grad_norm": 0.46898943185806274,
      "learning_rate": 2.236098042345395e-05,
      "loss": 0.29,
      "step": 18480
    },
    {
      "epoch": 2.353027266074894,
      "grad_norm": 0.3289299011230469,
      "learning_rate": 2.227670147660864e-05,
      "loss": 0.3003,
      "step": 18490
    },
    {
      "epoch": 2.354299895008113,
      "grad_norm": 0.3742210566997528,
      "learning_rate": 2.2192561741773154e-05,
      "loss": 0.3046,
      "step": 18500
    },
    {
      "epoch": 2.354299895008113,
      "eval_loss": 0.3418768048286438,
      "eval_runtime": 749.7483,
      "eval_samples_per_second": 10.481,
      "eval_steps_per_second": 5.24,
      "step": 18500
    },
    {
      "epoch": 2.3555725239413317,
      "grad_norm": 0.3044910430908203,
      "learning_rate": 2.2108561369652168e-05,
      "loss": 0.2908,
      "step": 18510
    },
    {
      "epoch": 2.3568451528745507,
      "grad_norm": 0.25855234265327454,
      "learning_rate": 2.2024700510700704e-05,
      "loss": 0.3028,
      "step": 18520
    },
    {
      "epoch": 2.358117781807769,
      "grad_norm": 0.2850086987018585,
      "learning_rate": 2.1940979315123834e-05,
      "loss": 0.2969,
      "step": 18530
    },
    {
      "epoch": 2.359390410740988,
      "grad_norm": 0.28914734721183777,
      "learning_rate": 2.1857397932876633e-05,
      "loss": 0.2743,
      "step": 18540
    },
    {
      "epoch": 2.3606630396742068,
      "grad_norm": 0.3280204236507416,
      "learning_rate": 2.1773956513663607e-05,
      "loss": 0.2866,
      "step": 18550
    },
    {
      "epoch": 2.3619356686074258,
      "grad_norm": 0.3898548185825348,
      "learning_rate": 2.1690655206938635e-05,
      "loss": 0.3031,
      "step": 18560
    },
    {
      "epoch": 2.3632082975406448,
      "grad_norm": 0.37274038791656494,
      "learning_rate": 2.1607494161904594e-05,
      "loss": 0.2912,
      "step": 18570
    },
    {
      "epoch": 2.3644809264738633,
      "grad_norm": 0.2586323618888855,
      "learning_rate": 2.1524473527513224e-05,
      "loss": 0.2862,
      "step": 18580
    },
    {
      "epoch": 2.3657535554070823,
      "grad_norm": 0.30102255940437317,
      "learning_rate": 2.1441593452464725e-05,
      "loss": 0.3006,
      "step": 18590
    },
    {
      "epoch": 2.367026184340301,
      "grad_norm": 0.33135947585105896,
      "learning_rate": 2.135885408520746e-05,
      "loss": 0.3055,
      "step": 18600
    },
    {
      "epoch": 2.36829881327352,
      "grad_norm": 0.3012240529060364,
      "learning_rate": 2.1276255573937885e-05,
      "loss": 0.313,
      "step": 18610
    },
    {
      "epoch": 2.3695714422067384,
      "grad_norm": 0.3013567626476288,
      "learning_rate": 2.119379806660009e-05,
      "loss": 0.2918,
      "step": 18620
    },
    {
      "epoch": 2.3708440711399574,
      "grad_norm": 0.31932517886161804,
      "learning_rate": 2.1111481710885683e-05,
      "loss": 0.2865,
      "step": 18630
    },
    {
      "epoch": 2.372116700073176,
      "grad_norm": 0.32088249921798706,
      "learning_rate": 2.1029306654233373e-05,
      "loss": 0.2876,
      "step": 18640
    },
    {
      "epoch": 2.373389329006395,
      "grad_norm": 0.38199135661125183,
      "learning_rate": 2.0947273043828786e-05,
      "loss": 0.3032,
      "step": 18650
    },
    {
      "epoch": 2.3746619579396135,
      "grad_norm": 0.3389952480792999,
      "learning_rate": 2.0865381026604302e-05,
      "loss": 0.2803,
      "step": 18660
    },
    {
      "epoch": 2.3759345868728325,
      "grad_norm": 0.2474588304758072,
      "learning_rate": 2.078363074923858e-05,
      "loss": 0.2792,
      "step": 18670
    },
    {
      "epoch": 2.3772072158060515,
      "grad_norm": 0.36311325430870056,
      "learning_rate": 2.0702022358156426e-05,
      "loss": 0.3085,
      "step": 18680
    },
    {
      "epoch": 2.37847984473927,
      "grad_norm": 0.3780742287635803,
      "learning_rate": 2.062055599952858e-05,
      "loss": 0.3012,
      "step": 18690
    },
    {
      "epoch": 2.379752473672489,
      "grad_norm": 0.30700942873954773,
      "learning_rate": 2.05392318192713e-05,
      "loss": 0.2849,
      "step": 18700
    },
    {
      "epoch": 2.3810251026057077,
      "grad_norm": 0.2836360037326813,
      "learning_rate": 2.0458049963046232e-05,
      "loss": 0.2984,
      "step": 18710
    },
    {
      "epoch": 2.3822977315389267,
      "grad_norm": 0.28845325112342834,
      "learning_rate": 2.0377010576260057e-05,
      "loss": 0.3016,
      "step": 18720
    },
    {
      "epoch": 2.383570360472145,
      "grad_norm": 0.2847014367580414,
      "learning_rate": 2.029611380406432e-05,
      "loss": 0.2876,
      "step": 18730
    },
    {
      "epoch": 2.384842989405364,
      "grad_norm": 0.2587708532810211,
      "learning_rate": 2.0215359791355202e-05,
      "loss": 0.2934,
      "step": 18740
    },
    {
      "epoch": 2.3861156183385828,
      "grad_norm": 0.3418234586715698,
      "learning_rate": 2.0134748682772954e-05,
      "loss": 0.2908,
      "step": 18750
    },
    {
      "epoch": 2.3873882472718018,
      "grad_norm": 0.3220810294151306,
      "learning_rate": 2.0054280622702103e-05,
      "loss": 0.3126,
      "step": 18760
    },
    {
      "epoch": 2.3886608762050203,
      "grad_norm": 0.26087313890457153,
      "learning_rate": 1.997395575527081e-05,
      "loss": 0.3143,
      "step": 18770
    },
    {
      "epoch": 2.3899335051382393,
      "grad_norm": 0.32117509841918945,
      "learning_rate": 1.989377422435088e-05,
      "loss": 0.3025,
      "step": 18780
    },
    {
      "epoch": 2.3912061340714583,
      "grad_norm": 0.3057060241699219,
      "learning_rate": 1.9813736173557286e-05,
      "loss": 0.2844,
      "step": 18790
    },
    {
      "epoch": 2.392478763004677,
      "grad_norm": 0.3337864279747009,
      "learning_rate": 1.9733841746248006e-05,
      "loss": 0.301,
      "step": 18800
    },
    {
      "epoch": 2.393751391937896,
      "grad_norm": 0.2982988655567169,
      "learning_rate": 1.9654091085523874e-05,
      "loss": 0.3026,
      "step": 18810
    },
    {
      "epoch": 2.3950240208711144,
      "grad_norm": 0.3369164764881134,
      "learning_rate": 1.957448433422813e-05,
      "loss": 0.3016,
      "step": 18820
    },
    {
      "epoch": 2.3962966498043334,
      "grad_norm": 0.27454301714897156,
      "learning_rate": 1.949502163494624e-05,
      "loss": 0.3043,
      "step": 18830
    },
    {
      "epoch": 2.397569278737552,
      "grad_norm": 0.40859106183052063,
      "learning_rate": 1.941570313000578e-05,
      "loss": 0.3122,
      "step": 18840
    },
    {
      "epoch": 2.398841907670771,
      "grad_norm": 0.33764776587486267,
      "learning_rate": 1.9336528961475908e-05,
      "loss": 0.2988,
      "step": 18850
    },
    {
      "epoch": 2.4001145366039895,
      "grad_norm": 0.26112788915634155,
      "learning_rate": 1.9257499271167346e-05,
      "loss": 0.3084,
      "step": 18860
    },
    {
      "epoch": 2.4013871655372085,
      "grad_norm": 0.33114615082740784,
      "learning_rate": 1.9178614200631972e-05,
      "loss": 0.3218,
      "step": 18870
    },
    {
      "epoch": 2.402659794470427,
      "grad_norm": 0.3511214852333069,
      "learning_rate": 1.90998738911627e-05,
      "loss": 0.3109,
      "step": 18880
    },
    {
      "epoch": 2.403932423403646,
      "grad_norm": 0.3530269265174866,
      "learning_rate": 1.902127848379319e-05,
      "loss": 0.2983,
      "step": 18890
    },
    {
      "epoch": 2.405205052336865,
      "grad_norm": 0.28861290216445923,
      "learning_rate": 1.8942828119297405e-05,
      "loss": 0.2753,
      "step": 18900
    },
    {
      "epoch": 2.4064776812700837,
      "grad_norm": 0.41786447167396545,
      "learning_rate": 1.8864522938189687e-05,
      "loss": 0.3034,
      "step": 18910
    },
    {
      "epoch": 2.4077503102033027,
      "grad_norm": 0.30880969762802124,
      "learning_rate": 1.8786363080724224e-05,
      "loss": 0.31,
      "step": 18920
    },
    {
      "epoch": 2.409022939136521,
      "grad_norm": 0.3016397953033447,
      "learning_rate": 1.8708348686895005e-05,
      "loss": 0.3088,
      "step": 18930
    },
    {
      "epoch": 2.41029556806974,
      "grad_norm": 0.32141175866127014,
      "learning_rate": 1.8630479896435405e-05,
      "loss": 0.3041,
      "step": 18940
    },
    {
      "epoch": 2.4115681970029588,
      "grad_norm": 0.26177313923835754,
      "learning_rate": 1.855275684881801e-05,
      "loss": 0.2815,
      "step": 18950
    },
    {
      "epoch": 2.4128408259361778,
      "grad_norm": 0.2906176745891571,
      "learning_rate": 1.847517968325442e-05,
      "loss": 0.2961,
      "step": 18960
    },
    {
      "epoch": 2.4141134548693963,
      "grad_norm": 0.36953648924827576,
      "learning_rate": 1.839774853869487e-05,
      "loss": 0.3067,
      "step": 18970
    },
    {
      "epoch": 2.4153860838026153,
      "grad_norm": 0.28373074531555176,
      "learning_rate": 1.8320463553828082e-05,
      "loss": 0.2994,
      "step": 18980
    },
    {
      "epoch": 2.416658712735834,
      "grad_norm": 0.3132779002189636,
      "learning_rate": 1.8243324867081025e-05,
      "loss": 0.2854,
      "step": 18990
    },
    {
      "epoch": 2.417931341669053,
      "grad_norm": 0.2951154112815857,
      "learning_rate": 1.8166332616618576e-05,
      "loss": 0.3019,
      "step": 19000
    },
    {
      "epoch": 2.417931341669053,
      "eval_loss": 0.34158381819725037,
      "eval_runtime": 759.3434,
      "eval_samples_per_second": 10.348,
      "eval_steps_per_second": 5.174,
      "step": 19000
    },
    {
      "epoch": 2.419203970602272,
      "grad_norm": 0.3069773316383362,
      "learning_rate": 1.808948694034336e-05,
      "loss": 0.3,
      "step": 19010
    },
    {
      "epoch": 2.4204765995354904,
      "grad_norm": 0.31910449266433716,
      "learning_rate": 1.8012787975895406e-05,
      "loss": 0.296,
      "step": 19020
    },
    {
      "epoch": 2.421749228468709,
      "grad_norm": 0.29951855540275574,
      "learning_rate": 1.7936235860652094e-05,
      "loss": 0.3032,
      "step": 19030
    },
    {
      "epoch": 2.423021857401928,
      "grad_norm": 0.29122209548950195,
      "learning_rate": 1.7859830731727657e-05,
      "loss": 0.3077,
      "step": 19040
    },
    {
      "epoch": 2.424294486335147,
      "grad_norm": 0.292226105928421,
      "learning_rate": 1.7783572725973085e-05,
      "loss": 0.2984,
      "step": 19050
    },
    {
      "epoch": 2.4255671152683655,
      "grad_norm": 0.2679942846298218,
      "learning_rate": 1.7707461979975913e-05,
      "loss": 0.2906,
      "step": 19060
    },
    {
      "epoch": 2.4268397442015845,
      "grad_norm": 0.3235546946525574,
      "learning_rate": 1.763149863005985e-05,
      "loss": 0.3004,
      "step": 19070
    },
    {
      "epoch": 2.428112373134803,
      "grad_norm": 0.3916260302066803,
      "learning_rate": 1.755568281228458e-05,
      "loss": 0.2973,
      "step": 19080
    },
    {
      "epoch": 2.429385002068022,
      "grad_norm": 0.5178733468055725,
      "learning_rate": 1.7480014662445654e-05,
      "loss": 0.3013,
      "step": 19090
    },
    {
      "epoch": 2.4306576310012407,
      "grad_norm": 0.31354010105133057,
      "learning_rate": 1.7404494316073993e-05,
      "loss": 0.2866,
      "step": 19100
    },
    {
      "epoch": 2.4319302599344597,
      "grad_norm": 0.23332111537456512,
      "learning_rate": 1.7329121908435918e-05,
      "loss": 0.2871,
      "step": 19110
    },
    {
      "epoch": 2.433202888867678,
      "grad_norm": 0.3665198087692261,
      "learning_rate": 1.725389757453262e-05,
      "loss": 0.3017,
      "step": 19120
    },
    {
      "epoch": 2.434475517800897,
      "grad_norm": 0.3691102862358093,
      "learning_rate": 1.7178821449100192e-05,
      "loss": 0.2912,
      "step": 19130
    },
    {
      "epoch": 2.4357481467341158,
      "grad_norm": 0.35533252358436584,
      "learning_rate": 1.710389366660925e-05,
      "loss": 0.276,
      "step": 19140
    },
    {
      "epoch": 2.4370207756673348,
      "grad_norm": 0.27141186594963074,
      "learning_rate": 1.7029114361264686e-05,
      "loss": 0.2852,
      "step": 19150
    },
    {
      "epoch": 2.4382934046005538,
      "grad_norm": 0.26881471276283264,
      "learning_rate": 1.6954483667005437e-05,
      "loss": 0.2938,
      "step": 19160
    },
    {
      "epoch": 2.4395660335337723,
      "grad_norm": 0.397560179233551,
      "learning_rate": 1.688000171750427e-05,
      "loss": 0.3063,
      "step": 19170
    },
    {
      "epoch": 2.4408386624669913,
      "grad_norm": 0.3423174321651459,
      "learning_rate": 1.680566864616756e-05,
      "loss": 0.2758,
      "step": 19180
    },
    {
      "epoch": 2.44211129140021,
      "grad_norm": 0.34902626276016235,
      "learning_rate": 1.6731484586135006e-05,
      "loss": 0.2848,
      "step": 19190
    },
    {
      "epoch": 2.443383920333429,
      "grad_norm": 0.25718674063682556,
      "learning_rate": 1.665744967027937e-05,
      "loss": 0.2898,
      "step": 19200
    },
    {
      "epoch": 2.4446565492666474,
      "grad_norm": 0.3306138515472412,
      "learning_rate": 1.6583564031206357e-05,
      "loss": 0.2823,
      "step": 19210
    },
    {
      "epoch": 2.4459291781998664,
      "grad_norm": 0.3111816942691803,
      "learning_rate": 1.650982780125424e-05,
      "loss": 0.2924,
      "step": 19220
    },
    {
      "epoch": 2.447201807133085,
      "grad_norm": 0.3569360375404358,
      "learning_rate": 1.6436241112493666e-05,
      "loss": 0.2885,
      "step": 19230
    },
    {
      "epoch": 2.448474436066304,
      "grad_norm": 0.2968513071537018,
      "learning_rate": 1.6362804096727523e-05,
      "loss": 0.2979,
      "step": 19240
    },
    {
      "epoch": 2.4497470649995226,
      "grad_norm": 0.4107007682323456,
      "learning_rate": 1.6289516885490507e-05,
      "loss": 0.3062,
      "step": 19250
    },
    {
      "epoch": 2.4510196939327415,
      "grad_norm": 0.37030020356178284,
      "learning_rate": 1.6216379610049116e-05,
      "loss": 0.2855,
      "step": 19260
    },
    {
      "epoch": 2.4522923228659605,
      "grad_norm": 0.31842753291130066,
      "learning_rate": 1.6143392401401148e-05,
      "loss": 0.2925,
      "step": 19270
    },
    {
      "epoch": 2.453564951799179,
      "grad_norm": 0.2990139126777649,
      "learning_rate": 1.607055539027571e-05,
      "loss": 0.286,
      "step": 19280
    },
    {
      "epoch": 2.454837580732398,
      "grad_norm": 0.35153359174728394,
      "learning_rate": 1.5997868707132924e-05,
      "loss": 0.2869,
      "step": 19290
    },
    {
      "epoch": 2.4561102096656167,
      "grad_norm": 0.2997586131095886,
      "learning_rate": 1.5925332482163557e-05,
      "loss": 0.2929,
      "step": 19300
    },
    {
      "epoch": 2.4573828385988357,
      "grad_norm": 0.34582534432411194,
      "learning_rate": 1.585294684528895e-05,
      "loss": 0.2897,
      "step": 19310
    },
    {
      "epoch": 2.458655467532054,
      "grad_norm": 0.39639154076576233,
      "learning_rate": 1.578071192616065e-05,
      "loss": 0.3002,
      "step": 19320
    },
    {
      "epoch": 2.459928096465273,
      "grad_norm": 0.3005064129829407,
      "learning_rate": 1.5708627854160385e-05,
      "loss": 0.288,
      "step": 19330
    },
    {
      "epoch": 2.4612007253984918,
      "grad_norm": 0.29878172278404236,
      "learning_rate": 1.563669475839956e-05,
      "loss": 0.3002,
      "step": 19340
    },
    {
      "epoch": 2.4624733543317108,
      "grad_norm": 0.34521982073783875,
      "learning_rate": 1.5564912767719208e-05,
      "loss": 0.3137,
      "step": 19350
    },
    {
      "epoch": 2.4637459832649293,
      "grad_norm": 0.29466909170150757,
      "learning_rate": 1.549328201068977e-05,
      "loss": 0.2811,
      "step": 19360
    },
    {
      "epoch": 2.4650186121981483,
      "grad_norm": 0.3975823223590851,
      "learning_rate": 1.5421802615610746e-05,
      "loss": 0.3013,
      "step": 19370
    },
    {
      "epoch": 2.4662912411313673,
      "grad_norm": 0.33380836248397827,
      "learning_rate": 1.5350474710510508e-05,
      "loss": 0.302,
      "step": 19380
    },
    {
      "epoch": 2.467563870064586,
      "grad_norm": 0.3787229061126709,
      "learning_rate": 1.5279298423146184e-05,
      "loss": 0.3233,
      "step": 19390
    },
    {
      "epoch": 2.468836498997805,
      "grad_norm": 0.28193530440330505,
      "learning_rate": 1.5208273881003254e-05,
      "loss": 0.2825,
      "step": 19400
    },
    {
      "epoch": 2.4701091279310234,
      "grad_norm": 0.2890508472919464,
      "learning_rate": 1.5137401211295433e-05,
      "loss": 0.2948,
      "step": 19410
    },
    {
      "epoch": 2.4713817568642424,
      "grad_norm": 0.3439224064350128,
      "learning_rate": 1.5066680540964385e-05,
      "loss": 0.3031,
      "step": 19420
    },
    {
      "epoch": 2.472654385797461,
      "grad_norm": 0.3363132178783417,
      "learning_rate": 1.4996111996679563e-05,
      "loss": 0.3016,
      "step": 19430
    },
    {
      "epoch": 2.47392701473068,
      "grad_norm": 0.31613796949386597,
      "learning_rate": 1.4925695704837984e-05,
      "loss": 0.2966,
      "step": 19440
    },
    {
      "epoch": 2.4751996436638986,
      "grad_norm": 0.24506470561027527,
      "learning_rate": 1.4855431791563822e-05,
      "loss": 0.3072,
      "step": 19450
    },
    {
      "epoch": 2.4764722725971176,
      "grad_norm": 0.36944806575775146,
      "learning_rate": 1.4785320382708456e-05,
      "loss": 0.3042,
      "step": 19460
    },
    {
      "epoch": 2.477744901530336,
      "grad_norm": 0.36874812841415405,
      "learning_rate": 1.4715361603850054e-05,
      "loss": 0.3016,
      "step": 19470
    },
    {
      "epoch": 2.479017530463555,
      "grad_norm": 0.3786084055900574,
      "learning_rate": 1.4645555580293423e-05,
      "loss": 0.3053,
      "step": 19480
    },
    {
      "epoch": 2.480290159396774,
      "grad_norm": 0.32812267541885376,
      "learning_rate": 1.4575902437069756e-05,
      "loss": 0.2916,
      "step": 19490
    },
    {
      "epoch": 2.4815627883299927,
      "grad_norm": 0.35798025131225586,
      "learning_rate": 1.4506402298936383e-05,
      "loss": 0.2886,
      "step": 19500
    },
    {
      "epoch": 2.4815627883299927,
      "eval_loss": 0.3413805067539215,
      "eval_runtime": 974.0751,
      "eval_samples_per_second": 8.067,
      "eval_steps_per_second": 4.034,
      "step": 19500
    },
    {
      "epoch": 2.4828354172632117,
      "grad_norm": 0.3522343039512634,
      "learning_rate": 1.4437055290376677e-05,
      "loss": 0.2946,
      "step": 19510
    },
    {
      "epoch": 2.48410804619643,
      "grad_norm": 0.3084821403026581,
      "learning_rate": 1.4367861535599658e-05,
      "loss": 0.2782,
      "step": 19520
    },
    {
      "epoch": 2.485380675129649,
      "grad_norm": 0.3519423007965088,
      "learning_rate": 1.4298821158539833e-05,
      "loss": 0.3087,
      "step": 19530
    },
    {
      "epoch": 2.4866533040628678,
      "grad_norm": 0.3109282851219177,
      "learning_rate": 1.4229934282857094e-05,
      "loss": 0.2967,
      "step": 19540
    },
    {
      "epoch": 2.4879259329960868,
      "grad_norm": 0.2978895604610443,
      "learning_rate": 1.4161201031936288e-05,
      "loss": 0.2998,
      "step": 19550
    },
    {
      "epoch": 2.4891985619293053,
      "grad_norm": 0.42802369594573975,
      "learning_rate": 1.409262152888715e-05,
      "loss": 0.3031,
      "step": 19560
    },
    {
      "epoch": 2.4904711908625243,
      "grad_norm": 0.3329980671405792,
      "learning_rate": 1.4024195896544002e-05,
      "loss": 0.2825,
      "step": 19570
    },
    {
      "epoch": 2.491743819795743,
      "grad_norm": 0.4608778953552246,
      "learning_rate": 1.3955924257465614e-05,
      "loss": 0.302,
      "step": 19580
    },
    {
      "epoch": 2.493016448728962,
      "grad_norm": 0.2910730540752411,
      "learning_rate": 1.3887806733934949e-05,
      "loss": 0.2775,
      "step": 19590
    },
    {
      "epoch": 2.494289077662181,
      "grad_norm": 0.3939245939254761,
      "learning_rate": 1.3819843447958802e-05,
      "loss": 0.291,
      "step": 19600
    },
    {
      "epoch": 2.4955617065953994,
      "grad_norm": 0.3444286286830902,
      "learning_rate": 1.3752034521267853e-05,
      "loss": 0.2963,
      "step": 19610
    },
    {
      "epoch": 2.496834335528618,
      "grad_norm": 0.34543856978416443,
      "learning_rate": 1.3684380075316228e-05,
      "loss": 0.2824,
      "step": 19620
    },
    {
      "epoch": 2.498106964461837,
      "grad_norm": 0.3538183867931366,
      "learning_rate": 1.3616880231281393e-05,
      "loss": 0.2831,
      "step": 19630
    },
    {
      "epoch": 2.499379593395056,
      "grad_norm": 0.29983386397361755,
      "learning_rate": 1.3549535110063904e-05,
      "loss": 0.2895,
      "step": 19640
    },
    {
      "epoch": 2.5006522223282746,
      "grad_norm": 0.406948447227478,
      "learning_rate": 1.348234483228713e-05,
      "loss": 0.2915,
      "step": 19650
    },
    {
      "epoch": 2.5019248512614936,
      "grad_norm": 0.311290979385376,
      "learning_rate": 1.3415309518297192e-05,
      "loss": 0.3073,
      "step": 19660
    },
    {
      "epoch": 2.503197480194712,
      "grad_norm": 0.4237692058086395,
      "learning_rate": 1.3348429288162579e-05,
      "loss": 0.2983,
      "step": 19670
    },
    {
      "epoch": 2.504470109127931,
      "grad_norm": 0.3344190716743469,
      "learning_rate": 1.3281704261674e-05,
      "loss": 0.2979,
      "step": 19680
    },
    {
      "epoch": 2.5057427380611497,
      "grad_norm": 0.38476383686065674,
      "learning_rate": 1.3215134558344267e-05,
      "loss": 0.2964,
      "step": 19690
    },
    {
      "epoch": 2.5070153669943687,
      "grad_norm": 0.35563263297080994,
      "learning_rate": 1.314872029740789e-05,
      "loss": 0.3079,
      "step": 19700
    },
    {
      "epoch": 2.5082879959275877,
      "grad_norm": 0.3620019257068634,
      "learning_rate": 1.3082461597820994e-05,
      "loss": 0.3001,
      "step": 19710
    },
    {
      "epoch": 2.509560624860806,
      "grad_norm": 0.27495816349983215,
      "learning_rate": 1.3016358578261068e-05,
      "loss": 0.2846,
      "step": 19720
    },
    {
      "epoch": 2.5108332537940248,
      "grad_norm": 0.2938961386680603,
      "learning_rate": 1.295041135712679e-05,
      "loss": 0.3017,
      "step": 19730
    },
    {
      "epoch": 2.5121058827272438,
      "grad_norm": 0.31257522106170654,
      "learning_rate": 1.28846200525378e-05,
      "loss": 0.3145,
      "step": 19740
    },
    {
      "epoch": 2.5133785116604628,
      "grad_norm": 0.38869988918304443,
      "learning_rate": 1.2818984782334353e-05,
      "loss": 0.2976,
      "step": 19750
    },
    {
      "epoch": 2.5146511405936813,
      "grad_norm": 0.3488146960735321,
      "learning_rate": 1.2753505664077381e-05,
      "loss": 0.3062,
      "step": 19760
    },
    {
      "epoch": 2.5159237695269003,
      "grad_norm": 0.36679714918136597,
      "learning_rate": 1.2688182815048e-05,
      "loss": 0.2875,
      "step": 19770
    },
    {
      "epoch": 2.517196398460119,
      "grad_norm": 0.3845141530036926,
      "learning_rate": 1.2623016352247541e-05,
      "loss": 0.2834,
      "step": 19780
    },
    {
      "epoch": 2.518469027393338,
      "grad_norm": 0.3100506067276001,
      "learning_rate": 1.2558006392397138e-05,
      "loss": 0.2843,
      "step": 19790
    },
    {
      "epoch": 2.5197416563265564,
      "grad_norm": 0.33016514778137207,
      "learning_rate": 1.2493153051937633e-05,
      "loss": 0.2977,
      "step": 19800
    },
    {
      "epoch": 2.5210142852597754,
      "grad_norm": 0.3116278052330017,
      "learning_rate": 1.2428456447029401e-05,
      "loss": 0.2994,
      "step": 19810
    },
    {
      "epoch": 2.5222869141929944,
      "grad_norm": 0.3781552016735077,
      "learning_rate": 1.2363916693552013e-05,
      "loss": 0.3021,
      "step": 19820
    },
    {
      "epoch": 2.523559543126213,
      "grad_norm": 0.3920856714248657,
      "learning_rate": 1.2299533907104099e-05,
      "loss": 0.3138,
      "step": 19830
    },
    {
      "epoch": 2.5248321720594316,
      "grad_norm": 0.34015730023384094,
      "learning_rate": 1.2235308203003216e-05,
      "loss": 0.2978,
      "step": 19840
    },
    {
      "epoch": 2.5261048009926506,
      "grad_norm": 0.338074654340744,
      "learning_rate": 1.2171239696285485e-05,
      "loss": 0.2947,
      "step": 19850
    },
    {
      "epoch": 2.5273774299258696,
      "grad_norm": 0.27293574810028076,
      "learning_rate": 1.2107328501705518e-05,
      "loss": 0.3013,
      "step": 19860
    },
    {
      "epoch": 2.528650058859088,
      "grad_norm": 0.3821776807308197,
      "learning_rate": 1.2043574733736095e-05,
      "loss": 0.2947,
      "step": 19870
    },
    {
      "epoch": 2.529922687792307,
      "grad_norm": 0.3349429965019226,
      "learning_rate": 1.1979978506568146e-05,
      "loss": 0.2927,
      "step": 19880
    },
    {
      "epoch": 2.5311953167255257,
      "grad_norm": 0.3281308710575104,
      "learning_rate": 1.1916539934110326e-05,
      "loss": 0.283,
      "step": 19890
    },
    {
      "epoch": 2.5324679456587447,
      "grad_norm": 0.43564656376838684,
      "learning_rate": 1.1853259129988903e-05,
      "loss": 0.3017,
      "step": 19900
    },
    {
      "epoch": 2.5337405745919632,
      "grad_norm": 0.3386651575565338,
      "learning_rate": 1.1790136207547652e-05,
      "loss": 0.2986,
      "step": 19910
    },
    {
      "epoch": 2.5350132035251822,
      "grad_norm": 0.31988900899887085,
      "learning_rate": 1.1727171279847493e-05,
      "loss": 0.3063,
      "step": 19920
    },
    {
      "epoch": 2.536285832458401,
      "grad_norm": 0.3942606449127197,
      "learning_rate": 1.1664364459666355e-05,
      "loss": 0.304,
      "step": 19930
    },
    {
      "epoch": 2.53755846139162,
      "grad_norm": 0.3568371534347534,
      "learning_rate": 1.1601715859499018e-05,
      "loss": 0.2802,
      "step": 19940
    },
    {
      "epoch": 2.5388310903248383,
      "grad_norm": 0.31843993067741394,
      "learning_rate": 1.1539225591556824e-05,
      "loss": 0.2862,
      "step": 19950
    },
    {
      "epoch": 2.5401037192580573,
      "grad_norm": 0.4364248812198639,
      "learning_rate": 1.1476893767767605e-05,
      "loss": 0.2976,
      "step": 19960
    },
    {
      "epoch": 2.5413763481912763,
      "grad_norm": 0.36303016543388367,
      "learning_rate": 1.1414720499775255e-05,
      "loss": 0.2932,
      "step": 19970
    },
    {
      "epoch": 2.542648977124495,
      "grad_norm": 0.33963751792907715,
      "learning_rate": 1.135270589893982e-05,
      "loss": 0.2892,
      "step": 19980
    },
    {
      "epoch": 2.5439216060577134,
      "grad_norm": 0.3336695730686188,
      "learning_rate": 1.12908500763371e-05,
      "loss": 0.2928,
      "step": 19990
    },
    {
      "epoch": 2.5451942349909324,
      "grad_norm": 0.2820962369441986,
      "learning_rate": 1.1229153142758474e-05,
      "loss": 0.2996,
      "step": 20000
    },
    {
      "epoch": 2.5451942349909324,
      "eval_loss": 0.34079328179359436,
      "eval_runtime": 737.6634,
      "eval_samples_per_second": 10.653,
      "eval_steps_per_second": 5.326,
      "step": 20000
    },
    {
      "epoch": 2.5464668639241514,
      "grad_norm": 0.3289964497089386,
      "learning_rate": 1.1167615208710769e-05,
      "loss": 0.3157,
      "step": 20010
    },
    {
      "epoch": 2.54773949285737,
      "grad_norm": 0.27764755487442017,
      "learning_rate": 1.1106236384415992e-05,
      "loss": 0.2831,
      "step": 20020
    },
    {
      "epoch": 2.549012121790589,
      "grad_norm": 0.30482494831085205,
      "learning_rate": 1.1045016779811212e-05,
      "loss": 0.2953,
      "step": 20030
    },
    {
      "epoch": 2.5502847507238076,
      "grad_norm": 0.33786702156066895,
      "learning_rate": 1.0983956504548287e-05,
      "loss": 0.286,
      "step": 20040
    },
    {
      "epoch": 2.5515573796570266,
      "grad_norm": 0.476324200630188,
      "learning_rate": 1.0923055667993664e-05,
      "loss": 0.2967,
      "step": 20050
    },
    {
      "epoch": 2.552830008590245,
      "grad_norm": 0.378658264875412,
      "learning_rate": 1.086231437922829e-05,
      "loss": 0.3094,
      "step": 20060
    },
    {
      "epoch": 2.554102637523464,
      "grad_norm": 0.3850244879722595,
      "learning_rate": 1.0801732747047289e-05,
      "loss": 0.2974,
      "step": 20070
    },
    {
      "epoch": 2.555375266456683,
      "grad_norm": 0.3374052941799164,
      "learning_rate": 1.0741310879959809e-05,
      "loss": 0.3129,
      "step": 20080
    },
    {
      "epoch": 2.5566478953899017,
      "grad_norm": 0.39958298206329346,
      "learning_rate": 1.0681048886188893e-05,
      "loss": 0.3047,
      "step": 20090
    },
    {
      "epoch": 2.5579205243231202,
      "grad_norm": 0.2883579134941101,
      "learning_rate": 1.0620946873671177e-05,
      "loss": 0.2868,
      "step": 20100
    },
    {
      "epoch": 2.5591931532563392,
      "grad_norm": 0.3410539925098419,
      "learning_rate": 1.056100495005683e-05,
      "loss": 0.2998,
      "step": 20110
    },
    {
      "epoch": 2.5604657821895582,
      "grad_norm": 0.37256231904029846,
      "learning_rate": 1.0501223222709156e-05,
      "loss": 0.2844,
      "step": 20120
    },
    {
      "epoch": 2.561738411122777,
      "grad_norm": 0.35561031103134155,
      "learning_rate": 1.0441601798704615e-05,
      "loss": 0.3078,
      "step": 20130
    },
    {
      "epoch": 2.563011040055996,
      "grad_norm": 0.3458685576915741,
      "learning_rate": 1.0382140784832561e-05,
      "loss": 0.2959,
      "step": 20140
    },
    {
      "epoch": 2.5642836689892143,
      "grad_norm": 0.30340635776519775,
      "learning_rate": 1.0322840287594992e-05,
      "loss": 0.29,
      "step": 20150
    },
    {
      "epoch": 2.5655562979224333,
      "grad_norm": 0.31164270639419556,
      "learning_rate": 1.02637004132064e-05,
      "loss": 0.2969,
      "step": 20160
    },
    {
      "epoch": 2.566828926855652,
      "grad_norm": 0.6274603605270386,
      "learning_rate": 1.0204721267593564e-05,
      "loss": 0.2881,
      "step": 20170
    },
    {
      "epoch": 2.568101555788871,
      "grad_norm": 0.31443989276885986,
      "learning_rate": 1.014590295639546e-05,
      "loss": 0.2942,
      "step": 20180
    },
    {
      "epoch": 2.56937418472209,
      "grad_norm": 0.3260584771633148,
      "learning_rate": 1.008724558496289e-05,
      "loss": 0.2996,
      "step": 20190
    },
    {
      "epoch": 2.5706468136553084,
      "grad_norm": 0.41113144159317017,
      "learning_rate": 1.0028749258358449e-05,
      "loss": 0.3001,
      "step": 20200
    },
    {
      "epoch": 2.571919442588527,
      "grad_norm": 0.31486156582832336,
      "learning_rate": 9.970414081356293e-06,
      "loss": 0.3034,
      "step": 20210
    },
    {
      "epoch": 2.573192071521746,
      "grad_norm": 0.2995639443397522,
      "learning_rate": 9.912240158441888e-06,
      "loss": 0.2934,
      "step": 20220
    },
    {
      "epoch": 2.574464700454965,
      "grad_norm": 0.2810814678668976,
      "learning_rate": 9.854227593811904e-06,
      "loss": 0.2936,
      "step": 20230
    },
    {
      "epoch": 2.5757373293881836,
      "grad_norm": 0.33916470408439636,
      "learning_rate": 9.796376491374015e-06,
      "loss": 0.2865,
      "step": 20240
    },
    {
      "epoch": 2.5770099583214026,
      "grad_norm": 0.36906400322914124,
      "learning_rate": 9.738686954746667e-06,
      "loss": 0.2944,
      "step": 20250
    },
    {
      "epoch": 2.578282587254621,
      "grad_norm": 0.3875581920146942,
      "learning_rate": 9.68115908725894e-06,
      "loss": 0.2849,
      "step": 20260
    },
    {
      "epoch": 2.57955521618784,
      "grad_norm": 0.32331252098083496,
      "learning_rate": 9.623792991950309e-06,
      "loss": 0.2933,
      "step": 20270
    },
    {
      "epoch": 2.5808278451210587,
      "grad_norm": 0.3852497637271881,
      "learning_rate": 9.56658877157054e-06,
      "loss": 0.3114,
      "step": 20280
    },
    {
      "epoch": 2.5821004740542777,
      "grad_norm": 0.35777539014816284,
      "learning_rate": 9.509546528579495e-06,
      "loss": 0.2949,
      "step": 20290
    },
    {
      "epoch": 2.5833731029874967,
      "grad_norm": 0.3519868552684784,
      "learning_rate": 9.452666365146768e-06,
      "loss": 0.3013,
      "step": 20300
    },
    {
      "epoch": 2.5846457319207152,
      "grad_norm": 0.39323002099990845,
      "learning_rate": 9.395948383151809e-06,
      "loss": 0.2991,
      "step": 20310
    },
    {
      "epoch": 2.585918360853934,
      "grad_norm": 0.3917839527130127,
      "learning_rate": 9.33939268418349e-06,
      "loss": 0.3115,
      "step": 20320
    },
    {
      "epoch": 2.587190989787153,
      "grad_norm": 0.28783926367759705,
      "learning_rate": 9.282999369540058e-06,
      "loss": 0.3048,
      "step": 20330
    },
    {
      "epoch": 2.588463618720372,
      "grad_norm": 0.33517736196517944,
      "learning_rate": 9.226768540228891e-06,
      "loss": 0.3119,
      "step": 20340
    },
    {
      "epoch": 2.5897362476535903,
      "grad_norm": 0.32425224781036377,
      "learning_rate": 9.170700296966318e-06,
      "loss": 0.2997,
      "step": 20350
    },
    {
      "epoch": 2.5910088765868093,
      "grad_norm": 0.4196406602859497,
      "learning_rate": 9.114794740177501e-06,
      "loss": 0.2972,
      "step": 20360
    },
    {
      "epoch": 2.592281505520028,
      "grad_norm": 0.3940146863460541,
      "learning_rate": 9.059051969996168e-06,
      "loss": 0.3151,
      "step": 20370
    },
    {
      "epoch": 2.593554134453247,
      "grad_norm": 0.33423835039138794,
      "learning_rate": 9.003472086264474e-06,
      "loss": 0.2815,
      "step": 20380
    },
    {
      "epoch": 2.5948267633864655,
      "grad_norm": 0.32980412244796753,
      "learning_rate": 8.948055188532888e-06,
      "loss": 0.2998,
      "step": 20390
    },
    {
      "epoch": 2.5960993923196845,
      "grad_norm": 0.35723450779914856,
      "learning_rate": 8.892801376059879e-06,
      "loss": 0.304,
      "step": 20400
    },
    {
      "epoch": 2.5973720212529035,
      "grad_norm": 0.4276469945907593,
      "learning_rate": 8.837710747811844e-06,
      "loss": 0.2901,
      "step": 20410
    },
    {
      "epoch": 2.598644650186122,
      "grad_norm": 0.3518856167793274,
      "learning_rate": 8.782783402462868e-06,
      "loss": 0.303,
      "step": 20420
    },
    {
      "epoch": 2.5999172791193406,
      "grad_norm": 0.31613537669181824,
      "learning_rate": 8.72801943839462e-06,
      "loss": 0.3183,
      "step": 20430
    },
    {
      "epoch": 2.6011899080525596,
      "grad_norm": 0.28525272011756897,
      "learning_rate": 8.673418953696133e-06,
      "loss": 0.3002,
      "step": 20440
    },
    {
      "epoch": 2.6024625369857786,
      "grad_norm": 0.3394222557544708,
      "learning_rate": 8.618982046163559e-06,
      "loss": 0.3131,
      "step": 20450
    },
    {
      "epoch": 2.603735165918997,
      "grad_norm": 0.28273671865463257,
      "learning_rate": 8.564708813300148e-06,
      "loss": 0.302,
      "step": 20460
    },
    {
      "epoch": 2.605007794852216,
      "grad_norm": 0.2896168529987335,
      "learning_rate": 8.510599352315918e-06,
      "loss": 0.3005,
      "step": 20470
    },
    {
      "epoch": 2.6062804237854347,
      "grad_norm": 0.3480304777622223,
      "learning_rate": 8.456653760127619e-06,
      "loss": 0.3003,
      "step": 20480
    },
    {
      "epoch": 2.6075530527186537,
      "grad_norm": 0.2830723524093628,
      "learning_rate": 8.402872133358442e-06,
      "loss": 0.2842,
      "step": 20490
    },
    {
      "epoch": 2.6088256816518722,
      "grad_norm": 0.3399152457714081,
      "learning_rate": 8.349254568337894e-06,
      "loss": 0.2896,
      "step": 20500
    },
    {
      "epoch": 2.6088256816518722,
      "eval_loss": 0.3402363955974579,
      "eval_runtime": 760.7609,
      "eval_samples_per_second": 10.329,
      "eval_steps_per_second": 5.165,
      "step": 20500
    },
    {
      "epoch": 2.6100983105850912,
      "grad_norm": 0.29220059514045715,
      "learning_rate": 8.29580116110168e-06,
      "loss": 0.2791,
      "step": 20510
    },
    {
      "epoch": 2.61137093951831,
      "grad_norm": 0.35360923409461975,
      "learning_rate": 8.242512007391412e-06,
      "loss": 0.2896,
      "step": 20520
    },
    {
      "epoch": 2.612643568451529,
      "grad_norm": 0.26492542028427124,
      "learning_rate": 8.189387202654541e-06,
      "loss": 0.2765,
      "step": 20530
    },
    {
      "epoch": 2.6139161973847473,
      "grad_norm": 0.3527347147464752,
      "learning_rate": 8.136426842044154e-06,
      "loss": 0.2635,
      "step": 20540
    },
    {
      "epoch": 2.6151888263179663,
      "grad_norm": 0.285941481590271,
      "learning_rate": 8.083631020418791e-06,
      "loss": 0.2799,
      "step": 20550
    },
    {
      "epoch": 2.6164614552511853,
      "grad_norm": 0.2747575342655182,
      "learning_rate": 8.030999832342256e-06,
      "loss": 0.2712,
      "step": 20560
    },
    {
      "epoch": 2.617734084184404,
      "grad_norm": 0.26487332582473755,
      "learning_rate": 7.978533372083485e-06,
      "loss": 0.2562,
      "step": 20570
    },
    {
      "epoch": 2.6190067131176225,
      "grad_norm": 0.3290053904056549,
      "learning_rate": 7.926231733616406e-06,
      "loss": 0.281,
      "step": 20580
    },
    {
      "epoch": 2.6202793420508415,
      "grad_norm": 0.38633742928504944,
      "learning_rate": 7.874095010619719e-06,
      "loss": 0.2957,
      "step": 20590
    },
    {
      "epoch": 2.6215519709840605,
      "grad_norm": 0.30940771102905273,
      "learning_rate": 7.822123296476658e-06,
      "loss": 0.2787,
      "step": 20600
    },
    {
      "epoch": 2.622824599917279,
      "grad_norm": 0.3335129916667938,
      "learning_rate": 7.770316684275026e-06,
      "loss": 0.2878,
      "step": 20610
    },
    {
      "epoch": 2.624097228850498,
      "grad_norm": 0.2951299846172333,
      "learning_rate": 7.718675266806818e-06,
      "loss": 0.2728,
      "step": 20620
    },
    {
      "epoch": 2.6253698577837166,
      "grad_norm": 0.5402606129646301,
      "learning_rate": 7.667199136568215e-06,
      "loss": 0.2698,
      "step": 20630
    },
    {
      "epoch": 2.6266424867169356,
      "grad_norm": 0.2826732397079468,
      "learning_rate": 7.6158883857592955e-06,
      "loss": 0.2718,
      "step": 20640
    },
    {
      "epoch": 2.627915115650154,
      "grad_norm": 0.33194005489349365,
      "learning_rate": 7.564743106283911e-06,
      "loss": 0.2736,
      "step": 20650
    },
    {
      "epoch": 2.629187744583373,
      "grad_norm": 0.3467321991920471,
      "learning_rate": 7.513763389749617e-06,
      "loss": 0.2699,
      "step": 20660
    },
    {
      "epoch": 2.630460373516592,
      "grad_norm": 0.3498910963535309,
      "learning_rate": 7.462949327467339e-06,
      "loss": 0.2894,
      "step": 20670
    },
    {
      "epoch": 2.6317330024498107,
      "grad_norm": 0.3562018871307373,
      "learning_rate": 7.412301010451317e-06,
      "loss": 0.2643,
      "step": 20680
    },
    {
      "epoch": 2.6330056313830292,
      "grad_norm": 0.3527182340621948,
      "learning_rate": 7.361818529418951e-06,
      "loss": 0.277,
      "step": 20690
    },
    {
      "epoch": 2.6342782603162482,
      "grad_norm": 0.30588918924331665,
      "learning_rate": 7.311501974790591e-06,
      "loss": 0.2692,
      "step": 20700
    },
    {
      "epoch": 2.6355508892494672,
      "grad_norm": 0.37796708941459656,
      "learning_rate": 7.261351436689379e-06,
      "loss": 0.287,
      "step": 20710
    },
    {
      "epoch": 2.636823518182686,
      "grad_norm": 0.2942619323730469,
      "learning_rate": 7.2113670049411055e-06,
      "loss": 0.2727,
      "step": 20720
    },
    {
      "epoch": 2.638096147115905,
      "grad_norm": 0.3044329583644867,
      "learning_rate": 7.161548769074066e-06,
      "loss": 0.2638,
      "step": 20730
    },
    {
      "epoch": 2.6393687760491233,
      "grad_norm": 0.3923649489879608,
      "learning_rate": 7.1118968183188526e-06,
      "loss": 0.2857,
      "step": 20740
    },
    {
      "epoch": 2.6406414049823423,
      "grad_norm": 0.2887023389339447,
      "learning_rate": 7.062411241608225e-06,
      "loss": 0.2459,
      "step": 20750
    },
    {
      "epoch": 2.641914033915561,
      "grad_norm": 0.3042055666446686,
      "learning_rate": 7.01309212757697e-06,
      "loss": 0.2686,
      "step": 20760
    },
    {
      "epoch": 2.64318666284878,
      "grad_norm": 0.3822101652622223,
      "learning_rate": 6.963939564561694e-06,
      "loss": 0.286,
      "step": 20770
    },
    {
      "epoch": 2.644459291781999,
      "grad_norm": 0.3580130934715271,
      "learning_rate": 6.9149536406006745e-06,
      "loss": 0.2851,
      "step": 20780
    },
    {
      "epoch": 2.6457319207152175,
      "grad_norm": 0.27641427516937256,
      "learning_rate": 6.866134443433781e-06,
      "loss": 0.2803,
      "step": 20790
    },
    {
      "epoch": 2.647004549648436,
      "grad_norm": 0.3371839225292206,
      "learning_rate": 6.817482060502178e-06,
      "loss": 0.2879,
      "step": 20800
    },
    {
      "epoch": 2.648277178581655,
      "grad_norm": 0.27961495518684387,
      "learning_rate": 6.768996578948328e-06,
      "loss": 0.2644,
      "step": 20810
    },
    {
      "epoch": 2.649549807514874,
      "grad_norm": 0.27490630745887756,
      "learning_rate": 6.7206780856156505e-06,
      "loss": 0.2675,
      "step": 20820
    },
    {
      "epoch": 2.6508224364480926,
      "grad_norm": 0.40297555923461914,
      "learning_rate": 6.6725266670485396e-06,
      "loss": 0.2741,
      "step": 20830
    },
    {
      "epoch": 2.6520950653813116,
      "grad_norm": 0.29893338680267334,
      "learning_rate": 6.624542409492151e-06,
      "loss": 0.2643,
      "step": 20840
    },
    {
      "epoch": 2.65336769431453,
      "grad_norm": 0.43278366327285767,
      "learning_rate": 6.576725398892181e-06,
      "loss": 0.2683,
      "step": 20850
    },
    {
      "epoch": 2.654640323247749,
      "grad_norm": 0.37920087575912476,
      "learning_rate": 6.529075720894806e-06,
      "loss": 0.2739,
      "step": 20860
    },
    {
      "epoch": 2.6559129521809677,
      "grad_norm": 0.32655853033065796,
      "learning_rate": 6.481593460846436e-06,
      "loss": 0.2652,
      "step": 20870
    },
    {
      "epoch": 2.6571855811141867,
      "grad_norm": 0.3620853126049042,
      "learning_rate": 6.434278703793706e-06,
      "loss": 0.2599,
      "step": 20880
    },
    {
      "epoch": 2.6584582100474057,
      "grad_norm": 0.342377245426178,
      "learning_rate": 6.387131534483148e-06,
      "loss": 0.2896,
      "step": 20890
    },
    {
      "epoch": 2.6597308389806242,
      "grad_norm": 0.26464974880218506,
      "learning_rate": 6.340152037361158e-06,
      "loss": 0.2648,
      "step": 20900
    },
    {
      "epoch": 2.661003467913843,
      "grad_norm": 0.35962358117103577,
      "learning_rate": 6.293340296573813e-06,
      "loss": 0.2737,
      "step": 20910
    },
    {
      "epoch": 2.662276096847062,
      "grad_norm": 0.3179216682910919,
      "learning_rate": 6.2466963959667115e-06,
      "loss": 0.2664,
      "step": 20920
    },
    {
      "epoch": 2.663548725780281,
      "grad_norm": 0.3572334349155426,
      "learning_rate": 6.2002204190848126e-06,
      "loss": 0.275,
      "step": 20930
    },
    {
      "epoch": 2.6648213547134993,
      "grad_norm": 0.315774530172348,
      "learning_rate": 6.15391244917235e-06,
      "loss": 0.2847,
      "step": 20940
    },
    {
      "epoch": 2.6660939836467183,
      "grad_norm": 0.3516954183578491,
      "learning_rate": 6.107772569172576e-06,
      "loss": 0.2744,
      "step": 20950
    },
    {
      "epoch": 2.667366612579937,
      "grad_norm": 0.31827881932258606,
      "learning_rate": 6.061800861727751e-06,
      "loss": 0.2776,
      "step": 20960
    },
    {
      "epoch": 2.668639241513156,
      "grad_norm": 0.3373982906341553,
      "learning_rate": 6.0159974091788086e-06,
      "loss": 0.2813,
      "step": 20970
    },
    {
      "epoch": 2.6699118704463745,
      "grad_norm": 0.3205452561378479,
      "learning_rate": 5.970362293565423e-06,
      "loss": 0.2661,
      "step": 20980
    },
    {
      "epoch": 2.6711844993795935,
      "grad_norm": 0.3368335962295532,
      "learning_rate": 5.924895596625701e-06,
      "loss": 0.275,
      "step": 20990
    },
    {
      "epoch": 2.6724571283128125,
      "grad_norm": 0.2630840241909027,
      "learning_rate": 5.879597399796111e-06,
      "loss": 0.2632,
      "step": 21000
    },
    {
      "epoch": 2.6724571283128125,
      "eval_loss": 0.3448910415172577,
      "eval_runtime": 751.4082,
      "eval_samples_per_second": 10.458,
      "eval_steps_per_second": 5.229,
      "step": 21000
    },
    {
      "epoch": 2.673729757246031,
      "grad_norm": 0.43540382385253906,
      "learning_rate": 5.834467784211295e-06,
      "loss": 0.2784,
      "step": 21010
    },
    {
      "epoch": 2.6750023861792496,
      "grad_norm": 0.2826651930809021,
      "learning_rate": 5.789506830703939e-06,
      "loss": 0.279,
      "step": 21020
    },
    {
      "epoch": 2.6762750151124686,
      "grad_norm": 0.29836708307266235,
      "learning_rate": 5.744714619804703e-06,
      "loss": 0.2579,
      "step": 21030
    },
    {
      "epoch": 2.6775476440456876,
      "grad_norm": 0.38087478280067444,
      "learning_rate": 5.700091231741933e-06,
      "loss": 0.273,
      "step": 21040
    },
    {
      "epoch": 2.678820272978906,
      "grad_norm": 0.35662469267845154,
      "learning_rate": 5.655636746441595e-06,
      "loss": 0.2707,
      "step": 21050
    },
    {
      "epoch": 2.680092901912125,
      "grad_norm": 0.3497284948825836,
      "learning_rate": 5.611351243527196e-06,
      "loss": 0.2828,
      "step": 21060
    },
    {
      "epoch": 2.6813655308453437,
      "grad_norm": 0.3493373394012451,
      "learning_rate": 5.56723480231951e-06,
      "loss": 0.2899,
      "step": 21070
    },
    {
      "epoch": 2.6826381597785627,
      "grad_norm": 0.41147518157958984,
      "learning_rate": 5.523287501836516e-06,
      "loss": 0.2812,
      "step": 21080
    },
    {
      "epoch": 2.6839107887117812,
      "grad_norm": 0.33384016156196594,
      "learning_rate": 5.47950942079326e-06,
      "loss": 0.278,
      "step": 21090
    },
    {
      "epoch": 2.6851834176450002,
      "grad_norm": 0.3011333644390106,
      "learning_rate": 5.435900637601677e-06,
      "loss": 0.2681,
      "step": 21100
    },
    {
      "epoch": 2.686456046578219,
      "grad_norm": 0.3630550503730774,
      "learning_rate": 5.392461230370483e-06,
      "loss": 0.2657,
      "step": 21110
    },
    {
      "epoch": 2.687728675511438,
      "grad_norm": 0.382179856300354,
      "learning_rate": 5.349191276904986e-06,
      "loss": 0.2675,
      "step": 21120
    },
    {
      "epoch": 2.6890013044446563,
      "grad_norm": 0.312442809343338,
      "learning_rate": 5.306090854707013e-06,
      "loss": 0.2629,
      "step": 21130
    },
    {
      "epoch": 2.6902739333778753,
      "grad_norm": 0.3798138499259949,
      "learning_rate": 5.263160040974791e-06,
      "loss": 0.2753,
      "step": 21140
    },
    {
      "epoch": 2.6915465623110943,
      "grad_norm": 0.3445439338684082,
      "learning_rate": 5.22039891260262e-06,
      "loss": 0.2593,
      "step": 21150
    },
    {
      "epoch": 2.692819191244313,
      "grad_norm": 0.3638932704925537,
      "learning_rate": 5.1778075461809794e-06,
      "loss": 0.2748,
      "step": 21160
    },
    {
      "epoch": 2.6940918201775315,
      "grad_norm": 0.3687385022640228,
      "learning_rate": 5.135386017996291e-06,
      "loss": 0.2586,
      "step": 21170
    },
    {
      "epoch": 2.6953644491107505,
      "grad_norm": 0.414798378944397,
      "learning_rate": 5.093134404030709e-06,
      "loss": 0.273,
      "step": 21180
    },
    {
      "epoch": 2.6966370780439695,
      "grad_norm": 0.336753249168396,
      "learning_rate": 5.051052779962084e-06,
      "loss": 0.2619,
      "step": 21190
    },
    {
      "epoch": 2.697909706977188,
      "grad_norm": 0.26257699728012085,
      "learning_rate": 5.009141221163794e-06,
      "loss": 0.2752,
      "step": 21200
    },
    {
      "epoch": 2.699182335910407,
      "grad_norm": 0.37780171632766724,
      "learning_rate": 4.96739980270462e-06,
      "loss": 0.2805,
      "step": 21210
    },
    {
      "epoch": 2.7004549648436256,
      "grad_norm": 0.3617755174636841,
      "learning_rate": 4.925828599348592e-06,
      "loss": 0.2679,
      "step": 21220
    },
    {
      "epoch": 2.7017275937768446,
      "grad_norm": 0.37793394923210144,
      "learning_rate": 4.884427685554827e-06,
      "loss": 0.2892,
      "step": 21230
    },
    {
      "epoch": 2.703000222710063,
      "grad_norm": 0.4078989326953888,
      "learning_rate": 4.843197135477506e-06,
      "loss": 0.2748,
      "step": 21240
    },
    {
      "epoch": 2.704272851643282,
      "grad_norm": 0.2803001403808594,
      "learning_rate": 4.802137022965602e-06,
      "loss": 0.257,
      "step": 21250
    },
    {
      "epoch": 2.705545480576501,
      "grad_norm": 0.34758102893829346,
      "learning_rate": 4.761247421562843e-06,
      "loss": 0.2963,
      "step": 21260
    },
    {
      "epoch": 2.7068181095097197,
      "grad_norm": 0.3312956988811493,
      "learning_rate": 4.7205284045075515e-06,
      "loss": 0.2874,
      "step": 21270
    },
    {
      "epoch": 2.7080907384429382,
      "grad_norm": 0.3440968990325928,
      "learning_rate": 4.6799800447325015e-06,
      "loss": 0.2665,
      "step": 21280
    },
    {
      "epoch": 2.7093633673761572,
      "grad_norm": 0.3520441949367523,
      "learning_rate": 4.63960241486483e-06,
      "loss": 0.2922,
      "step": 21290
    },
    {
      "epoch": 2.7106359963093762,
      "grad_norm": 0.6861677169799805,
      "learning_rate": 4.599395587225808e-06,
      "loss": 0.2809,
      "step": 21300
    },
    {
      "epoch": 2.711908625242595,
      "grad_norm": 0.3498231768608093,
      "learning_rate": 4.559359633830829e-06,
      "loss": 0.2731,
      "step": 21310
    },
    {
      "epoch": 2.713181254175814,
      "grad_norm": 0.35958805680274963,
      "learning_rate": 4.5194946263892534e-06,
      "loss": 0.2835,
      "step": 21320
    },
    {
      "epoch": 2.7144538831090324,
      "grad_norm": 0.40390753746032715,
      "learning_rate": 4.47980063630421e-06,
      "loss": 0.2717,
      "step": 21330
    },
    {
      "epoch": 2.7157265120422514,
      "grad_norm": 0.30105215311050415,
      "learning_rate": 4.440277734672516e-06,
      "loss": 0.2785,
      "step": 21340
    },
    {
      "epoch": 2.71699914097547,
      "grad_norm": 0.31168800592422485,
      "learning_rate": 4.400925992284555e-06,
      "loss": 0.2899,
      "step": 21350
    },
    {
      "epoch": 2.718271769908689,
      "grad_norm": 0.36723482608795166,
      "learning_rate": 4.36174547962418e-06,
      "loss": 0.2767,
      "step": 21360
    },
    {
      "epoch": 2.719544398841908,
      "grad_norm": 0.34254252910614014,
      "learning_rate": 4.322736266868488e-06,
      "loss": 0.2708,
      "step": 21370
    },
    {
      "epoch": 2.7208170277751265,
      "grad_norm": 0.35118645429611206,
      "learning_rate": 4.2838984238878e-06,
      "loss": 0.2677,
      "step": 21380
    },
    {
      "epoch": 2.722089656708345,
      "grad_norm": 0.4076402485370636,
      "learning_rate": 4.245232020245493e-06,
      "loss": 0.2793,
      "step": 21390
    },
    {
      "epoch": 2.723362285641564,
      "grad_norm": 0.30405929684638977,
      "learning_rate": 4.206737125197857e-06,
      "loss": 0.2759,
      "step": 21400
    },
    {
      "epoch": 2.724634914574783,
      "grad_norm": 0.2938470244407654,
      "learning_rate": 4.168413807693972e-06,
      "loss": 0.2914,
      "step": 21410
    },
    {
      "epoch": 2.7259075435080016,
      "grad_norm": 0.32258012890815735,
      "learning_rate": 4.1302621363756624e-06,
      "loss": 0.2789,
      "step": 21420
    },
    {
      "epoch": 2.7271801724412206,
      "grad_norm": 0.3384822905063629,
      "learning_rate": 4.092282179577245e-06,
      "loss": 0.2785,
      "step": 21430
    },
    {
      "epoch": 2.728452801374439,
      "grad_norm": 0.387988805770874,
      "learning_rate": 4.054474005325526e-06,
      "loss": 0.2719,
      "step": 21440
    },
    {
      "epoch": 2.729725430307658,
      "grad_norm": 0.38347408175468445,
      "learning_rate": 4.016837681339581e-06,
      "loss": 0.268,
      "step": 21450
    },
    {
      "epoch": 2.7309980592408767,
      "grad_norm": 0.3981574475765228,
      "learning_rate": 3.979373275030718e-06,
      "loss": 0.2828,
      "step": 21460
    },
    {
      "epoch": 2.7322706881740957,
      "grad_norm": 0.31954479217529297,
      "learning_rate": 3.942080853502328e-06,
      "loss": 0.2832,
      "step": 21470
    },
    {
      "epoch": 2.7335433171073147,
      "grad_norm": 0.3577909767627716,
      "learning_rate": 3.904960483549713e-06,
      "loss": 0.2785,
      "step": 21480
    },
    {
      "epoch": 2.7348159460405332,
      "grad_norm": 0.3346421718597412,
      "learning_rate": 3.868012231660045e-06,
      "loss": 0.2764,
      "step": 21490
    },
    {
      "epoch": 2.736088574973752,
      "grad_norm": 0.3802529573440552,
      "learning_rate": 3.831236164012164e-06,
      "loss": 0.2852,
      "step": 21500
    },
    {
      "epoch": 2.736088574973752,
      "eval_loss": 0.34518375992774963,
      "eval_runtime": 767.2416,
      "eval_samples_per_second": 10.242,
      "eval_steps_per_second": 5.121,
      "step": 21500
    },
    {
      "epoch": 2.737361203906971,
      "grad_norm": 0.4088115394115448,
      "learning_rate": 3.7946323464766007e-06,
      "loss": 0.2811,
      "step": 21510
    },
    {
      "epoch": 2.73863383284019,
      "grad_norm": 0.4209185242652893,
      "learning_rate": 3.7582008446152563e-06,
      "loss": 0.2725,
      "step": 21520
    },
    {
      "epoch": 2.7399064617734084,
      "grad_norm": 0.2531423270702362,
      "learning_rate": 3.7219417236814547e-06,
      "loss": 0.2756,
      "step": 21530
    },
    {
      "epoch": 2.7411790907066274,
      "grad_norm": 0.4204346835613251,
      "learning_rate": 3.6858550486197686e-06,
      "loss": 0.2882,
      "step": 21540
    },
    {
      "epoch": 2.742451719639846,
      "grad_norm": 0.416826069355011,
      "learning_rate": 3.649940884065861e-06,
      "loss": 0.2693,
      "step": 21550
    },
    {
      "epoch": 2.743724348573065,
      "grad_norm": 0.3160973787307739,
      "learning_rate": 3.614199294346421e-06,
      "loss": 0.2763,
      "step": 21560
    },
    {
      "epoch": 2.7449969775062835,
      "grad_norm": 0.36551615595817566,
      "learning_rate": 3.5786303434790835e-06,
      "loss": 0.2818,
      "step": 21570
    },
    {
      "epoch": 2.7462696064395025,
      "grad_norm": 0.3698015809059143,
      "learning_rate": 3.5432340951721877e-06,
      "loss": 0.2791,
      "step": 21580
    },
    {
      "epoch": 2.7475422353727215,
      "grad_norm": 0.44099900126457214,
      "learning_rate": 3.5080106128247967e-06,
      "loss": 0.3023,
      "step": 21590
    },
    {
      "epoch": 2.74881486430594,
      "grad_norm": 0.33158817887306213,
      "learning_rate": 3.472959959526478e-06,
      "loss": 0.2826,
      "step": 21600
    },
    {
      "epoch": 2.7500874932391586,
      "grad_norm": 0.4080296456813812,
      "learning_rate": 3.438082198057313e-06,
      "loss": 0.3069,
      "step": 21610
    },
    {
      "epoch": 2.7513601221723776,
      "grad_norm": 0.32300639152526855,
      "learning_rate": 3.4033773908876632e-06,
      "loss": 0.2801,
      "step": 21620
    },
    {
      "epoch": 2.7526327511055966,
      "grad_norm": 0.3351132869720459,
      "learning_rate": 3.3688456001780943e-06,
      "loss": 0.2627,
      "step": 21630
    },
    {
      "epoch": 2.753905380038815,
      "grad_norm": 0.40440645813941956,
      "learning_rate": 3.3344868877793313e-06,
      "loss": 0.2703,
      "step": 21640
    },
    {
      "epoch": 2.755178008972034,
      "grad_norm": 0.3186783194541931,
      "learning_rate": 3.300301315232035e-06,
      "loss": 0.2686,
      "step": 21650
    },
    {
      "epoch": 2.7564506379052527,
      "grad_norm": 0.34336456656455994,
      "learning_rate": 3.2662889437668043e-06,
      "loss": 0.2939,
      "step": 21660
    },
    {
      "epoch": 2.7577232668384717,
      "grad_norm": 0.30976319313049316,
      "learning_rate": 3.2324498343039856e-06,
      "loss": 0.2908,
      "step": 21670
    },
    {
      "epoch": 2.7589958957716902,
      "grad_norm": 0.3686632513999939,
      "learning_rate": 3.1987840474535735e-06,
      "loss": 0.2763,
      "step": 21680
    },
    {
      "epoch": 2.7602685247049092,
      "grad_norm": 0.3527701497077942,
      "learning_rate": 3.165291643515178e-06,
      "loss": 0.2623,
      "step": 21690
    },
    {
      "epoch": 2.761541153638128,
      "grad_norm": 0.35951218008995056,
      "learning_rate": 3.1319726824778016e-06,
      "loss": 0.2837,
      "step": 21700
    },
    {
      "epoch": 2.762813782571347,
      "grad_norm": 0.32725340127944946,
      "learning_rate": 3.098827224019796e-06,
      "loss": 0.2745,
      "step": 21710
    },
    {
      "epoch": 2.7640864115045654,
      "grad_norm": 0.3822457194328308,
      "learning_rate": 3.0658553275088042e-06,
      "loss": 0.276,
      "step": 21720
    },
    {
      "epoch": 2.7653590404377844,
      "grad_norm": 0.30420687794685364,
      "learning_rate": 3.0330570520015313e-06,
      "loss": 0.2846,
      "step": 21730
    },
    {
      "epoch": 2.7666316693710034,
      "grad_norm": 0.34616491198539734,
      "learning_rate": 3.00043245624374e-06,
      "loss": 0.2976,
      "step": 21740
    },
    {
      "epoch": 2.767904298304222,
      "grad_norm": 0.34602251648902893,
      "learning_rate": 2.9679815986700888e-06,
      "loss": 0.2746,
      "step": 21750
    },
    {
      "epoch": 2.7691769272374405,
      "grad_norm": 0.3372708261013031,
      "learning_rate": 2.9357045374040825e-06,
      "loss": 0.2882,
      "step": 21760
    },
    {
      "epoch": 2.7704495561706595,
      "grad_norm": 0.2813640534877777,
      "learning_rate": 2.903601330257921e-06,
      "loss": 0.2629,
      "step": 21770
    },
    {
      "epoch": 2.7717221851038785,
      "grad_norm": 0.3405545949935913,
      "learning_rate": 2.8716720347323866e-06,
      "loss": 0.2838,
      "step": 21780
    },
    {
      "epoch": 2.772994814037097,
      "grad_norm": 0.31495940685272217,
      "learning_rate": 2.8399167080167875e-06,
      "loss": 0.2809,
      "step": 21790
    },
    {
      "epoch": 2.774267442970316,
      "grad_norm": 0.33517390489578247,
      "learning_rate": 2.808335406988838e-06,
      "loss": 0.2713,
      "step": 21800
    },
    {
      "epoch": 2.7755400719035346,
      "grad_norm": 0.3208374083042145,
      "learning_rate": 2.7769281882145448e-06,
      "loss": 0.279,
      "step": 21810
    },
    {
      "epoch": 2.7768127008367536,
      "grad_norm": 0.3104743957519531,
      "learning_rate": 2.7456951079481098e-06,
      "loss": 0.2788,
      "step": 21820
    },
    {
      "epoch": 2.778085329769972,
      "grad_norm": 0.33224496245384216,
      "learning_rate": 2.7146362221318057e-06,
      "loss": 0.266,
      "step": 21830
    },
    {
      "epoch": 2.779357958703191,
      "grad_norm": 0.3179408311843872,
      "learning_rate": 2.683751586395955e-06,
      "loss": 0.2962,
      "step": 21840
    },
    {
      "epoch": 2.78063058763641,
      "grad_norm": 0.3472476899623871,
      "learning_rate": 2.6530412560587303e-06,
      "loss": 0.2781,
      "step": 21850
    },
    {
      "epoch": 2.7819032165696287,
      "grad_norm": 0.34531712532043457,
      "learning_rate": 2.62250528612612e-06,
      "loss": 0.2723,
      "step": 21860
    },
    {
      "epoch": 2.7831758455028472,
      "grad_norm": 0.35465964674949646,
      "learning_rate": 2.5921437312918296e-06,
      "loss": 0.2875,
      "step": 21870
    },
    {
      "epoch": 2.7844484744360662,
      "grad_norm": 0.27983254194259644,
      "learning_rate": 2.5619566459371356e-06,
      "loss": 0.2689,
      "step": 21880
    },
    {
      "epoch": 2.7857211033692852,
      "grad_norm": 0.3927669823169708,
      "learning_rate": 2.531944084130822e-06,
      "loss": 0.2598,
      "step": 21890
    },
    {
      "epoch": 2.786993732302504,
      "grad_norm": 0.3278830349445343,
      "learning_rate": 2.5021060996290866e-06,
      "loss": 0.2738,
      "step": 21900
    },
    {
      "epoch": 2.788266361235723,
      "grad_norm": 0.3892093896865845,
      "learning_rate": 2.4724427458754583e-06,
      "loss": 0.2692,
      "step": 21910
    },
    {
      "epoch": 2.7895389901689414,
      "grad_norm": 0.3718089163303375,
      "learning_rate": 2.4429540760006366e-06,
      "loss": 0.2807,
      "step": 21920
    },
    {
      "epoch": 2.7908116191021604,
      "grad_norm": 0.3514932692050934,
      "learning_rate": 2.413640142822471e-06,
      "loss": 0.2698,
      "step": 21930
    },
    {
      "epoch": 2.792084248035379,
      "grad_norm": 0.4080818295478821,
      "learning_rate": 2.384500998845851e-06,
      "loss": 0.2799,
      "step": 21940
    },
    {
      "epoch": 2.793356876968598,
      "grad_norm": 0.29539838433265686,
      "learning_rate": 2.3555366962625504e-06,
      "loss": 0.2815,
      "step": 21950
    },
    {
      "epoch": 2.794629505901817,
      "grad_norm": 0.31320545077323914,
      "learning_rate": 2.326747286951203e-06,
      "loss": 0.2664,
      "step": 21960
    },
    {
      "epoch": 2.7959021348350355,
      "grad_norm": 0.3459501564502716,
      "learning_rate": 2.298132822477217e-06,
      "loss": 0.2724,
      "step": 21970
    },
    {
      "epoch": 2.797174763768254,
      "grad_norm": 0.3476194143295288,
      "learning_rate": 2.2696933540925946e-06,
      "loss": 0.2629,
      "step": 21980
    },
    {
      "epoch": 2.798447392701473,
      "grad_norm": 0.39024871587753296,
      "learning_rate": 2.241428932735978e-06,
      "loss": 0.2683,
      "step": 21990
    },
    {
      "epoch": 2.799720021634692,
      "grad_norm": 0.3436599671840668,
      "learning_rate": 2.213339609032372e-06,
      "loss": 0.273,
      "step": 22000
    },
    {
      "epoch": 2.799720021634692,
      "eval_loss": 0.34497687220573425,
      "eval_runtime": 743.7378,
      "eval_samples_per_second": 10.566,
      "eval_steps_per_second": 5.283,
      "step": 22000
    },
    {
      "epoch": 2.8009926505679106,
      "grad_norm": 0.3244172930717468,
      "learning_rate": 2.185425433293242e-06,
      "loss": 0.2771,
      "step": 22010
    },
    {
      "epoch": 2.8022652795011296,
      "grad_norm": 0.3851328492164612,
      "learning_rate": 2.1576864555163278e-06,
      "loss": 0.2955,
      "step": 22020
    },
    {
      "epoch": 2.803537908434348,
      "grad_norm": 0.3526398539543152,
      "learning_rate": 2.130122725385564e-06,
      "loss": 0.2769,
      "step": 22030
    },
    {
      "epoch": 2.804810537367567,
      "grad_norm": 0.3337256908416748,
      "learning_rate": 2.1027342922709693e-06,
      "loss": 0.2608,
      "step": 22040
    },
    {
      "epoch": 2.8060831663007857,
      "grad_norm": 0.37622109055519104,
      "learning_rate": 2.075521205228603e-06,
      "loss": 0.2853,
      "step": 22050
    },
    {
      "epoch": 2.8073557952340047,
      "grad_norm": 0.3378596901893616,
      "learning_rate": 2.0484835130004766e-06,
      "loss": 0.2662,
      "step": 22060
    },
    {
      "epoch": 2.8086284241672237,
      "grad_norm": 0.4484322667121887,
      "learning_rate": 2.0216212640144172e-06,
      "loss": 0.2717,
      "step": 22070
    },
    {
      "epoch": 2.8099010531004422,
      "grad_norm": 0.38869988918304443,
      "learning_rate": 1.9949345063840276e-06,
      "loss": 0.2763,
      "step": 22080
    },
    {
      "epoch": 2.811173682033661,
      "grad_norm": 0.3648384213447571,
      "learning_rate": 1.968423287908594e-06,
      "loss": 0.2967,
      "step": 22090
    },
    {
      "epoch": 2.81244631096688,
      "grad_norm": 0.349811315536499,
      "learning_rate": 1.942087656072955e-06,
      "loss": 0.29,
      "step": 22100
    },
    {
      "epoch": 2.813718939900099,
      "grad_norm": 0.38424643874168396,
      "learning_rate": 1.9159276580474782e-06,
      "loss": 0.2697,
      "step": 22110
    },
    {
      "epoch": 2.8149915688333174,
      "grad_norm": 0.3865240216255188,
      "learning_rate": 1.8899433406879608e-06,
      "loss": 0.2783,
      "step": 22120
    },
    {
      "epoch": 2.8162641977665364,
      "grad_norm": 0.40043848752975464,
      "learning_rate": 1.8641347505355066e-06,
      "loss": 0.2929,
      "step": 22130
    },
    {
      "epoch": 2.817536826699755,
      "grad_norm": 0.29439884424209595,
      "learning_rate": 1.8385019338164944e-06,
      "loss": 0.2775,
      "step": 22140
    },
    {
      "epoch": 2.818809455632974,
      "grad_norm": 0.29940053820610046,
      "learning_rate": 1.8130449364424318e-06,
      "loss": 0.2721,
      "step": 22150
    },
    {
      "epoch": 2.8200820845661925,
      "grad_norm": 0.4347383379936218,
      "learning_rate": 1.7877638040099565e-06,
      "loss": 0.286,
      "step": 22160
    },
    {
      "epoch": 2.8213547134994115,
      "grad_norm": 0.3314577639102936,
      "learning_rate": 1.7626585818007135e-06,
      "loss": 0.2638,
      "step": 22170
    },
    {
      "epoch": 2.8226273424326305,
      "grad_norm": 0.3246857821941376,
      "learning_rate": 1.7377293147812224e-06,
      "loss": 0.2683,
      "step": 22180
    },
    {
      "epoch": 2.823899971365849,
      "grad_norm": 0.38429927825927734,
      "learning_rate": 1.7129760476028878e-06,
      "loss": 0.2672,
      "step": 22190
    },
    {
      "epoch": 2.8251726002990676,
      "grad_norm": 0.2974952459335327,
      "learning_rate": 1.6883988246018444e-06,
      "loss": 0.2667,
      "step": 22200
    },
    {
      "epoch": 2.8264452292322866,
      "grad_norm": 0.3761976957321167,
      "learning_rate": 1.6639976897989573e-06,
      "loss": 0.2828,
      "step": 22210
    },
    {
      "epoch": 2.8277178581655056,
      "grad_norm": 0.3775610625743866,
      "learning_rate": 1.6397726868996544e-06,
      "loss": 0.2722,
      "step": 22220
    },
    {
      "epoch": 2.828990487098724,
      "grad_norm": 0.30450305342674255,
      "learning_rate": 1.6157238592938828e-06,
      "loss": 0.2809,
      "step": 22230
    },
    {
      "epoch": 2.830263116031943,
      "grad_norm": 0.24281181395053864,
      "learning_rate": 1.5918512500560866e-06,
      "loss": 0.2759,
      "step": 22240
    },
    {
      "epoch": 2.8315357449651617,
      "grad_norm": 0.33604809641838074,
      "learning_rate": 1.5681549019450515e-06,
      "loss": 0.2739,
      "step": 22250
    },
    {
      "epoch": 2.8328083738983807,
      "grad_norm": 0.35546883940696716,
      "learning_rate": 1.544634857403826e-06,
      "loss": 0.2793,
      "step": 22260
    },
    {
      "epoch": 2.8340810028315992,
      "grad_norm": 0.2667634189128876,
      "learning_rate": 1.5212911585597455e-06,
      "loss": 0.2733,
      "step": 22270
    },
    {
      "epoch": 2.8353536317648182,
      "grad_norm": 0.3787020742893219,
      "learning_rate": 1.4981238472242421e-06,
      "loss": 0.2759,
      "step": 22280
    },
    {
      "epoch": 2.836626260698037,
      "grad_norm": 0.437883585691452,
      "learning_rate": 1.4751329648928225e-06,
      "loss": 0.2833,
      "step": 22290
    },
    {
      "epoch": 2.837898889631256,
      "grad_norm": 0.28477194905281067,
      "learning_rate": 1.45231855274498e-06,
      "loss": 0.2768,
      "step": 22300
    },
    {
      "epoch": 2.8391715185644744,
      "grad_norm": 0.3555762469768524,
      "learning_rate": 1.4296806516441496e-06,
      "loss": 0.2758,
      "step": 22310
    },
    {
      "epoch": 2.8404441474976934,
      "grad_norm": 0.4065030813217163,
      "learning_rate": 1.407219302137619e-06,
      "loss": 0.2718,
      "step": 22320
    },
    {
      "epoch": 2.8417167764309124,
      "grad_norm": 0.35723578929901123,
      "learning_rate": 1.3849345444564066e-06,
      "loss": 0.2809,
      "step": 22330
    },
    {
      "epoch": 2.842989405364131,
      "grad_norm": 0.37008026242256165,
      "learning_rate": 1.3628264185152838e-06,
      "loss": 0.2604,
      "step": 22340
    },
    {
      "epoch": 2.8442620342973495,
      "grad_norm": 0.3934546411037445,
      "learning_rate": 1.34089496391262e-06,
      "loss": 0.2905,
      "step": 22350
    },
    {
      "epoch": 2.8455346632305685,
      "grad_norm": 0.31720584630966187,
      "learning_rate": 1.3191402199303593e-06,
      "loss": 0.2721,
      "step": 22360
    },
    {
      "epoch": 2.8468072921637875,
      "grad_norm": 0.4158502519130707,
      "learning_rate": 1.2975622255339215e-06,
      "loss": 0.2901,
      "step": 22370
    },
    {
      "epoch": 2.848079921097006,
      "grad_norm": 0.3608607053756714,
      "learning_rate": 1.2761610193721464e-06,
      "loss": 0.2852,
      "step": 22380
    },
    {
      "epoch": 2.849352550030225,
      "grad_norm": 0.33545368909835815,
      "learning_rate": 1.25493663977726e-06,
      "loss": 0.2824,
      "step": 22390
    },
    {
      "epoch": 2.8506251789634436,
      "grad_norm": 0.40979480743408203,
      "learning_rate": 1.2338891247647199e-06,
      "loss": 0.2729,
      "step": 22400
    },
    {
      "epoch": 2.8518978078966626,
      "grad_norm": 0.36161282658576965,
      "learning_rate": 1.213018512033237e-06,
      "loss": 0.2793,
      "step": 22410
    },
    {
      "epoch": 2.853170436829881,
      "grad_norm": 0.407365083694458,
      "learning_rate": 1.1923248389646313e-06,
      "loss": 0.2862,
      "step": 22420
    },
    {
      "epoch": 2.8544430657631,
      "grad_norm": 0.38168683648109436,
      "learning_rate": 1.1718081426238536e-06,
      "loss": 0.2796,
      "step": 22430
    },
    {
      "epoch": 2.855715694696319,
      "grad_norm": 0.41383567452430725,
      "learning_rate": 1.1514684597588087e-06,
      "loss": 0.2797,
      "step": 22440
    },
    {
      "epoch": 2.8569883236295377,
      "grad_norm": 0.37346383929252625,
      "learning_rate": 1.1313058268003773e-06,
      "loss": 0.2815,
      "step": 22450
    },
    {
      "epoch": 2.8582609525627563,
      "grad_norm": 0.38883188366889954,
      "learning_rate": 1.1113202798623268e-06,
      "loss": 0.2916,
      "step": 22460
    },
    {
      "epoch": 2.8595335814959753,
      "grad_norm": 0.393213152885437,
      "learning_rate": 1.0915118547412452e-06,
      "loss": 0.2753,
      "step": 22470
    },
    {
      "epoch": 2.8608062104291943,
      "grad_norm": 0.33953914046287537,
      "learning_rate": 1.0718805869164517e-06,
      "loss": 0.2591,
      "step": 22480
    },
    {
      "epoch": 2.862078839362413,
      "grad_norm": 0.3026384115219116,
      "learning_rate": 1.0524265115499753e-06,
      "loss": 0.3001,
      "step": 22490
    },
    {
      "epoch": 2.863351468295632,
      "grad_norm": 0.3561687767505646,
      "learning_rate": 1.0331496634864546e-06,
      "loss": 0.2862,
      "step": 22500
    },
    {
      "epoch": 2.863351468295632,
      "eval_loss": 0.3448939621448517,
      "eval_runtime": 743.5373,
      "eval_samples_per_second": 10.568,
      "eval_steps_per_second": 5.284,
      "step": 22500
    },
    {
      "epoch": 2.8646240972288504,
      "grad_norm": 0.37391936779022217,
      "learning_rate": 1.0140500772531146e-06,
      "loss": 0.2911,
      "step": 22510
    },
    {
      "epoch": 2.8658967261620694,
      "grad_norm": 0.39381346106529236,
      "learning_rate": 9.951277870596575e-07,
      "loss": 0.2693,
      "step": 22520
    },
    {
      "epoch": 2.867169355095288,
      "grad_norm": 0.36933544278144836,
      "learning_rate": 9.763828267982278e-07,
      "loss": 0.2783,
      "step": 22530
    },
    {
      "epoch": 2.868441984028507,
      "grad_norm": 0.4144538640975952,
      "learning_rate": 9.578152300433907e-07,
      "loss": 0.2778,
      "step": 22540
    },
    {
      "epoch": 2.869714612961726,
      "grad_norm": 0.3519520163536072,
      "learning_rate": 9.394250300519769e-07,
      "loss": 0.281,
      "step": 22550
    },
    {
      "epoch": 2.8709872418949445,
      "grad_norm": 0.3019864857196808,
      "learning_rate": 9.212122597631045e-07,
      "loss": 0.2723,
      "step": 22560
    },
    {
      "epoch": 2.872259870828163,
      "grad_norm": 0.4012613594532013,
      "learning_rate": 9.031769517981015e-07,
      "loss": 0.28,
      "step": 22570
    },
    {
      "epoch": 2.873532499761382,
      "grad_norm": 0.41231605410575867,
      "learning_rate": 8.853191384604276e-07,
      "loss": 0.2866,
      "step": 22580
    },
    {
      "epoch": 2.874805128694601,
      "grad_norm": 0.32493510842323303,
      "learning_rate": 8.676388517356082e-07,
      "loss": 0.2675,
      "step": 22590
    },
    {
      "epoch": 2.8760777576278196,
      "grad_norm": 0.3836325407028198,
      "learning_rate": 8.501361232912342e-07,
      "loss": 0.2932,
      "step": 22600
    },
    {
      "epoch": 2.8773503865610386,
      "grad_norm": 0.45063233375549316,
      "learning_rate": 8.328109844768394e-07,
      "loss": 0.2811,
      "step": 22610
    },
    {
      "epoch": 2.878623015494257,
      "grad_norm": 0.35328543186187744,
      "learning_rate": 8.156634663239016e-07,
      "loss": 0.2676,
      "step": 22620
    },
    {
      "epoch": 2.879895644427476,
      "grad_norm": 0.309520959854126,
      "learning_rate": 7.98693599545719e-07,
      "loss": 0.2653,
      "step": 22630
    },
    {
      "epoch": 2.8811682733606947,
      "grad_norm": 0.37921270728111267,
      "learning_rate": 7.819014145374338e-07,
      "loss": 0.2851,
      "step": 22640
    },
    {
      "epoch": 2.8824409022939137,
      "grad_norm": 0.42943552136421204,
      "learning_rate": 7.652869413758978e-07,
      "loss": 0.289,
      "step": 22650
    },
    {
      "epoch": 2.8837135312271327,
      "grad_norm": 0.38385626673698425,
      "learning_rate": 7.48850209819707e-07,
      "loss": 0.2632,
      "step": 22660
    },
    {
      "epoch": 2.8849861601603513,
      "grad_norm": 0.3516373932361603,
      "learning_rate": 7.325912493090559e-07,
      "loss": 0.2719,
      "step": 22670
    },
    {
      "epoch": 2.88625878909357,
      "grad_norm": 0.3329745829105377,
      "learning_rate": 7.165100889657384e-07,
      "loss": 0.2661,
      "step": 22680
    },
    {
      "epoch": 2.887531418026789,
      "grad_norm": 0.34552785754203796,
      "learning_rate": 7.006067575931253e-07,
      "loss": 0.281,
      "step": 22690
    },
    {
      "epoch": 2.888804046960008,
      "grad_norm": 0.31243380904197693,
      "learning_rate": 6.848812836760199e-07,
      "loss": 0.2717,
      "step": 22700
    },
    {
      "epoch": 2.8900766758932264,
      "grad_norm": 0.2787362337112427,
      "learning_rate": 6.693336953806917e-07,
      "loss": 0.284,
      "step": 22710
    },
    {
      "epoch": 2.8913493048264454,
      "grad_norm": 0.4180729389190674,
      "learning_rate": 6.53964020554787e-07,
      "loss": 0.283,
      "step": 22720
    },
    {
      "epoch": 2.892621933759664,
      "grad_norm": 0.38188424706459045,
      "learning_rate": 6.387722867272849e-07,
      "loss": 0.2856,
      "step": 22730
    },
    {
      "epoch": 2.893894562692883,
      "grad_norm": 0.40189889073371887,
      "learning_rate": 6.237585211084751e-07,
      "loss": 0.2805,
      "step": 22740
    },
    {
      "epoch": 2.8951671916261015,
      "grad_norm": 0.33758893609046936,
      "learning_rate": 6.089227505898242e-07,
      "loss": 0.2922,
      "step": 22750
    },
    {
      "epoch": 2.8964398205593205,
      "grad_norm": 0.3215309679508209,
      "learning_rate": 5.942650017440543e-07,
      "loss": 0.2679,
      "step": 22760
    },
    {
      "epoch": 2.8977124494925395,
      "grad_norm": 0.36021688580513,
      "learning_rate": 5.797853008250087e-07,
      "loss": 0.2883,
      "step": 22770
    },
    {
      "epoch": 2.898985078425758,
      "grad_norm": 0.3903988301753998,
      "learning_rate": 5.654836737675861e-07,
      "loss": 0.2784,
      "step": 22780
    },
    {
      "epoch": 2.9002577073589766,
      "grad_norm": 0.31708016991615295,
      "learning_rate": 5.513601461877849e-07,
      "loss": 0.2734,
      "step": 22790
    },
    {
      "epoch": 2.9015303362921956,
      "grad_norm": 0.3144403398036957,
      "learning_rate": 5.374147433825805e-07,
      "loss": 0.2789,
      "step": 22800
    },
    {
      "epoch": 2.9028029652254146,
      "grad_norm": 0.3579891622066498,
      "learning_rate": 5.236474903298927e-07,
      "loss": 0.281,
      "step": 22810
    },
    {
      "epoch": 2.904075594158633,
      "grad_norm": 0.33840492367744446,
      "learning_rate": 5.100584116886076e-07,
      "loss": 0.2782,
      "step": 22820
    },
    {
      "epoch": 2.905348223091852,
      "grad_norm": 0.2964533567428589,
      "learning_rate": 4.966475317983999e-07,
      "loss": 0.2755,
      "step": 22830
    },
    {
      "epoch": 2.9066208520250707,
      "grad_norm": 0.408831924200058,
      "learning_rate": 4.834148746798328e-07,
      "loss": 0.2851,
      "step": 22840
    },
    {
      "epoch": 2.9078934809582897,
      "grad_norm": 0.34684184193611145,
      "learning_rate": 4.7036046403421407e-07,
      "loss": 0.2782,
      "step": 22850
    },
    {
      "epoch": 2.9091661098915083,
      "grad_norm": 0.27705273032188416,
      "learning_rate": 4.5748432324360657e-07,
      "loss": 0.2748,
      "step": 22860
    },
    {
      "epoch": 2.9104387388247273,
      "grad_norm": 0.379669725894928,
      "learning_rate": 4.4478647537077313e-07,
      "loss": 0.2665,
      "step": 22870
    },
    {
      "epoch": 2.911711367757946,
      "grad_norm": 0.36174294352531433,
      "learning_rate": 4.322669431591209e-07,
      "loss": 0.2844,
      "step": 22880
    },
    {
      "epoch": 2.912983996691165,
      "grad_norm": 0.39079228043556213,
      "learning_rate": 4.19925749032668e-07,
      "loss": 0.2758,
      "step": 22890
    },
    {
      "epoch": 2.9142566256243834,
      "grad_norm": 0.3897087574005127,
      "learning_rate": 4.077629150960216e-07,
      "loss": 0.2856,
      "step": 22900
    },
    {
      "epoch": 2.9155292545576024,
      "grad_norm": 0.3797779381275177,
      "learning_rate": 3.957784631343109e-07,
      "loss": 0.2667,
      "step": 22910
    },
    {
      "epoch": 2.9168018834908214,
      "grad_norm": 0.3654378652572632,
      "learning_rate": 3.8397241461317624e-07,
      "loss": 0.2833,
      "step": 22920
    },
    {
      "epoch": 2.91807451242404,
      "grad_norm": 0.26316776871681213,
      "learning_rate": 3.7234479067870254e-07,
      "loss": 0.2711,
      "step": 22930
    },
    {
      "epoch": 2.919347141357259,
      "grad_norm": 0.345930814743042,
      "learning_rate": 3.608956121573859e-07,
      "loss": 0.2672,
      "step": 22940
    },
    {
      "epoch": 2.9206197702904775,
      "grad_norm": 0.38340991735458374,
      "learning_rate": 3.4962489955614464e-07,
      "loss": 0.2905,
      "step": 22950
    },
    {
      "epoch": 2.9218923992236965,
      "grad_norm": 0.3283396065235138,
      "learning_rate": 3.385326730621752e-07,
      "loss": 0.2667,
      "step": 22960
    },
    {
      "epoch": 2.923165028156915,
      "grad_norm": 0.29268017411231995,
      "learning_rate": 3.2761895254306287e-07,
      "loss": 0.2869,
      "step": 22970
    },
    {
      "epoch": 2.924437657090134,
      "grad_norm": 0.352628618478775,
      "learning_rate": 3.1688375754659326e-07,
      "loss": 0.27,
      "step": 22980
    },
    {
      "epoch": 2.9257102860233526,
      "grad_norm": 0.3252123296260834,
      "learning_rate": 3.0632710730085224e-07,
      "loss": 0.2717,
      "step": 22990
    },
    {
      "epoch": 2.9269829149565716,
      "grad_norm": 0.39514845609664917,
      "learning_rate": 2.959490207140814e-07,
      "loss": 0.2695,
      "step": 23000
    },
    {
      "epoch": 2.9269829149565716,
      "eval_loss": 0.344833105802536,
      "eval_runtime": 762.0827,
      "eval_samples_per_second": 10.311,
      "eval_steps_per_second": 5.156,
      "step": 23000
    },
    {
      "epoch": 2.92825554388979,
      "grad_norm": 0.4068152904510498,
      "learning_rate": 2.857495163747226e-07,
      "loss": 0.2756,
      "step": 23010
    },
    {
      "epoch": 2.929528172823009,
      "grad_norm": 0.37853485345840454,
      "learning_rate": 2.757286125513403e-07,
      "loss": 0.291,
      "step": 23020
    },
    {
      "epoch": 2.930800801756228,
      "grad_norm": 0.39771485328674316,
      "learning_rate": 2.658863271926104e-07,
      "loss": 0.284,
      "step": 23030
    },
    {
      "epoch": 2.9320734306894467,
      "grad_norm": 0.34015771746635437,
      "learning_rate": 2.5622267792728696e-07,
      "loss": 0.2773,
      "step": 23040
    },
    {
      "epoch": 2.9333460596226653,
      "grad_norm": 0.32789668440818787,
      "learning_rate": 2.467376820641465e-07,
      "loss": 0.2606,
      "step": 23050
    },
    {
      "epoch": 2.9346186885558843,
      "grad_norm": 0.337037593126297,
      "learning_rate": 2.3743135659199945e-07,
      "loss": 0.2736,
      "step": 23060
    },
    {
      "epoch": 2.9358913174891033,
      "grad_norm": 0.2890666723251343,
      "learning_rate": 2.2830371817960107e-07,
      "loss": 0.2795,
      "step": 23070
    },
    {
      "epoch": 2.937163946422322,
      "grad_norm": 0.46487289667129517,
      "learning_rate": 2.1935478317569592e-07,
      "loss": 0.2847,
      "step": 23080
    },
    {
      "epoch": 2.938436575355541,
      "grad_norm": 0.36668258905410767,
      "learning_rate": 2.1058456760891798e-07,
      "loss": 0.2742,
      "step": 23090
    },
    {
      "epoch": 2.9397092042887594,
      "grad_norm": 0.3672652542591095,
      "learning_rate": 2.0199308718781285e-07,
      "loss": 0.2791,
      "step": 23100
    },
    {
      "epoch": 2.9409818332219784,
      "grad_norm": 0.3560642600059509,
      "learning_rate": 1.9358035730077106e-07,
      "loss": 0.2743,
      "step": 23110
    },
    {
      "epoch": 2.942254462155197,
      "grad_norm": 0.40107548236846924,
      "learning_rate": 1.853463930160504e-07,
      "loss": 0.2831,
      "step": 23120
    },
    {
      "epoch": 2.943527091088416,
      "grad_norm": 0.3664330244064331,
      "learning_rate": 1.7729120908167585e-07,
      "loss": 0.2775,
      "step": 23130
    },
    {
      "epoch": 2.944799720021635,
      "grad_norm": 0.34602856636047363,
      "learning_rate": 1.6941481992547303e-07,
      "loss": 0.2822,
      "step": 23140
    },
    {
      "epoch": 2.9460723489548535,
      "grad_norm": 0.3656747043132782,
      "learning_rate": 1.6171723965503484e-07,
      "loss": 0.2794,
      "step": 23150
    },
    {
      "epoch": 2.947344977888072,
      "grad_norm": 0.342131108045578,
      "learning_rate": 1.5419848205768804e-07,
      "loss": 0.3039,
      "step": 23160
    },
    {
      "epoch": 2.948617606821291,
      "grad_norm": 0.29835036396980286,
      "learning_rate": 1.468585606004269e-07,
      "loss": 0.2677,
      "step": 23170
    },
    {
      "epoch": 2.94989023575451,
      "grad_norm": 0.30910733342170715,
      "learning_rate": 1.3969748842997953e-07,
      "loss": 0.2831,
      "step": 23180
    },
    {
      "epoch": 2.9511628646877286,
      "grad_norm": 0.4118303656578064,
      "learning_rate": 1.3271527837269705e-07,
      "loss": 0.2756,
      "step": 23190
    },
    {
      "epoch": 2.9524354936209476,
      "grad_norm": 0.25567561388015747,
      "learning_rate": 1.2591194293457565e-07,
      "loss": 0.2753,
      "step": 23200
    },
    {
      "epoch": 2.953708122554166,
      "grad_norm": 0.38182616233825684,
      "learning_rate": 1.1928749430124565e-07,
      "loss": 0.2836,
      "step": 23210
    },
    {
      "epoch": 2.954980751487385,
      "grad_norm": 0.2982330024242401,
      "learning_rate": 1.1284194433789364e-07,
      "loss": 0.2757,
      "step": 23220
    },
    {
      "epoch": 2.9562533804206037,
      "grad_norm": 0.336590051651001,
      "learning_rate": 1.0657530458929587e-07,
      "loss": 0.2748,
      "step": 23230
    },
    {
      "epoch": 2.9575260093538227,
      "grad_norm": 0.3437865078449249,
      "learning_rate": 1.0048758627978494e-07,
      "loss": 0.2822,
      "step": 23240
    },
    {
      "epoch": 2.9587986382870417,
      "grad_norm": 0.3113062381744385,
      "learning_rate": 9.457880031320531e-08,
      "loss": 0.2859,
      "step": 23250
    },
    {
      "epoch": 2.9600712672202603,
      "grad_norm": 0.3517063558101654,
      "learning_rate": 8.884895727293563e-08,
      "loss": 0.267,
      "step": 23260
    },
    {
      "epoch": 2.961343896153479,
      "grad_norm": 0.47151869535446167,
      "learning_rate": 8.32980674218109e-08,
      "loss": 0.2934,
      "step": 23270
    },
    {
      "epoch": 2.962616525086698,
      "grad_norm": 0.33544856309890747,
      "learning_rate": 7.792614070217807e-08,
      "loss": 0.2973,
      "step": 23280
    },
    {
      "epoch": 2.963889154019917,
      "grad_norm": 0.3294578790664673,
      "learning_rate": 7.273318673581831e-08,
      "loss": 0.2756,
      "step": 23290
    },
    {
      "epoch": 2.9651617829531354,
      "grad_norm": 0.3492550253868103,
      "learning_rate": 6.771921482393584e-08,
      "loss": 0.2798,
      "step": 23300
    },
    {
      "epoch": 2.9664344118863544,
      "grad_norm": 0.27750054001808167,
      "learning_rate": 6.288423394718024e-08,
      "loss": 0.2986,
      "step": 23310
    },
    {
      "epoch": 2.967707040819573,
      "grad_norm": 0.3719058036804199,
      "learning_rate": 5.8228252765613055e-08,
      "loss": 0.2865,
      "step": 23320
    },
    {
      "epoch": 2.968979669752792,
      "grad_norm": 0.4233030378818512,
      "learning_rate": 5.375127961865234e-08,
      "loss": 0.2895,
      "step": 23330
    },
    {
      "epoch": 2.9702522986860105,
      "grad_norm": 0.39875349402427673,
      "learning_rate": 4.945332252510593e-08,
      "loss": 0.2834,
      "step": 23340
    },
    {
      "epoch": 2.9715249276192295,
      "grad_norm": 0.3331621289253235,
      "learning_rate": 4.533438918317145e-08,
      "loss": 0.273,
      "step": 23350
    },
    {
      "epoch": 2.9727975565524485,
      "grad_norm": 0.35316118597984314,
      "learning_rate": 4.139448697033643e-08,
      "loss": 0.2797,
      "step": 23360
    },
    {
      "epoch": 2.974070185485667,
      "grad_norm": 0.3933049142360687,
      "learning_rate": 3.763362294346706e-08,
      "loss": 0.2623,
      "step": 23370
    },
    {
      "epoch": 2.9753428144188856,
      "grad_norm": 0.3381993770599365,
      "learning_rate": 3.4051803838741626e-08,
      "loss": 0.2754,
      "step": 23380
    },
    {
      "epoch": 2.9766154433521046,
      "grad_norm": 0.37731868028640747,
      "learning_rate": 3.0649036071617175e-08,
      "loss": 0.2945,
      "step": 23390
    },
    {
      "epoch": 2.9778880722853236,
      "grad_norm": 0.32156065106391907,
      "learning_rate": 2.7425325736885054e-08,
      "loss": 0.2829,
      "step": 23400
    },
    {
      "epoch": 2.979160701218542,
      "grad_norm": 0.37516772747039795,
      "learning_rate": 2.438067860861537e-08,
      "loss": 0.2792,
      "step": 23410
    },
    {
      "epoch": 2.980433330151761,
      "grad_norm": 0.3099623918533325,
      "learning_rate": 2.15151001401237e-08,
      "loss": 0.277,
      "step": 23420
    },
    {
      "epoch": 2.9817059590849797,
      "grad_norm": 0.3922105133533478,
      "learning_rate": 1.8828595464037702e-08,
      "loss": 0.2697,
      "step": 23430
    },
    {
      "epoch": 2.9829785880181987,
      "grad_norm": 0.39917171001434326,
      "learning_rate": 1.6321169392197188e-08,
      "loss": 0.3029,
      "step": 23440
    },
    {
      "epoch": 2.9842512169514173,
      "grad_norm": 0.37886419892311096,
      "learning_rate": 1.3992826415731853e-08,
      "loss": 0.3012,
      "step": 23450
    },
    {
      "epoch": 2.9855238458846363,
      "grad_norm": 0.37210530042648315,
      "learning_rate": 1.1843570704983542e-08,
      "loss": 0.2803,
      "step": 23460
    },
    {
      "epoch": 2.986796474817855,
      "grad_norm": 0.31597480177879333,
      "learning_rate": 9.873406109528471e-09,
      "loss": 0.2745,
      "step": 23470
    },
    {
      "epoch": 2.988069103751074,
      "grad_norm": 0.3745904862880707,
      "learning_rate": 8.082336158177218e-09,
      "loss": 0.2923,
      "step": 23480
    },
    {
      "epoch": 2.9893417326842924,
      "grad_norm": 0.39190760254859924,
      "learning_rate": 6.470364058952516e-09,
      "loss": 0.299,
      "step": 23490
    },
    {
      "epoch": 2.9906143616175114,
      "grad_norm": 0.3956824839115143,
      "learning_rate": 5.037492699111468e-09,
      "loss": 0.2855,
      "step": 23500
    },
    {
      "epoch": 2.9906143616175114,
      "eval_loss": 0.34479814767837524,
      "eval_runtime": 760.5856,
      "eval_samples_per_second": 10.332,
      "eval_steps_per_second": 5.166,
      "step": 23500
    }
  ],
  "logging_steps": 10,
  "max_steps": 23574,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.1798118946992292e+18,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
